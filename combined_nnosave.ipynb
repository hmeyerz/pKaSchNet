{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "from Bio import PDB\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from ase import Atoms, Atom\n",
    "import dask.dataframe as dd\n",
    "from ordered_set import OrderedSet\n",
    "import os\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import chain, product\n",
    "import sys\n",
    "\n",
    "local_folder=\"/Users/jessihoernschemeyer/pKaSchNet\"\n",
    "pkPDB_CSV = f\"{local_folder}/pkas.csv\"\n",
    "def read_database(path):\n",
    "    \"\"\"csv --> dask df\"\"\"\n",
    "    #make the dask data frame from the PYPKA csv\n",
    "    dk=dd.read_csv(path, delimiter=';', na_filter=False, dtype={'idcode':'category', \n",
    "                                                                    'residue_number':'uint8',\n",
    "                                                                    'pk': 'float32',\n",
    "                                                                    'residue_name':'category',\n",
    "                                                                    'chain': 'category',\n",
    "                                                                    'residue_name': 'category'\n",
    "                                                                    })\n",
    "                                                            \n",
    "    dk=dk.rename(columns={'idcode': 'PDB ID', 'residue_number': 'Res ID', 'residue_name': 'Res Name', 'residue_number': 'Res ID', 'pk': 'pKa', 'chain' : 'Chain'}) #rename columns to match df from pkad \n",
    "    dk=dk.sort_values(['PDB ID', 'Res ID'], ascending=[True, True]) \n",
    "    dk=dk.compute() \n",
    "    dff = dk.reset_index() \n",
    "\n",
    "    return dff\n",
    "\n",
    "def check_atoms_protein(structure, struc_atoms): \n",
    "    \"\"\"internal function. checks every atom in the entire protein for metals, undesirables\"\"\"\n",
    "    pdb_residues=[]\n",
    "    for atom in struc_atoms: \n",
    "        resname, atomid=atom.get_parent().get_resname(), atom.get_full_id()[2:]\n",
    "        element=atomid[2][0]\n",
    "\n",
    "        if element in [\"MG\", \"MN\", \"FE\", \"CO\", \"NI\", \"CU\", \"ZN\"]:\n",
    "            return 0#,0#print(f\"{element} present, pdb skipped\")\n",
    "        \n",
    "        else:\n",
    "            #atomid=atom.get_full_id() #('', 0, 'B', (' ', 177, ' '), ('OH', ' '))\n",
    "            if atomid[1][0] not in [' ']:\n",
    "                if element == 'S': #check 4 hetero sulfur, exclude.\n",
    "                    print(f\"{atomid}, hetero sulfur. pdb skipped \")\n",
    "                    return 0#,0\n",
    "                \n",
    "                if element in ['CA', 'CL', 'K', 'NA']: #other salt\n",
    "                    for res in structure.get_residues():\n",
    "                        if resname in [\"GLU\", \"HIS\", \"ASP\", \"ARG\", \"TYR\", \"CYS\", \"LYS\"]: #if the other salt is part of the residue (<3Ã¥ from geometric center), delete atom from residue\n",
    "                            if np.linalg.norm(res.center_of_mass(geometric=True) - atom.get_coord()) < 3:\n",
    "                                atom.get_parent().detach_child(atom.get_id()) #print(f\"salt {atom} deleted, {d} from {res}\")\n",
    "    \n",
    "    return structure#, set(pdb_residues) #('', 0, 'B', ('W', 371, ' '), ('O', ' '))\n",
    "\n",
    "def atoms_to_structure(cutout, filename): \n",
    "    \"\"\"Internal function (or not), cutout --> save to harddrive\n",
    "    input: cutout: list of biopython atom objects (NOT ASE)\"\"\"\n",
    "    chain_dict = {}\n",
    "\n",
    "    structure = Structure.Structure(filename)\n",
    "    model = Model.Model(0)\n",
    "    structure.add(model)\n",
    "\n",
    "    for atom in cutout:\n",
    "        res = atom.get_parent()\n",
    "        res_id, resname, chain_id = res.get_id(), res.get_resname(), res.get_full_id()[2]\n",
    "\n",
    "        #make acidic GLH and ASH straight here. so change their name before saving \n",
    "        if resname == \"GLU\":\n",
    "            resname=\"GLH\"\n",
    "            \n",
    "        if resname==\"ASP\":\n",
    "            resname=\"ASH\"\n",
    "\n",
    "        if resname==\"HIS\":\n",
    "            resname=\"HIP\"\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "        if chain_id not in chain_dict:\n",
    "            chain = Chain.Chain(chain_id) #make new chain\n",
    "            chain_dict[chain_id] = chain\n",
    "            model.add(chain) #add it\n",
    "\n",
    "        else:\n",
    "            chain = chain_dict[chain_id]\n",
    "\n",
    "        if res_id in [res.get_id() for res in chain.get_residues()]:\n",
    "            residue = [res for res in chain.get_residues() if res.get_id() == res_id][0] \n",
    "        else:\n",
    "            residue = Residue.Residue(res_id, resname, '') #make new res\n",
    "            chain.add(residue)\n",
    "\n",
    "        residue.add(atom)\n",
    "    # save the pdb\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(f\"cuts/{filename}.pdb\")\n",
    "\n",
    "def generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter, resname):\n",
    "    \"\"\"Residue wise resolurion. ns is neighbor search set up for the entire protein, residue is the single data point / 1 of several residues in a pdb & in pypka.\n",
    "    input is one residue. output is the cutout around its titratable site, both of which can be plural e.g. his, mb asp and glu.\n",
    "    residue (biopython Residue object): a single protonable residue \"\"\"\n",
    "    protonatable_sites = {\"G\":(\"OE1\",\"OE2\"), \"A\":(\"OD1\",\"OD2\"), \"C\":\"SG\", \"L\":\"NZ\", \"H\":(\"NE2\", \"ND1\"), \"T\":\"OH\"}\n",
    "    cuts = []\n",
    "    if resname==0:\n",
    "        #first atom is N and NTR\n",
    "        #atoms=residue.\n",
    "        center = residue['N'].get_coord()\n",
    "        cut = ns.search(center, distance_cutoff, \"A\")\n",
    "        cuts.append((counter, center, 'NTR', cut)) #counter is id!\n",
    "        return cuts\n",
    "    \n",
    "    elif resname==1: #CTR\n",
    "        try:\n",
    "            center = residue['OXT'].get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, 'OX', cut))\n",
    "        except:\n",
    "            center = residue['C'].get_coord()\n",
    "        cut = ns.search(center, distance_cutoff, \"A\")\n",
    "        cuts.append((counter, center, 'X', cut)) #counter is id!\n",
    "        return cuts\n",
    " \n",
    "    else:\n",
    "        if resname==\"G\": \n",
    "            sites=protonatable_sites[resname]\n",
    "            atom1,atom2=residue[sites[0]],residue[sites[1]]\n",
    "            if atom1.is_disordered(): \n",
    "                center, resname = atom1.get_coord(), resname + \"D\"\n",
    "            elif atom2.is_disordered():\n",
    "                center, resname = atom2.get_coord(), resname + \"D\"\n",
    "            else:\n",
    "                center=(atom1.get_coord() + atom2.get_coord()) / 2.0\n",
    "            cut = ns.search(center, distance_cutoff, \"A\") #put ns search i n below? todo\n",
    "            cuts.append((counter, center, resname, cut)) #counter is id!\n",
    "            return cuts\n",
    "        if resname==\"A\": \n",
    "            sites=protonatable_sites[resname]\n",
    "            atom1,atom2=residue[sites[0]],residue[sites[1]]\n",
    "            if atom1.is_disordered(): \n",
    "                center, resname = atom1.get_coord(), resname + \"D\"\n",
    "                print(1)\n",
    "            elif atom2.is_disordered():\n",
    "                center, resname = atom2.get_coord(), resname + \"D\"\n",
    "                print(2)\n",
    "            else:\n",
    "                center=(atom1.get_coord() + atom2.get_coord()) / 2.0\n",
    "                #print(3)\n",
    "            \n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            #print(\"cut\", cut)\n",
    "            cuts.append((counter, center, resname, cut)) #counter is id!\n",
    "            return cuts\n",
    "        if resname==\"C\": \n",
    "            site=residue[protonatable_sites[resname]]\n",
    "            if site.is_disordered(): \n",
    "                resname = resname + \"D\"\n",
    "            center =site.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, resname, cut)) #counter is id!\n",
    "            return cuts\n",
    "        if resname==\"L\": \n",
    "            site=residue[protonatable_sites[resname]]\n",
    "            if site.is_disordered(): \n",
    "                resname = resname + \"D\"\n",
    "            center =site.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, resname, cut)) #counter is id!\n",
    "            return cuts\n",
    "        if resname==\"T\":\n",
    "            site=residue[protonatable_sites[resname]]\n",
    "            if site.is_disordered(): \n",
    "                resname = resname + \"D\"\n",
    "            center =site.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, resname, cut)) #counter is id!\n",
    "            return cuts\n",
    "              \n",
    "        if resname==\"H\":\n",
    "            sites=protonatable_sites[resname]\n",
    "            atom1,atom2=residue[sites[0]],residue[sites[1]]            \n",
    "            if atom1.is_disordered(): \n",
    "                resname = resname + \"D\"\n",
    "            if atom2.is_disordered():\n",
    "                resname = resname + \"D\"\n",
    "            center1,center2=atom1.get_coord(), atom2.get_coord()\n",
    "            cut1 = ns.search(center1, distance_cutoff, \"A\")\n",
    "            cut2= ns.search(center2, distance_cutoff, \"A\")\n",
    "            cuts.append([(counter+.1, center1, resname, cut1),(counter+.2, center2, resname, cut2)])\n",
    "            #cuts.append((counter+.2, center2, resname, cut2))\n",
    "\n",
    "\n",
    "    return cuts #plural because of sites with multiple sites.\n",
    "\n",
    "def merge_or_not_cutouts(cutouts_apdb, distance_cutoff): #TODO: reduce dtypes #PDB WISE!\n",
    "    \"\"\"\n",
    "    in: all of the cutouts from the pdb. returns the merged or solo cutout for each input residue of cutouts_apdb. len in = len out\"\"\"\n",
    "    #protein wise ..\n",
    "    dp_ids,centers,cuts, Ds_lite, cutouts, resnames,redunant_merged_is, done_pairs =[],[],[],[], [],[],[],[]\n",
    "\n",
    "    for site in cutouts_apdb:\n",
    "        if type(site)==tuple:\n",
    "            #print(\"a site\", site[0])\n",
    "            dp_ids.append(site[0]) #1,2,3f,4,5,6,7,8,9.1, 9.2....\n",
    "            centers.append(site[1]) \n",
    "            resnames.append(site[2])\n",
    "            cuts.append(site[3])\n",
    "        else:\n",
    "            print(\"a site\", site[0][0], site[1][0])\n",
    "            #site1,site2=site[0],site[1]\n",
    "            dp_ids.append(site[0][0]) #1,2,3,4,5,6,7,8,9.1, 9.2....\n",
    "            dp_ids.append(site[1][0])\n",
    "\n",
    "            centers.append(site[0][1]) \n",
    "            centers.append(site[1][1]) \n",
    "\n",
    "            resnames.append(site[0][2])\n",
    "            resnames.append(site[1][2]) \n",
    "\n",
    "            cuts.append(site[0][3])\n",
    "            cuts.append(site[1][3])\n",
    "    print(resnames)\n",
    "    num_residues=len(centers)\n",
    "    distances = np.zeros((num_residues, num_residues))\n",
    "    \n",
    "    for i in range(num_residues):\n",
    "        for j in range(i + 1, num_residues):\n",
    "            distance = np.linalg.norm(centers[i] - centers[j]).astype(np.float32)\n",
    "\n",
    "            if distance < distance_cutoff:\n",
    "                distances[i, j] = distance.astype(np.float32)\n",
    "                distances[j, i] = distance.astype(np.float32)\n",
    "\n",
    "    #Ds lite correctly gets the nonzero entries from column? row? i of distances.\n",
    "    Ds_lite = [distances[i][distances[i] != 0] for i in range(num_residues)] #nonzero entries for easier searching\n",
    "    #print(len(Ds_lite))\n",
    "#residuewise...\n",
    "    for i in range(len(Ds_lite)): #=len IDs \n",
    "        a_residues_distance_array=Ds_lite[i]\n",
    "        if a_residues_distance_array.any(): #if not empty\n",
    "            index=i\n",
    "            closest_cutout_i = int(np.where((distances[int(index), :])==np.min(a_residues_distance_array))[0]) #int is unneccessary TODO\n",
    "            pair_i = frozenset((index,dp_ids[closest_cutout_i]))#key #frozen set is immutable thus can be used as a dict key #also order doesnt matter, 2-1=1-2\n",
    "\n",
    "            if not done_pairs: #if there are any yet merged\n",
    "                pairid = resnames[i] + resnames[closest_cutout_i]\n",
    "                \n",
    "                cutout = (list(set(cuts[i] + cuts[closest_cutout_i])),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]))\n",
    "                done_pairs.append(pair_i)\n",
    "                redunant_merged_is.append(closest_cutout_i)\n",
    "                \n",
    "            else: #if there are already some generated\n",
    "                if pair_i not in done_pairs: #if that mergedcut hasnt yet been made\n",
    "                    cutout = (list(set(cuts[i] + cuts[closest_cutout_i])),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]))\n",
    "                    done_pairs.append(pair_i)\n",
    "                    redunant_merged_is.append(closest_cutout_i)\n",
    "\n",
    "                else: #null\n",
    "                    cutout = None\n",
    "\n",
    "        else: #solo cutout\n",
    "            cutout = (cuts[i], centers[i])\n",
    "\n",
    "        cutouts.append(cutout)\n",
    "\n",
    "    if len(cutouts) != len(dp_ids): #delete?\n",
    "        return #this will make an exception if something went wrong\n",
    "    \n",
    "    return cutouts,redunant_merged_is #merged or solo\n",
    "\n",
    "def get_cutout(dask_df, distance_cutoff): #\"PARENT\" FUNCTION\n",
    "    \"\"\"for each protein in dask_df (the entire PYPKA database), it iterates residue wise through the 121,294 proteins in PYPKA database and downloads\n",
    "    the structure from RCSB with biopython. Then, it checks and skips the structure if metals & hetero sulfurs are present, and deletes non-sulfur\n",
    "    salts from titratable residues.\n",
    "    Then, for each structure residue represented in PYPKA, generates a cutout for each residue, appends the structure to cutouts_apdb\"\"\"\n",
    "    all_fnames, all_cuts, all_centers = [],[],[]\n",
    "    for i in range(19,20): #will equal len of set of pdbs in pypka, == 121294 \n",
    "        cutouts_apdb, fnames, cutouts_1_datapoint, counter, pdbname, newfnames, centers_apdb = [],[], [],0, pdbs[i],[],[]\n",
    "        Structure = pdb_parser.get_structure(\"\",  PDBList().retrieve_pdb_file(str.lower(pdbname),obsolete=False, pdir='PDB',file_format = 'pdb'))\n",
    "        structure= check_atoms_protein(Structure, Structure.get_atoms())\n",
    "        if not structure: #skip entire pdb and all its entries in pypka db if there are undesirables in pdb\n",
    "            continue\n",
    "            \n",
    "        ns = PDB.NeighborSearch(list(structure.get_atoms())) #set up ns , entire protein\n",
    "        pdb_df = dask_df[dask_df.iloc[:, 1] == pdbname].drop(columns = [\"PDB ID\", \"pKa\"]) #make a subdf containing only residue entries which are in PYPKA (dask_df) \n",
    "        for j in range(len(pdb_df)):  #go through each residue in a pdb #each j is a datapoint!\n",
    "            NTRresname, CTRresname=None,None\n",
    "            chain, res_id =pdb_df.iloc[j]['Chain'], int(pdb_df.iloc[j]['Res ID'])\n",
    "            try: \n",
    "                residue=structure[0][chain][res_id] #a datapoint #TODO: make ID?\n",
    "                pypka_resname, PDBresname = pdb_df.iloc[j]['Res Name'], residue.get_resname() #pypka error\n",
    "                if pypka_resname=='NTR':\n",
    "                    resname, pypka_resname, NTRresname=0, 'N', PDBresname\n",
    "                elif pypka_resname=='CTR':\n",
    "                    resname,pypka_resname, CTRresname =1,\"X\", PDBresname #carboxyl\n",
    "                elif pypka_resname==PDBresname:\n",
    "                    resname=pypka_resname[0]\n",
    "                #pypka error: if not in ntr or == pdbresname, it will error and pass.\n",
    "                    #elif pypka_resname == PDBresname: #ACHTUNG! this navigates the pyka error. #TODO: mail him #TODO: THIS EXCLUDES NTR AND CTR!\n",
    "\n",
    "                cutouts_1_datapoint=generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter, resname) #can be multiple #returns empty if disordered\n",
    "                if cutouts_1_datapoint: #cutouts_1_datapoint DNE if titratable site is disordered\n",
    "                    cutouts_apdb.append(*cutouts_1_datapoint) #append each residue/data point cutouts here #it will error here if disordered\n",
    "                    #for _ in cutouts_1_datapoint:\n",
    "                    #TODO check: pypka resname always equals pdb resname\n",
    "                    #fnames.append(f\"{pdbname}{chain}{res_id}_{pypka_resname}{counter}\") \n",
    "                    if resname!=\"H\": #TODO: check if its quicker to do \"for cuts in cutouts a pdb\" or if resname==H\n",
    "                        fnames.append(f\"{pdbname}{chain}{res_id}_{pypka_resname}{counter}\") \n",
    "                        \n",
    "                    elif CTRresname:\n",
    "                        fnames.append(f\"{pdbname}{chain}{res_id}_{pypka_resname}{counter}-{CTRresname}\")\n",
    "                    elif NTRresname:\n",
    "                        fnames.append(f\"{pdbname}{chain}{res_id}_{pypka_resname}{counter}-{NTRresname}\") \n",
    "\n",
    "                        \n",
    "                    else: #normal\n",
    "                        fnames.append(f\"{pdbname}{chain}{res_id}_{pypka_resname}{counter + .1}\") \n",
    "                        fnames.append(f\"{pdbname}{chain}{res_id}_{pypka_resname}{counter + .2}\") \n",
    "                    counter+=1\n",
    "                else:\n",
    "                    continue #pypka error\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Exception caught: {e}\")\n",
    "                raise  \n",
    "  \n",
    "        #os.remove(f\"{local_folder}/PDB/pdb{pdbname}.ent\")  #TODO\n",
    "        if cutouts_apdb:\n",
    "            merged_and_solos, greaterN_pair_i =merge_or_not_cutouts(cutouts_apdb, distance_cutoff)#make a merged cutout or not based off radius criteria\n",
    "            for cut, fname in zip(merged_and_solos, fnames):\n",
    "                if not cut:\n",
    "                    continue\n",
    "                \n",
    "                elif len(cut)==3: #means it is a merged cutout. second argument is the pairid #it is still 1-to-1 here but ima destroy it\n",
    "                    Fname=\"\".join([fname,'_',fnames[greaterN_pair_i[0]],\"_\",cut[1]]) #cut1 is pairid AT, HH,...\n",
    "                    newfnames.append(Fname)\n",
    "                    centers_apdb.append(cut[2])\n",
    "                    del greaterN_pair_i[0]\n",
    "                    atoms_to_structure(cut[0], Fname) #save as pdb) #cut \n",
    "\n",
    "                else:\n",
    "                    newfnames.append(fname)\n",
    "                    centers_apdb.append(cut[1])\n",
    "                    atoms_to_structure(cut[0], fname) \n",
    "        all_fnames.append(newfnames)\n",
    "        all_cuts.append(cutouts_apdb)\n",
    "        all_centers.append(centers_apdb)\n",
    "\n",
    "    return all_fnames, all_cuts, all_centers \n",
    "\n",
    "\n",
    "\n",
    "def amber(input_pdb):\n",
    "    skript = f\"\"\"source leaprc.protein.ff14SB\n",
    "    source leaprc.water.tip3p\n",
    "    loadOff \"/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\"\n",
    "    mol = loadpdb \"/Users/jessihoernschemeyer/pKaSchNet/cuts/{input_pdb}.pdb\"\n",
    "    savepdb mol \"/Users/jessihoernschemeyer/pKaSchNet/prot/{input_pdb}.pdb\"\n",
    "\n",
    "    quit\"\"\"\n",
    "    with open(\"ascript.py\",\"w\") as file: \n",
    "        file.writelines(skript)\n",
    "    return\n",
    "\n",
    "\n",
    "protonatable_sites2 = {\"G\":\"GLH\", \n",
    "                      \"C\":\"CYS\", \n",
    "                      \"L\":\"LYS\", \n",
    "                      \"A\":\"ASH\",\n",
    "                      \"H\": \"HIP\",\n",
    "                      \"T\": \"TYR\"\n",
    "                      \"X\": \"CTR\"\n",
    "                      \"N\": \"NTR\"}\n",
    "\n",
    "protonatable_sites = {\"G\":\"HE2\", \n",
    "                      \"C\":\"HG\", \n",
    "                      \"L\":\"HZ1\", \n",
    "                      \"A\":\"HD2\",\n",
    "                      \"H\": (\"HD1\",\"HE2\"), #this needs to be fixed \n",
    "                      \"T\": \"HH\"}\n",
    "\n",
    "def deprotonate_singles(cut, res): #turn one acidic into all its others? #NOT HIS!!!\n",
    "    \"\"\"Binary Situation\n",
    "    this function takes a cutout that is not merged / a single cutout, and the file name of that cutout. It gets the residue string name, and from that a string of the atom name of the hydrogen ion\n",
    "    that should be deleted. \n",
    "    ONE CCUT AT A TIME!\n",
    "    Then, found atoms is a list of all the atoms with that name e.g. \"OXT\" and the desired parent res (in the file name).\n",
    "    If the atom has the name and parent res name matching the file name information, then the atom is detached and then saved.\n",
    "    \n",
    "    This returns: ApBd or AdBp.\"\"\"\n",
    "\n",
    "#NORMAL CASE\n",
    "    try: #NORMAL. the atoms for x and n are not in the dictionary. \n",
    "        #res=A,T..\n",
    "        atom_to_delete = protonatable_sites[res] #ntr/ctr errors here\n",
    "        res = protonatable_sites2[res] #careful here\n",
    "\n",
    "        for residue in cut.get_residues():\n",
    "                if residue.get_name() == res:\n",
    "                    residue.detach_child(atom_to_delete)\n",
    "                    return cut\n",
    "                    \n",
    "#TERMINUS\n",
    "    except: #ter. \"PHE\" #CTR/NTR . input is \"PHE #need to consider that there might be two e.g. phe or met!!\n",
    "        if len(res) > 1: #his\n",
    "            for residue in cut.get_residues():\n",
    "                if residue.get_name() == \"HIP\":\n",
    "                    residue.detach_child(res) #res IS atom to delete for HIS!\n",
    "        \n",
    "        else: #ctr/ntr\n",
    "        deprotonate_terminus_single(cut, res)\n",
    "\n",
    "def deprotonate_terminus_single(cut, res):\n",
    "    \"\"\"Input: XPHE, NARG..\n",
    "    returns a deprotonated NTR or CTR\"\"\"\n",
    "    ter, resi = res[0], res[1:]\n",
    "    for residue in cut.get_residues():\n",
    "        if residue.get_name() == resi: \n",
    "            if res==\"X\": #CTR\n",
    "                atoms = residue.get_atoms()\n",
    "                try: \n",
    "                    residue.detach_child(\"OXT\")\n",
    "                    return cut \n",
    "                except:\n",
    "                    residue.detach_child(\"C\")\n",
    "                    return cut\n",
    "            else: #NTR \n",
    "                residue.detach_child(\"N\")\n",
    "                return cut\n",
    "\n",
    "def dp_GleichRes2Mal(cut, res): #doesnt take HHH or ters\n",
    "    \"returns two cuts, deprotonated of them both.\"\n",
    "    \n",
    "    found_atoms, dp_cuts =[],[]\n",
    "    atom_to_delete = protonatable_sites[res]\n",
    "\n",
    "    if type(atom_to_delete) == tuple: #histidine\n",
    "        for residue in cut.get_residues():\n",
    "            if residue.get_name() == \"HIP\":\n",
    "                for atom in residue.get_atoms():   \n",
    "                    atomname = atom.get_name()        \n",
    "                    if atomname in atom_to_delete:\n",
    "                        found_atoms.append((atomname, residue))\n",
    "        \n",
    "        found_atoms.sort() #will sort by letter and number \n",
    "        resA_del, resB_del, resA_eps, resB_eps = found_atoms[0], found_atoms[1], found_atoms[2], found_atoms[3]\n",
    "        \n",
    "        hipAhipB = cut.copy() \n",
    "        dp_cuts.append(hipAhipB, \"HIPHIP\")\n",
    "        #modify resA\n",
    "        resA_del[1].detach_child(resA_del[0]) #makes HIE res A, res B HIP\n",
    "        hieAhipB = cut.copy()\n",
    "        dp_cuts.append(hieAhipB, \"HIEHIP\") #HIE+HIp\n",
    "\n",
    "        resA_eps[1].detach_child(resA_eps[0]) #makes HIS res A, res B HIP\n",
    "        hisAhipB = cut.copy()\n",
    "        dp_cuts.append(hisAhipB, \"HISHIP\") #HIS+HIp\n",
    "\n",
    "        hidAhipB = hisAhipB.union(hipAhipB-hieAhipB)\n",
    "        dp_cuts.append(hidAhipB, \"HIDHIP\")\n",
    "\n",
    "        #modify residue b \n",
    "        resB_del[1].detach_child(resB_del[0]) #makes HIE res A, res B HIP\n",
    "        hisAhieB = cut.copy()\n",
    "        dp_cuts.append(hisAhieB, \"HISHIE\")\n",
    "\n",
    "        resB_eps[1].detach_child(resB_eps[0])\n",
    "        hisAhisB = cut.copy()\n",
    "        dp_cuts.append(hisAhisB, \"HISHIE\")\n",
    "\n",
    "        hisAhidB = hisAhisB.union(hisAhipB-hisAhieB)\n",
    "        dp_cuts.append(hisAhisB, \"HISHID\")\n",
    "        \n",
    "        #now make the rest \n",
    "        hipA_atoms = hipAhipB - hisAhipB \n",
    "        HIPHIE = hisAhieB.union(hipA_atoms) #arg is the atoms which make hip seperate from his\n",
    "        dp_cuts.append(HIPHIE, \"HIPHIE\")\n",
    "        HIPHID = hisAhidB.union(hipA_atoms)\n",
    "        dp_cuts.append(HIPHID, \"HIPHID\")\n",
    "        HIPHIS = hisAhisB.union(hipA_atoms)\n",
    "        dp_cuts.append(HIPHIS, \"HIPHIS\")\n",
    "        #HIEHIE = HIPHIE | hieAhipB\n",
    "        #HIEHID = HIPHID | hieAhipB\n",
    "        #HIEHIS = HIPHIS | hieAhipB\n",
    "        dp_cuts.append(HIPHIE | hieAhipB, \"HIEHIE\")\n",
    "        dp_cuts.append(HIPHID | hieAhipB, \"HIEHID\")\n",
    "        dp_cuts.apprnf(HIPHIS | hieAhipB,  \"HIEHIS\")\n",
    "\n",
    "        dp_cuts.append(HIPHIE | hidAhipB, \"HIDHIE\") \n",
    "        dp_cuts.append(HIPHID | hidAhipB, \"HIDHID\")\n",
    "        dp_cuts.append(HIPHIS | hidAhipB, \"HIDHIS\")\n",
    "\n",
    "    elif len(atom_to_delete) == 2: #nor his\n",
    "        Res = protonatable_sites2[res]\n",
    "        for residue in cut.get_residues():\n",
    "            if residue.get_name() == Res:\n",
    "                for atom in residue.get_atoms():           \n",
    "                    if atom.get_name() == atom_to_delete:\n",
    "                        found_atoms.append((residue, atom_to_delete))\n",
    "\n",
    "        #for two found atoms\n",
    "        resA, resB = found_atoms[0], found_atoms[1]\n",
    "        resA[0].detach_child(resA[1])\n",
    "        Adp = cut.copy()\n",
    "        #deprotonate cut fully by removing the other second residue\n",
    "        resB[0].detach_child(resB[1])\n",
    "        Bdp = cut.copy()\n",
    "\n",
    "        return Adp, resB\n",
    "\n",
    "def recut_and_deprotonate(fnames_apdb, centers_apdb, distance_cutoff): #the centers come in #fnames after protonation\n",
    "    \"\"\"\n",
    "    fnames_apdb [list]: [fname_cut1, fname_cut2, fname_cut3] --> resA &/OR resB\n",
    "                    Ex: ['199lA11_GLU3', '199lA10_ASP2_199lA161_TYR37_AT', '199lA70_ASP22_199lA31_HIS11.2_AH'] \n",
    "\n",
    "    This function takes in all the file names for a single pdb, as well as the centers of their titratable site (OXT, N, NE2, NH...). Using the fname, it\n",
    "    makes a cutout again using that center which was found before. \n",
    "    \n",
    "    If the cutout is merged, then there will be a multiple centers. Then, the cutout becomes the set of both cutoute (a sphere of distance_cutoff from the \n",
    "    protonatable site.)\"\"\"\n",
    "    for fname, center in zip(fnames_apdb, centers_apdb):\n",
    "        struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/{fname}.pdb')\n",
    "        ns = PDB.NeighborSearch(list(struct.get_atoms())) #set up ns , entire protein\n",
    "\n",
    "        #############MERGEDD#####\n",
    "        if type(center)==tuple: \n",
    "            f=fname.split(\"_\")\n",
    "            singles_res, key=f[1],f[4] #22X-PHE, AT, XASP\n",
    "            resA, resB = key[0],key[1] #A,T\n",
    "\n",
    "            #NTR/CTR (cannot combine NTR and CTR.) MERGED\n",
    "            if resA or resB in ('X', 'N'): #need to deal wih his in here???\n",
    "                if resA in ('X', 'N'): \n",
    "                    res1 = f[1].split(\"-\")\n",
    "                    cut = set(ns.search(center[0], distance_cutoff, \"A\")) | set(ns.search(center[1], distance_cutoff, \"A\")) #the merged cut\n",
    "                    Save(cut, fname) #fully protonated\n",
    "\n",
    "                else: #elif resB in ('X', 'N'):\n",
    "                    res2 = f[3].split(\"-\")\n",
    "                    cut = set(ns.search(center[0], distance_cutoff, \"A\")) | set(ns.search(center[1], distance_cutoff, \"A\")) #the merged cut\n",
    "                    Save(cut, fname) #fully protonated\n",
    "\n",
    "                resAdp = deprotonate_singles(resA+res1, cut.copy()) #xphe\n",
    "                Save(resAdp, fname + f'~{resA}d') #resA deprot, B prot\n",
    "\n",
    "                resBdp = deprotonate_singles(resB+res2, cut)\n",
    "                Save(resBdp, fname + f\"~{resB}d\") #A prot, resB deprot\n",
    "\n",
    "                deprotonated = set(resAdp) | set(resBdp)  #fully deprotonated #not making a new cut but combining what is done \n",
    "                Save(deprotonated, fname + \"~d\")\n",
    "\n",
    "            elif resA == resB: #no ntr and ctr will get here!\n",
    "                if resB == 'H' or resA=='H':  #double H\n",
    "                    his_cuts = dp_HH(\"H\", cut)\n",
    "                    for cut in his_cuts:\n",
    "                        Save(cut[0], fname + f'{cut[1]}')\n",
    "\n",
    "                else: #normal AA, GG..\n",
    "                  resAdp, resBdp = dp_GleichRes2Mal(cut, resA)   ##AA, GG... #res A is res B\n",
    "                Save(resAdp, fname + f'~{resA}d') #resA deprot, B prot\n",
    "                Save(resBdp, fname + f\"~{resB}d\") #A prot, resB deprot\n",
    "                Save(set(resBdp) | set(resAdp), fname + '~d')\n",
    "                \n",
    "            elif resB == 'H' or resA=='H': #histidine \n",
    "                    if resA == 'H': #1 his #HA\n",
    "                        HIE = deprotonate_singles(\"HD1\", cut.copy())\n",
    "                        Save(HIE, fname + '~HIE') #A, eps prot with B prot\n",
    "                        HID = deprotonate_singles(\"HE2\", cut.copy())\n",
    "                        Save(HID, fname + '~HID') #A, delta protonated\n",
    "                        HIS = deprotonate_singles(\"HD1\", HID.copy())\n",
    "                        Save(HIS, fname + '~HIS') #A fully deprotonated\n",
    "\n",
    "                        resBdp = deprotonate_singles(resB, cut.copy())\n",
    "\n",
    "                        #remaining combos with deprotonated other nonhis and nonter residue\n",
    "                        resBd_HIE = set(resBdp) | set(HIE) \n",
    "                        Save(resAd_HIE, fname + f'~{resB}d+HIE')\n",
    "                        resBd_HID = set(resBdp) | set(HID)\n",
    "                        Save(resAd_HID, fname + f'~{resB}d+HID')\n",
    "                        resBd_HIS = set(resBdp) | set(HIS)\n",
    "                        Save(resAd_HIS, fname + f'~{resB}d+HIS')\n",
    "                \n",
    "                    else: #ResB = H. then this means that the second res is the his. AH\n",
    "                        HIE = deprotonate_singles(\"HD1\", cut.copy())\n",
    "                        Save(HIE, fname + '~HIE') #HIE with A =HIP\n",
    "                        HID = deprotonate_singles(\"HE2\", cut.copy())\n",
    "                        Save(HID, fname + '~HID')\n",
    "                        HIS = deprotonate_singles(\"HD1\", HID.copy())\n",
    "                        Save(HID, fname + '~HIS') #fully deprotonated\n",
    "\n",
    "                        resAdp = deprotonate_singles(resA, cut.copy())\n",
    "\n",
    "                        #make combos with sets \n",
    "                        resAd_HIE = set(resAdp) | set(HIE) #after resA is already deprotonated\n",
    "                        Save(resAd_HIE, fname + f'~{resA}d+HIE')\n",
    "                        resAd_HID = set(resAdp) | set(HID)\n",
    "                        Save(resAd_HID, fname + f'~{resA}d+HID')\n",
    "                        resAd_HIS = set(resAdp) | set(HIS)\n",
    "                        Save(resAd_HIS, fname + f'~{resA}d+HIS')\n",
    "                        \n",
    "            else:  #normal merged\n",
    "                    cut = set(ns.search(center[0], distance_cutoff, \"A\")) | set(ns.search(center[1], distance_cutoff, \"A\")) #the merged cut\n",
    "                    Save(cut, fname) #fully protonated, both\n",
    "\n",
    "                    resAdp = deprotonate_singles(resA, cut.copy()) #resA = \"A\", \"G\". resAdp = a cut\n",
    "                    Save(resAdp, fname + f'~{resA}d') #resA deprot, B prot\n",
    "\n",
    "                    resBdp = deprotonate_singles(resB, cut.copy())\n",
    "                    Save(resBdp, fname + f\"~{resB}d\") #A prot, resB deprot\n",
    "\n",
    "                    deprotonated = set(resAdp) | set(resBdp)  #fully deprotonated #not making a new cut but combining what is done \n",
    "                    Save(deprotonated, fname + \"~d\")\n",
    "\n",
    "        else: #single\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            Save(cut, fname) #fully protonated\n",
    "\n",
    "            L = singles_res.split(\"-\")\n",
    "            if len(L)==2: #TER\n",
    "                 deprotonated = deprotonate_singles(cut, L[1]) #L[1] = \"PHE\"\n",
    "                 Save(deprotonated, fname + \"~D\")\n",
    "\n",
    "            else: \n",
    "                if len(L[0].dplit(\".\")) == 2: #HIS\n",
    "                    HIP=cut.copy()\n",
    "\n",
    "                    HIE = deprotonate_singles(cut, \"OD1\")\n",
    "                    Save(HIE, fname + \"HIE\")\n",
    "\n",
    "                    HIS = deprotonate_singles(HIE.copy(), \"OE2\")\n",
    "                    Save(HIS, fname + \"HIS\")\n",
    "                    \n",
    "                    Save(HIS.union(HIP - HIE), fname + \"HID\")\n",
    "                    \n",
    "                else: #regular\n",
    "                    deprotonated = deprotonate_singles(cut, fname.split(\"_\")[1][0]) #[A]SP22, [X]25PHE.. #not his\n",
    "                    Save(deprotonated, fname + \"~D\")\n",
    "            \n",
    "dask_df = read_database(local_folder + pkPDB_CSV)\n",
    "pdb_parser, pdbs = PDB.PDBParser(), list(OrderedSet(list(dask_df[\"PDB ID\"])))\n",
    "\n",
    "fs, all_cuts, all_centers = get_cutout(dask_df, 5)\n",
    "    \n",
    "for f in fs[0]:\n",
    "    amber(f)\n",
    "    !tleap -s -f /Users/jessihoernschemeyer/pKaSchNet/ascript.py\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
