{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "split_seed=0\n",
    "split_ratio = .5\n",
    "##for my architecture i dont trust batch size over one. but i think functionally it works fine. but it doesnt suit my purposes. that is why there is achtung. use it as you please with caution that\n",
    "#I never have used batch size more than one.\n",
    "\n",
    "#batch size of one = a batch of a whole protein. \n",
    "\n",
    "class HoodDS_from_npz(Dataset):\n",
    "    \"\"\"Generate hoods around n_neighbors, a hyperparameter. This choice determines how many n_nearest neighbors\n",
    "    the egnn encoder sees.\n",
    "    \n",
    "    This function takes as input the pdb.npz numpy files and returns an \"\"\"\n",
    "    def __init__(self, paths, n_neighbors, keep_ids=False): #keep ids doesnt work\n",
    "        self.data=[]; self.keep_ids = keep_ids; \n",
    "        nbr=NearestNeighbors(n_neighbors=n_neighbors,algorithm='brute')\n",
    "        for p in paths:\n",
    "            try:\n",
    "                d=np.load(p,allow_pickle=True)\n",
    "                if len(d['sites'])==0: continue\n",
    "                nbr.fit(d['pos']); idx=nbr.kneighbors(d['sites'],return_distance=False)\n",
    "                self.data.append((torch.from_numpy(d['z'][idx]),\n",
    "                                  torch.from_numpy(d['pos'][idx]),\n",
    "                                  torch.from_numpy(d['pks'])))\n",
    "                #self.ids.append(os.path.splitext(os.path.basename(p))[0])\n",
    "            except Exception as e: print(\"skip\",p,e)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        z,p,y=self.data[i]; \n",
    "        return z,p,y,self.ids[i] if self.keep_ids else z,p,y\n",
    "    def pad(batch,k,device):\n",
    "        #ids=[b[3] for b in batch] if keep_ids else None\n",
    "        B=len(batch); S=max(b[0].shape[0] for b in batch)\n",
    "        zt=torch.zeros(B,S,k,dtype=torch.int32,device=device)\n",
    "        pt=torch.zeros(B,S,k,3,dtype=torch.float32,device=device)\n",
    "        yt=torch.full((B,S),float('nan'),device=device); mt=torch.zeros(B,S,dtype=torch.bool,device=device)\n",
    "        for b,data in enumerate(batch):\n",
    "            z,p,y=data[0],data[1],data[2]\n",
    "            s=z.shape[0]; zt[b,:s]=z; pt[b,:s]=p; yt[b,:s]=y; mt[b,:s]=True\n",
    "        return (zt,pt,yt,mt) #if keep_ids else (zt,pt,yt,mt)\n",
    "\n",
    "    def split(paths):\n",
    "        \"\"\"deterministic and random #TODO tunable determinism\"\"\"\n",
    "        rng=np.random.RandomState(split_seed)\n",
    "        idx=rng.permutation(len(paths)); cut=int(len(paths)*split_ratio)\n",
    "        return [paths[i] for i in idx[:cut]], [paths[i] for i in idx[cut:]]\n",
    "    \n",
    "    \n",
    "def run_hoodDS(n_neighbors, INPUTS_DIR, num_paths):\n",
    "    if num_paths==\"all\":\n",
    "        num_paths=len(glob.glob(INPUTS_DIR))\n",
    "    coll = lambda b: HoodDS_from_npz.pad(b,n_neighbors,device)\n",
    "    tr,val=HoodDS_from_npz.split(sorted(glob.glob(INPUTS_DIR))[:num_paths])\n",
    "    train_ds=HoodDS_from_npz(tr, n_neighbors); val_ds=HoodDS_from_npz(val,\n",
    "                                                               n_neighbors)\n",
    "\n",
    "    tr_loader=DataLoader(train_ds,batch_size=1,shuffle=True,collate_fn=coll)#ACTHUNG: i dont trust batch size over 1 with this pad fn and ''  use AT OWN RISK.\n",
    "    val_loader=DataLoader(val_ds,batch_size=1,shuffle=False,collate_fn=coll) #i dont trust batch size over 1 with this pad fn and personally dont need it use at OWN RISK\n",
    "    return tr_loader, val_loader\n",
    "\n",
    "INPUTS_DIR=\"../../data/pkegnn_INS/inputs/*.npz\"\n",
    "tr_loader, va_loader = run_hoodDS(100,INPUTS_DIR,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 8,  6,  6,  ...,  6,  7,  6],\n",
      "         [ 8,  6,  8,  ...,  8,  6,  8],\n",
      "         [ 8,  6,  8,  ...,  7,  6,  6],\n",
      "         ...,\n",
      "         [ 8,  6,  8,  ...,  6,  8,  8],\n",
      "         [ 8,  6,  6,  ...,  6,  8,  6],\n",
      "         [ 8,  6,  8,  ..., 16,  8,  7]]], dtype=torch.int32), tensor([[[[68.0350, 91.7610, 38.6070],\n",
      "          [67.7180, 90.4250, 38.6710],\n",
      "          [66.6170, 89.9510, 37.9820],\n",
      "          ...,\n",
      "          [66.3630, 93.9870, 31.3450],\n",
      "          [66.6350, 85.7460, 33.8150],\n",
      "          [74.7650, 95.7110, 37.5800]],\n",
      "\n",
      "         [[73.6860, 76.4210, 42.9290],\n",
      "          [73.1790, 76.1190, 41.8240],\n",
      "          [73.8710, 75.8170, 40.8250],\n",
      "          ...,\n",
      "          [68.5280, 69.6540, 45.4050],\n",
      "          [75.9200, 70.7350, 36.4920],\n",
      "          [70.8710, 77.9780, 34.6550]],\n",
      "\n",
      "         [[77.3800, 78.2300, 20.2870],\n",
      "          [76.2080, 78.4030, 19.8910],\n",
      "          [75.7660, 79.5170, 19.5510],\n",
      "          ...,\n",
      "          [83.1160, 82.4470, 14.3880],\n",
      "          [82.7650, 76.5190, 27.6060],\n",
      "          [81.2420, 86.2180, 23.0960]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[62.2530, 60.1380, 31.0260],\n",
      "          [61.2760, 60.9130, 30.9760],\n",
      "          [60.5170, 60.9540, 29.9860],\n",
      "          ...,\n",
      "          [52.6540, 62.8760, 33.7690],\n",
      "          [70.6570, 66.2410, 30.1010],\n",
      "          [62.0780, 69.5360, 26.4600]],\n",
      "\n",
      "         [[69.7060, 67.5100, 32.2400],\n",
      "          [68.3550, 67.2860, 32.1530],\n",
      "          [67.5590, 67.5110, 33.2600],\n",
      "          ...,\n",
      "          [64.1610, 72.1780, 35.0160],\n",
      "          [75.7370, 69.5340, 36.7040],\n",
      "          [75.0140, 61.8660, 32.9320]],\n",
      "\n",
      "         [[62.0780, 69.5360, 26.4600],\n",
      "          [62.8340, 69.8170, 27.4170],\n",
      "          [64.0250, 69.4270, 27.4760],\n",
      "          ...,\n",
      "          [65.0460, 62.2560, 33.4890],\n",
      "          [72.5940, 69.5620, 25.5100],\n",
      "          [62.0340, 79.6700, 29.6270]]]]), tensor([[ 4.2709e+00, -3.8823e-01, -2.2926e+00, -1.1243e-01, -5.2718e-01,\n",
      "         -8.2562e-01,  8.1380e-01, -1.5420e+00, -8.4056e-01, -3.1853e+00,\n",
      "          1.6830e-02,  1.0785e+00, -9.7216e-01, -8.4491e-01, -9.5848e-01,\n",
      "          1.8845e+00, -9.4600e-02,  2.2548e-01,  1.0275e+00, -4.9883e-01,\n",
      "         -1.7150e-01, -8.3467e-01, -2.2908e+00,  2.9517e+00,  7.6820e-01,\n",
      "         -9.8878e-01,  8.0195e-01, -2.0774e-01, -5.3070e-02, -1.2166e-01,\n",
      "         -1.8178e-01, -2.0295e-01, -4.8179e+00,  9.5090e-02, -1.1645e+00,\n",
      "          2.9013e+00,  7.2000e-02, -3.5592e-01, -2.4793e-01,  4.5778e-01,\n",
      "          1.7930e-01, -4.5861e-01,  3.0800e-03,  6.1050e-01,  1.7841e+00,\n",
      "          8.4560e-02, -3.3480e-01, -4.7310e-02,  2.4920e-01,  1.9520e-01,\n",
      "          1.9790e-01, -1.9169e-01, -2.2637e+00, -5.7269e-01, -1.6538e+00,\n",
      "          1.8600e-01,  1.7135e-01, -1.0123e-01, -1.9053e-01,  9.5820e-01,\n",
      "         -2.0310e+00, -8.5935e-01,  9.9000e-03,  1.3455e+00, -1.4316e+00,\n",
      "         -2.3666e+00, -2.5311e+00, -9.3699e-01, -3.4932e+00,  3.2270e-01,\n",
      "         -1.4243e+00, -8.6058e-01, -1.0030e+00, -2.9706e-01, -3.2083e-01,\n",
      "         -3.3050e-02, -6.1597e+00, -1.1421e-01,  7.8600e-01,  1.7432e-01,\n",
      "         -2.1410e-01, -1.6770e-02, -3.7522e-01,  3.2084e-01, -2.4943e-01,\n",
      "          1.9310e-02,  2.8249e+00,  7.0280e-01, -1.9296e-01, -2.0982e+00,\n",
      "         -5.0868e-01,  1.4180e-01, -1.2519e+00,  1.2917e-01, -4.4833e-01,\n",
      "          6.2030e-01, -3.2170e-02, -1.3391e+00,  3.9591e+00,  5.9380e-01,\n",
      "          6.6914e-01,  2.9999e-01, -1.3891e+00, -1.9172e-01, -1.8998e-01,\n",
      "         -9.3550e-02, -5.0086e+00, -6.2780e-01,  2.2479e+00, -4.7110e-02,\n",
      "         -2.4052e+00, -6.7000e-03, -6.2720e-02, -1.8616e+00,  1.3130e-01,\n",
      "          2.1218e+00, -1.5560e-01,  4.7920e-01, -1.1390e+00,  3.6181e+00,\n",
      "          2.0535e+00, -3.4467e+00, -1.0810e+00, -5.5537e-01,  3.4157e+00,\n",
      "         -9.4000e-03]]), tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True]]))\n"
     ]
    }
   ],
   "source": [
    "for a in tr_loader:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([126, 100])\n",
      "torch.Size([126, 100, 3])\n",
      "torch.Size([126])\n"
     ]
    }
   ],
   "source": [
    "for z,x,y,m,*_ in tr_loader:\n",
    "    v=m.view(-1); z=z.view(-1,z.size(2))[v].to(device)\n",
    "    x=x.view(-1,x.size(2),3)[v].to(device); y=y.view(-1)[v].to(device)\n",
    "    print(z.shape)\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(loader):\n",
    "    for z,x,y,m,*_ in loader:\n",
    "        v=m.view(-1); z=z.view(-1,z.size(2))[v].to(device)\n",
    "        x=x.view(-1,x.size(2),3)[v].to(device); y=y.view(-1)[v].to(device)\n",
    "        #return z,x,y #Zs,coors,PK Shifts.\n",
    "        #here you put a model.\n",
    "        #preds = loop(x,z)\n",
    "        #loss(preds, y)\n",
    "run_model(tr_loader)\n",
    "run_model(va_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
