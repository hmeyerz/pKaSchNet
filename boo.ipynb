{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 15,\n",
       " 12,\n",
       " 21,\n",
       " 27,\n",
       " 15,\n",
       " 18,\n",
       " 22,\n",
       " 15,\n",
       " 12,\n",
       " 12,\n",
       " 9,\n",
       " 8,\n",
       " 28,\n",
       " 21,\n",
       " 18,\n",
       " 22,\n",
       " 18,\n",
       " 24,\n",
       " 20,\n",
       " 18,\n",
       " 25,\n",
       " 15,\n",
       " 22,\n",
       " 18,\n",
       " 21,\n",
       " 15,\n",
       " 21,\n",
       " 16,\n",
       " 18,\n",
       " 12,\n",
       " 27,\n",
       " 10,\n",
       " 31,\n",
       " 26,\n",
       " 13,\n",
       " 18,\n",
       " 17,\n",
       " 20,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 18,\n",
       " 23,\n",
       " 23,\n",
       " 17,\n",
       " 19,\n",
       " 12,\n",
       " 21,\n",
       " 24,\n",
       " 10,\n",
       " 19,\n",
       " 16,\n",
       " 12,\n",
       " 12,\n",
       " 39,\n",
       " 32,\n",
       " 21,\n",
       " 16,\n",
       " 22,\n",
       " 26,\n",
       " 26,\n",
       " 19,\n",
       " 18,\n",
       " 12,\n",
       " 19,\n",
       " 19,\n",
       " 23,\n",
       " 13,\n",
       " 16,\n",
       " 12,\n",
       " 22,\n",
       " 10,\n",
       " 14,\n",
       " 19,\n",
       " 10,\n",
       " 18,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 24,\n",
       " 22,\n",
       " 22]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import time\n",
    "import glob\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "to=time.time()\n",
    "\n",
    "fullcode={b\"HIS\":b\"0\",\n",
    "        b\"ASP\":b\"1\",\n",
    "        b\"LYS\":b\"2\",\n",
    "        b\"TYR\":b\"3\",\n",
    "        b\"GLU\":b\"4\",\n",
    "        b\"CYS\":b\"5\"}\n",
    "code={b\"H\":b\"0\",\n",
    "        b\"A\":b\"1\",\n",
    "        b\"L\":b\"2\",\n",
    "        b\"T\":b\"3\",\n",
    "        b\"G\":b\"4\",\n",
    "        b\"C\":b\"5\"}\n",
    "elements = {\n",
    "    b\"D\":1, b\"H\": 1, b\"LI\":3, b\"C\": 6, b\"N\": 7, b\"O\": 8, \n",
    "    b\"F\":9,\n",
    "    b\"NA\": 11, b\"MG\": 12,  b\"P\": 15, b\"S\": 16, b\"CL\": 17, b\"K\": 19,\n",
    "    b\"CA\": 20, b\"MN\": 25, b\"FE\": 26, b\"CO\":27, b\"NI\":28,\n",
    "    b\"CU\": 29, b\"ZN\": 30,\n",
    "    b\"SE\":34,\n",
    "    b\"MO\":42, b\"SN\":50, \n",
    "    b\"I\":53, b\"CS\":55,\n",
    "    b\"W\":74, b\"PT\":78\n",
    "    }\n",
    "elements={k.decode() :np.int32(v) for k,v in elements.items()}\n",
    "\n",
    "class pkparser():\n",
    "    \"\"\"#TODO save terminus files\n",
    "    last id full path include dir. assumed XXXpdb.gz as is gotten from RCSB.\"\"\"\n",
    "    \"\"\"it was necessary to use numpy, because I cant make jagged tensors.\"\"\"\n",
    "    def __init__(self,gzipped_pdb,cutoff):\n",
    "        self.path = gzipped_pdb#\"/Users/jessihoernschemeyer/pKaSchNet/pkas.csv\" #('/content/drive/MyDrive/pkas.csv') #3directory\n",
    "        self.pdb = gzipped_pdb[-11:-7]\n",
    "        self.targets=np.load(f\"/home/jrhoernschemeyer/Desktop/data_prep/targets/{self.pdb}.npz\")\n",
    "        self.cutoff=cutoff #Angstrom\n",
    "        self.ligands=np.load(\"ligands.npz\")[\"data\"]\n",
    "\n",
    "    def parse_titratable_lines(self,lines):\n",
    "        \"\"\"get info from asp,glu,his,cys,tyr. removes hydrogens, skips insertion codes, takes most probable config or \"A\" if 50-50.\"\"\"\n",
    "        pdbspecies, pdbcoors,terminus_lines=[],[],[]\n",
    "        species,coors,line,lastresi,strii=None,None,None,None,None\n",
    "        \n",
    "        while lines:\n",
    "            stri=lines[0]\n",
    "            if not stri[0:1] == b\"H\":\n",
    "                #alt conformations\n",
    "                if not np.char.isspace(stri[3:4]):\n",
    "                    strii=lines[1]\n",
    "                    stri1,stri2=stri[43:47], strii[43:47]\n",
    "                    if np.char.greater_equal(stri1,stri2):\n",
    "                        resi=stri[4:14]\n",
    "                        resinum=resi[5:].strip()\n",
    "\n",
    "                        #insertion\n",
    "                        if not resinum.isdigit(): \n",
    "                            self.others.append(lines[0])\n",
    "                            del lines[0]\n",
    "                            self.others.append(lines[0])\n",
    "                            del lines[0]\n",
    "                            strii=None\n",
    "                            #TODO: put them in all_other_coors\n",
    "                            continue \n",
    "                        \n",
    "                        #continuing resi\n",
    "                        if resinum==lastresi:\n",
    "                            line, lastresi=stri,resinum\n",
    "                            species.append(elements[list(filter(str.isalpha, line[-4:].decode()))[0]])\n",
    "                            coors.append((np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41])))\n",
    "                            del lines[0]\n",
    "                            del lines[0]\n",
    "                        else: #newresi\n",
    "                            pdbspecies.append(np.array(species))\n",
    "                            pdbcoors.append(np.array(coors))\n",
    "                            terminus_lines.append(line)\n",
    "                            line,lastresi=stri,resi\n",
    "                            species=[elements[list(filter(str.isalpha, line[-4:].decode()))[0]]]\n",
    "                            coors=[(np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41]))]\n",
    "                            lastresi=resinum\n",
    "                            del lines[0]\n",
    "                            del lines[0]\n",
    "                            strii=None     \n",
    "\n",
    "                    else:\n",
    "                            #B is greater\n",
    "                        resi=strii[4:14]\n",
    "                        resinum=resi[5:].strip()\n",
    "                        if not resinum.isdigit(): #INSERT\n",
    "                            self.others.append(lines[0])\n",
    "                            del lines[0]\n",
    "                            self.others.append(lines[0])\n",
    "                            del lines[0]\n",
    "                            continue\n",
    "\n",
    "                        if resinum==lastresi:\n",
    "                            line, lastresi=strii,resinum\n",
    "                            species.append(elements[list(filter(str.isalpha, line[-4:].decode()))[0]])\n",
    "                            coors.append((np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41])))\n",
    "                            del lines[0]\n",
    "                        else:  #newresi\n",
    "                            pdbspecies.append(np.array(species))\n",
    "                            pdbcoors.append(np.array(coors))\n",
    "                            terminus_lines.append(line)\n",
    "                            line=strii\n",
    "                            strii=None\n",
    "                            species=[elements[list(filter(str.isalpha, line[-4:].decode()))[0]]]\n",
    "                            coors=[(np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41]))]\n",
    "                            lastresi=resinum\n",
    "                            del lines[0]\n",
    "\n",
    "                #normal run\n",
    "                else:\n",
    "                    resi=stri[4:14]\n",
    "                    resinum=resi[5:].strip()\n",
    "                    if not resinum.isdigit(): #INSERTion\n",
    "                        self.others.append(lines[0])\n",
    "                        del lines[0]\n",
    "                        self.others.append(lines[0])\n",
    "                        del lines[0]\n",
    "\n",
    "                    if resinum==lastresi:\n",
    "                        line,lastresi=stri,resinum\n",
    "                        species.append(elements[list(filter(str.isalpha, line[-4:].decode()))[0]])\n",
    "                        coors.append((np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41])))\n",
    "                        del lines[0]\n",
    "                    else: #newresi\n",
    "                        pdbspecies.append(np.array(species))\n",
    "                        pdbcoors.append(np.array(coors))\n",
    "                        terminus_lines.append(line)\n",
    "                        line,lastresi=stri,resinum\n",
    "                        species=[elements[list(filter(str.isalpha, line[-4:].decode()))[0]]]\n",
    "                        coors=[(np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41]))]\n",
    "                        lastresi=resinum\n",
    "                        del lines[0]\n",
    "            else: #hydrogens-skip\n",
    "                del lines[0]\n",
    "                continue\n",
    "\n",
    "            \n",
    "                     \n",
    "        pdbspecies.append(np.array(species))\n",
    "        pdbcoors.append(np.array(coors))\n",
    "        terminus_lines.append(line)\n",
    "        #TODO save terminus lines\n",
    "        self.terminus_lines = terminus_lines[1:]\n",
    "        self.ids=[np.char.add(np.char.add(np.char.strip(b[-5:]),b[-6:-5]),code[b[4:5]]) for b in [t[:14] for t in terminus_lines[1:]]]\n",
    "        #return np.array(pdbspecies,dtype=object), np.array(pdbcoors,dtype=object)\n",
    "        return pdbspecies, pdbcoors\n",
    "    \n",
    "    def aggregate_others(self):\n",
    "        \"\"\"#TODO\"\"\"\n",
    "        #def stack_columns(data):\n",
    "        \"\"\"\n",
    "        data: list of (int_arr, coord_arr) tuples, where\n",
    "        - int_arr is either a 1D np.ndarray of ints or an object array of int sub-arrays\n",
    "        - coord_arr is either a 2D np.ndarray of shape (M,3) or an object array of 2D sub-arrays\n",
    "        Returns:\n",
    "        - all_ints: 1D np.ndarray of all ints concatenated\n",
    "        - all_coords: 2D np.ndarray of shape (total_rows, 3)\n",
    "        \"\"\"\n",
    "        int_chunks = []\n",
    "        coord_chunks = []\n",
    "\n",
    "        for int_arr, coord_arr in self.others:\n",
    "            # collect ints\n",
    "            if int_arr.dtype == object:\n",
    "                # flatten object-array of int sub-arrays\n",
    "                for sub in int_arr:\n",
    "                    int_chunks.append(np.ravel(sub))\n",
    "            else:\n",
    "                int_chunks.append(int_arr.ravel())\n",
    "\n",
    "            # collect coords\n",
    "            if coord_arr.dtype == object:\n",
    "                # flatten object-array of 2D sub-arrays\n",
    "                for sub in coord_arr:\n",
    "                    coord_chunks.append(sub)\n",
    "            else:\n",
    "                coord_chunks.append(coord_arr)\n",
    "\n",
    "        all_ints   = np.concatenate(int_chunks, axis=0)\n",
    "        all_coords = np.concatenate(coord_chunks, axis=0)\n",
    "        return all_ints, all_coords\n",
    "\n",
    "    def parse_ligands(self,lines):\n",
    "            \"\"\"parse ligands #TODO\"\"\"\n",
    "            species,coors=[],[]\n",
    "            lines=[line[13:] for line in lines if line[16:20].strip() in self.ligands] \n",
    "            while lines:\n",
    "                line=lines[0]\n",
    "                if not line[0:1] == b\"H\":\n",
    "                    #alt conformations\n",
    "                    if np.char.isspace(line[3:4]):\n",
    "                        strii=lines[1]\n",
    "                        stri1,stri2=line[43:47], strii[43:47]\n",
    "                        if np.char.greater_equal(stri1,stri2):\n",
    "                            species.append(elements[list(filter(str.isalpha, line[-4:].decode()))[0]])\n",
    "                            coors.append((np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41])))\n",
    "                            del lines[0]\n",
    "                            del lines[0]\n",
    "                              \n",
    "\n",
    "                        else: \n",
    "                                #B is greater\n",
    "                            species.append(elements[list(filter(str.isalpha, line[-4:].decode()))[0]])\n",
    "                            coors.append((np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41])))\n",
    "                            del lines[0]\n",
    "\n",
    "\n",
    "                    #normal run\n",
    "                    else:\n",
    "                        species.append(elements[list(filter(str.isalpha, line[-4:].decode()))[0]])\n",
    "                        coors.append((np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41])))\n",
    "                        del lines[0]\n",
    "                else: #hydrogens-skip\n",
    "                    del lines[0]\n",
    "                    continue\n",
    "\n",
    "            self.others.append((np.array(species),np.array(coors)))\n",
    "\n",
    "            #print(3,species,coors)\n",
    "   \n",
    "    def parse_others(self,lines):\n",
    "        \"\"\"\"\"\"\n",
    "        species,coors=[],[]\n",
    "        #ligands=np.load(\"ligands.npz\")[\"data\"]\n",
    "        lines=[line[13:] for line in lines] \n",
    "        while lines:\n",
    "            line=lines[0]\n",
    "            if not line[0:1] == b\"H\":\n",
    "                #alt conformations\n",
    "                if np.char.isspace(line[3:4]):\n",
    "                    strii=lines[1]\n",
    "                    stri1,stri2=line[43:47], strii[43:47]\n",
    "                    if np.char.greater_equal(stri1,stri2):\n",
    "                        species.append(elements[list(filter(str.isalpha, line[-4:].decode()))[0]])\n",
    "                        coors.append((np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41])))\n",
    "                        del lines[0]\n",
    "                        del lines[0]\n",
    "                            \n",
    "\n",
    "                    else: \n",
    "                            #B is greater\n",
    "                        species.append(elements[list(filter(str.isalpha, line[-4:].decode()))[0]])\n",
    "                        coors.append((np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41])))\n",
    "                        del lines[0]\n",
    "\n",
    "\n",
    "                #normal run\n",
    "                else:\n",
    "                    species.append(elements[list(filter(str.isalpha, line[-4:].decode()))[0]])\n",
    "                    coors.append((np.float32(line[17:25]),np.float32(line[25:33]),np.float32(line[33:41])))\n",
    "                    del lines[0]\n",
    "            else: #hydrogens-skip\n",
    "                del lines[0]\n",
    "                continue\n",
    "\n",
    "        self.others.append((np.array(species),np.array(coors)))\n",
    "\n",
    "        #print(3,species,coors)\n",
    "   \n",
    "    def parse_pdb(self):\n",
    "        \"\"\"to do try except re: encoding/gzipped\"\"\"\n",
    "        with gzip.open(self.path, \"r\") as f:\n",
    "            lines=np.char.array(f.readlines())\n",
    "            f.close()\n",
    "        #encode everything if user didnt gzip their filess\n",
    "\n",
    "        #run\n",
    "       \n",
    "        lines=np.char.array([line for line in lines if np.char.startswith(line,[b\"ATOM\",b\"HETATM\"]).any()])\n",
    "        print(len(lines))\n",
    "        hets=[(i,line) for i,line in enumerate(lines) if np.char.startswith(line,b\"HETATM\")]\n",
    "        lines=np.delete(lines,[idx[0] for idx in hets])\n",
    "        self.parse_ligands([a[1] for a in hets])\n",
    "        #lines=np.char.array([line for line in lines if np.char.startswith(line,b\"ATOM\")])#for line in lines if np.char.startswith(line,\"ATOM\")])\n",
    "        tlines=[(i,line[13:]) for i,line in enumerate(lines) if line[16:20].strip() in fullcode.keys()]\n",
    "        self.parse_others(np.delete(lines,[idx[0] for idx in tlines]))\n",
    "        #tlines=[line[1] for line in tlines]\n",
    "        pdbspecies,pdbcoors=self.parse_titratable_lines([line[1] for line in tlines])\n",
    "        \n",
    "        #self.parse_regular_lines()\n",
    "\n",
    "\n",
    "        return np.array(pdbspecies[1:],dtype=object), np.array(pdbcoors[1:],dtype=object)\n",
    "    \n",
    "\n",
    "    def hoods(self,coors,species):\n",
    "        others=self.aggregate_others()\n",
    "        all_coors=np.vstack([*coors,others[1]])\n",
    "        neigh = NearestNeighbors(algorithm=\"brute\")\n",
    "        neigh.fit(all_coors)\n",
    "        idxs,last=[],0\n",
    "        for z in species:\n",
    "            idxs.append(len(z) + last - 1)\n",
    "            last=idxs[-1]\n",
    "        nbrs = neigh.radius_neighbors(all_coors[idxs],radius=self.cutoff, return_distance=False)\n",
    "        \n",
    "        species=np.concatenate([*[*species, others[0]]]) #allspecoes\n",
    "        return [species[n_ixs] for n_ixs in nbrs], [all_coors[n_ixs].astype(np.float32) for n_ixs in nbrs]\n",
    "    \n",
    "    \n",
    "    def get_disulfides(self,terminus_lines):\n",
    "        \"\"\"#TODO check for sulfur?\"\"\"\n",
    "\n",
    "        cys_lines = [(i,line) for i,line in enumerate(terminus_lines) if line[4:5] == b\"C\"]\n",
    "        cys_coors = [(np.float32(line[1][17:25]),np.float32(line[1][25:33]),np.float32(line[1][33:41])) for line in cys_lines] #TODO confirm its S?\n",
    "\n",
    "        neigh = NearestNeighbors(algorithm=\"brute\")\n",
    "        neigh.fit(cys_coors)\n",
    "        nbrs = neigh.radius_neighbors(cys_coors,radius=2.05, return_distance=False)\n",
    "        bridges = (np.array([cys[0] for cys in cys_lines]),np.array([len(a) == 2 for a in nbrs]))\n",
    "        self.disulfides=bridges[0][bridges[1]]\n",
    "        \n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"TODO save terminus lines\"\"\"\n",
    "        self.others=[]\n",
    "\n",
    "        #get structures of titratable residues\n",
    "        species,coors=self.parse_pdb()\n",
    "        #parseligands\n",
    "\n",
    "        #get targets\n",
    "        pkpdb=self.targets\n",
    "        ids, pidx, midx = np.intersect1d(pkpdb[\"ids\"], self.ids,return_indices=True)\n",
    "\n",
    "        #get unmatched structures\n",
    "        mask = np.ones(len(self.ids), dtype=bool)\n",
    "        mask[midx] = False\n",
    "        if mask.any():\n",
    "            self.others.append((species[mask], coors[mask]))\n",
    "        \n",
    "        #disulfide mask\n",
    "        self.get_disulfides(self.terminus_lines) #TODO Integrate with all_non_tit_coors matrix machen\n",
    "\n",
    "        if self.disulfides.any(): \n",
    "            sulf=self.disulfides\n",
    "            #delete from ids\n",
    "            self.ids=np.delete(self.ids,self.disulfides)\n",
    "            #save other lines\n",
    "            self.others.append((species[sulf], coors[sulf]))\n",
    "      \n",
    "        \n",
    "        #get titratable cuts with labeled structures\n",
    "        #TODO put other atoms and ligands in\n",
    "        species,coors=self.hoods(coors[midx],species[midx])\n",
    "\n",
    "\n",
    "        #save input\n",
    "        np.savez_compressed(f\"/home/jrhoernschemeyer/Desktop/data_prep/{self.pdb}.npz\",z=species, pos=coors, pks=pkpdb[\"pks\"][pidx],ids=ids)\n",
    "\n",
    "        return self\n",
    "        #except:\n",
    "        #\"zip the pdb or find pdb code somehow else lol or seperate home dir from after\"\n",
    "        \n",
    "me=pkparser(gzipped_pdb=f\"/home/jrhoernschemeyer/Desktop/data_prep/structures/pdbs/4b00.pdb.gz\",cutoff=5).run()\n",
    "[len(x) for x in np.load(\"/home/jrhoernschemeyer/Desktop/data_prep/4b00.npz\",allow_pickle=True)[\"z\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/jrhoernschemeyer/Documents/lig2pdb.lst\", \"r\") as f:\n",
    "    lines=np.char.encode(np.char.array(f.readlines()))\n",
    "    \n",
    "c=[b.strip() for b in lines if not np.char.startswith(b,b\" \")]\n",
    "ligands = set().union(*[*[set(a.split(b\"-\")) for a in c]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chararray([b'56X', b'6B9', b'8O4', ..., b'B19', b'42G', b'XZY'],\n",
       "          dtype='|S9')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.char.array(list(ligands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"ligands.npz\",data=np.char.array(list(ligands)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
