{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBList\n",
    "from Bio.PDB import *\n",
    "import pandas as pd\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf) #1000 is default\n",
    "import random\n",
    "import math\n",
    "from IPython.display import display, HTML\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28020c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PANDAS DATAFRAME PRODUCTION CELL FOR PKAD\n",
    "\n",
    "def input_df(external_file_name):\n",
    "\n",
    "#load the PKAD csv into pandas \n",
    "    df = pd.read_csv(external_file_name) \n",
    "\n",
    "#extract the needed info from the PKAD csv\n",
    "    df = df[[\"PDB ID\",\"Res ID\",\"Res Name\", \"Expt. pKa\"]]\n",
    "\n",
    "#get rid of the N/A values (For Jesse: they are N/A because the CSV has an empty cell where the Res ID should be)\n",
    "    df=df.dropna(ignore_index=True)\n",
    "\n",
    "#make an identifier \n",
    "    ID=[]\n",
    "    for i in range(len(df)):\n",
    "        pdb=str.lower(df.iloc[i]['PDB ID'])\n",
    "        res_n=str(math.trunc(df.iloc[i]['Res ID']))\n",
    "        res=str(df.iloc[i]['Res Name'])\n",
    "        ids=\"-\".join([pdb,res,res_n]) #combine with a hyphen\n",
    "        ID=np.append(ID,ids) #array with the unique IDs\n",
    "    \n",
    "#add identifier array to df\n",
    "    col = 'ID' #column name\n",
    "    df[col] = ID #adding array\n",
    "    \n",
    "    df = df.rename(columns={'Expt. pKa': 'pKa'})\n",
    "\n",
    "    return df\n",
    "#inputdf=input_df(\"/Users/jessihoernschemeyer/Desktop/Thesis/WT_pka.csv\")\n",
    "#display(HTML(inputdf.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pypka/pkPDB dataframe production\n",
    "\n",
    "def input_pkPDB_df(csv_file):\n",
    "    df = pd.read_csv(csv_file, nrows=100, delimiter=\";\") [[\"idcode\",\"residue_name\",\"residue_number\", \"pk\"]]\n",
    "\n",
    "\n",
    "\n",
    "#make an identifier \n",
    "    ID=[]\n",
    "    for i in range(len(df)):\n",
    "        pdb=str(df.iloc[i]['idcode'])\n",
    "        res_n=str(df.iloc[i]['residue_number'])\n",
    "        res=str(df.iloc[i]['residue_name'])\n",
    "        ids=\"-\".join([pdb,res,res_n]) #combine with a hyphen\n",
    "        ID=np.append(ID,ids) #array with the unique IDs\n",
    "    \n",
    "#add identifier array to df\n",
    "    col = 'ID' #column name\n",
    "    df[col] = ID #adding array\n",
    "    \n",
    "    \n",
    "#rename columns to match df from pkad \n",
    "    df = df.rename(columns={'idcode': 'PDB ID', 'residue_number': 'Res ID', 'residue_name': 'Res Name', 'residue_number': 'Res ID', 'pk': 'pKa'})\n",
    "\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7539397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run this cell if you want to download pdb files..\n",
    "\n",
    "def download_pdbs(df):\n",
    "#get an unordered list of the pdbs in order to download them\n",
    "    matrix = df[df.columns[0]]\n",
    "    PDB_list = matrix.tolist()\n",
    "    PDB_list=list(set(PDB_list)) \n",
    "\n",
    "\n",
    "#download the pdbs\n",
    "    pdbl = PDBList()\n",
    "    for i in PDB_list:\n",
    "        pdbl.retrieve_pdb_file(i,pdir='PDB',file_format = 'pdb')\n",
    "\n",
    "\n",
    "download_pdbs(input_df(\"/Users/jessihoernschemeyer/Desktop/Thesis/WT_pka.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batches(input_df):\n",
    "    #this function generates the atom information about the neighborhood of a titratable residue which is retrieved\n",
    "    #from inputted data. It then adds the pdb name and pka value of the titratable residue for which the atoms belong\n",
    "    #to, to the new dataframe, which becomes the new main dataframe. \n",
    "    #each new df made in this function corresponds to 1 row on the original/input/old df.\n",
    "    \n",
    "#get pdb name from input df to put into mda.\n",
    "    pdb_res=input_df #just me being lazy, ignore..\n",
    "    \n",
    "    df_list=[]\n",
    "    \n",
    "    for i in range(1): #range(len(pdb_res)) #change this when Pypka storage issue is fixed! TODO\n",
    "        x=[]\n",
    "        y=[]\n",
    "        z=[]\n",
    "    \n",
    "        pdbname=str.lower(pdb_res.iloc[i]['PDB ID']) #zooming into pdb name\n",
    "        #For Jesse: file name needs manual change of everything preceding {} for code to work\n",
    "        pdb_file = \"/Users/jessihoernschemeyer/PDB/pdb{}.ent\".format(pdbname) \n",
    "    \n",
    "#make mda universe with the pdb\n",
    "        u = mda.Universe(pdb_file)\n",
    "\n",
    "#get resids in format for mda to read.\n",
    "\n",
    "        if bool(isinstance(pdb_res.iloc[1]['Res ID'], float) == True): #because pkPDB is already a truncated integer. \n",
    "            val=math.trunc(pdb_res.iloc[i]['Res ID']) \n",
    "        else:\n",
    "            val=pdb_res.iloc[i]['Res ID'] \n",
    "        \n",
    "        \n",
    "        resid_in=\"resid {}\".format(val) #string in string\n",
    "\n",
    "\n",
    "#zooming into residue of 1 pdb: selects the atoms of the residue given by res id above and makes an atom group.\n",
    "        res_atoms=u.select_atoms(resid_in) #makes an mda atom group. ORDER NOT PRESERVED AND DUPLICATES REMOVED FOR AGs\n",
    "\n",
    "#get atoms in distance of residue we are focusing on\n",
    "        string_nahe='around 10 {}'.format(resid_in) #all atoms around the word after the number, which is the cutoff distance\n",
    "        nahe=u.select_atoms(string_nahe) #atom group \n",
    "\n",
    "#make a residue group of residues which are within the atom group of atoms in the vicinity of the t. residue.\n",
    "        residues = nahe.residues #vicinity residues\n",
    "    \n",
    "#get the vicinity residues' names \n",
    "        res_name = residues.atoms.resnames\n",
    "    \n",
    "#get the vicinity residues' residue number\n",
    "        res_ids = residues.atoms.resids\n",
    "    \n",
    "#get atom NAMES of atoms in (each) vicinity residue  \n",
    "        atomname = residues.atoms.names \n",
    "    \n",
    "#get the positions of atoms in (each) vicinity residue\n",
    "        positions=residues.atoms.positions\n",
    "\n",
    "#seperate them into x, y, and z coordinate arrays for easier processing into the df\n",
    "        for j in range(len(positions)):\n",
    "\n",
    "    #x coordinate, 1 atom, 1 residue\n",
    "            x=np.append(x,positions[j,0]) #goes through each atom of 1 pdb file and takes the x coordinate. \n",
    "            \n",
    "        \n",
    "        #pdb_res[column_name_x] = x #adds the x position as a column to the df.\n",
    "    \n",
    "    #y coordinate\n",
    "\n",
    "            y=np.append(y,positions[j,1])\n",
    "        #pdb_res[column_name_y] = y\n",
    "\n",
    "    #z coordinate\n",
    "\n",
    "            z=np.append(z,positions[j,2])\n",
    "        \n",
    "#get pka values\n",
    "        pka = pdb_res.iloc[i]['pKa']\n",
    "\n",
    "#make a dataframe of the neighborhood information\n",
    "        df = pd.DataFrame({\"PDB\": pdbname,\n",
    "                    \"Res Name\": res_name,\n",
    "                    \"Res No\": res_ids,\n",
    "                    \"pKa\": pka,\n",
    "                    \"Atom Name\": atomname,\n",
    "                    \"x\": x,\n",
    "                    \"y\":y,\n",
    "                    \"z\":z\n",
    "                          })\n",
    "\n",
    "#name each df (mini batch) with the name of the unique identifier from the imported df.\n",
    "        df.name = str((pdb_res.iloc[i]['ID']))\n",
    "\n",
    "#makes the index column name = the identifer for which the neighborhood information belongs to    \n",
    "        df.index.name = df.name\n",
    "    \n",
    "#sort res name alphabetically \n",
    "        df = df.sort_values('Res Name')\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df.rename(columns={'Res Name': 'Res_Name'})\n",
    "        \n",
    "#add each df, which represents the information about the neighborhood of the titratable residue, to a list\n",
    "        df_list.append(df) #append a list\n",
    "    \n",
    "#prepare residue name list for eventual export...\n",
    "        resnames_set=list(set(res_name))\n",
    "        \n",
    "#TODO: make a check such that the number of rows in original input data frame = the length of df_list.  \n",
    "    \n",
    "\n",
    "    return df_list, resnames_set #df_list is a list of all the mini batches / new data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817addb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkPDB\n",
    "input_df_pkPDB=input_pkPDB_df(\"/Users/jessihoernschemeyer/Downloads/pkas.csv\")\n",
    "\n",
    "#for Jesse (& Jessi) to download 1 pdb\n",
    "pdbl = PDBList()\n",
    "pdbl.retrieve_pdb_file(\"2bb7\",pdir='PDB',file_format = 'pdb')\n",
    "\n",
    "#run the function for the data from pkPDB\n",
    "df_pkPDB, resnames_pkPDB = mini_batches(input_df_pkPDB) \n",
    "\n",
    "#display first (only) mini batch\n",
    "df_pkPDB[0]\n",
    "\n",
    "#optional: unhash to see full table\n",
    "#display(HTML(df_pkPDB[0].to_html()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get the atom types from charmm topology file\n",
    "rtf = \"/Users/jessihoernschemeyer/pKaSchNet/rtf/top_all36_prot.rtf\"\n",
    "with open(rtf, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "def partial_charges(text, df):\n",
    "\n",
    "    n_dup=0\n",
    "    reslist=list(df['Res_Name'])\n",
    "    final_name=df.Res_Name[len(df)-1]\n",
    "    final_n=reslist.count(final_name)\n",
    "    for i in range(len(df)-final_n-1):\n",
    "            if i+n_dup - 1 == len(df):\n",
    "                break\n",
    "            name=df.Res_Name[i+n_dup] #we are iterating down the list of resnames. gets the res name\n",
    "            n_dup=reslist.count(name) #number we skip by at the end.\n",
    "\n",
    "     \n",
    "    \n",
    "#parsing the rtf file...\n",
    "\n",
    "    #isolate the part of the topology file which is the partial charges\n",
    "            index1 = text.find(name)\n",
    "            index2 = text.find(\"BOND\",index1)\n",
    "            string=text[index1:index2]\n",
    "        \n",
    "    #turn the long string into a list of strings\n",
    "            listtt=re.split(r'\\s',string)\n",
    "            \n",
    "    #remove empty entries\n",
    "            listtt = [x for x in listtt if x.strip()]\n",
    "\n",
    "\n",
    "      \n",
    "    #get partial charges \n",
    "            charges=[]\n",
    "            listt=listtt\n",
    "            while len(listt) >= 4: #3 is the size the information i am extracting from the list of strings\n",
    "                if listt.count(\"ATOM\") == 0:\n",
    "                    break\n",
    "                index = listt.index(\"ATOM\")\n",
    "                \n",
    "                charge = listt[index+1:index+4] #gets the atom name, atom type, and partial charge \n",
    "                charges.append(charge)\n",
    "    #delete the charge which was just stored, from the list we are extracting info from\n",
    "                listt=listt[index+4:len(string)]\n",
    "\n",
    "\n",
    "            dict1 = {}\n",
    "            dict2 = {}\n",
    "            keys = []\n",
    "            types=[]\n",
    "            partials=[]\n",
    "#make the keys, aka the atom names\n",
    "            for i in range(len(charges)):\n",
    "                key = charges[i][0]\n",
    "                keys.append(key)\n",
    "\n",
    "#get the atom type (vals for dic 1)\n",
    "            for i in range(len(charges)):\n",
    "                atype = charges[i][1]\n",
    "                types.append(atype)\n",
    "\n",
    "        \n",
    "        \n",
    "#get partial charge (vals for dic 2)\n",
    "            for i in range(len(charges)):\n",
    "                partial = charges[i][2]\n",
    "                partials.append(partial)\n",
    "\n",
    "        #make the dictionaries\n",
    "            dict_types  = { keys[j] : types[j] for j in range(len(keys)) }\n",
    "            dict_partials = { keys[j] : partials[j] for j in range(len(keys)) }\n",
    "\n",
    "            if keys.count(\"CD\") > 0: #charm uses cd for atom name cd1 so i need to add a dict entry\n",
    "                cd_type=dict_types[\"CD\"] #retrieve value\n",
    "                cd_charge=dict_partials[\"CD\"]\n",
    "                dict_partials[\"CD1\"]=cd_charge #add entry to dict\n",
    "                dict_types[\"CD1\"]=cd_type\n",
    "\n",
    "        #mapping to atom name in pandas\n",
    "            df.loc[df.Res_Name==name, 'Atom Type'] = df[\"Atom Name\"].map(dict_types)\n",
    "            df.loc[df.Res_Name==name, 'Partial Charge'] = df[\"Atom Name\"].map(dict_partials)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return df\n",
    "dff=df_pkPDB[0]\n",
    "dfpkPDB = partial_charges(text,dff)\n",
    "display(HTML(dfpkPDB.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1216ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PKAD\n",
    "input_df_PKAD=input_df(\"/Users/jessihoernschemeyer/Desktop/Thesis/WT_pka.csv\")\n",
    "\n",
    "#for Jesse to download 1 pdb\n",
    "pdbl = PDBList()\n",
    "pdbl.retrieve_pdb_file(\"1a2p\",pdir='PDB',file_format = 'pdb')\n",
    "\n",
    "df_PKAD, resnames_PKAD = mini_batches(input_df_PKAD)\n",
    "dfff=df_PKAD[0]\n",
    "dfPKAD = partial_charges(text,dfff)\n",
    "\n",
    "#df_PKAD[0]\n",
    "display(HTML(dfPKAD.to_html()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c290a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#junk cell / ignore \n",
    "\n",
    "\n",
    "#make unique identifier \n",
    "    data=pdb_res.to_numpy() #pandas to numpy\n",
    "    pdb=[]\n",
    "    res=[]\n",
    "    randomm=[]\n",
    "    rand=random.sample(range(1000,9999), len(data))\n",
    "    ID=[]\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        pdb=np.append(pdb,str(data[i,0]))\n",
    "        res=np.append(res,str(math.trunc(data[i,1])))\n",
    "        randomm=np.append(randomm,str(rand[i])) #random 4 digit number \n",
    "        ids=\"-\".join([pdb[i],res[i],randomm[i]]) #combine with a hyphen\n",
    "        ID=np.append(ID,ids) #array with the unique IDs\n",
    "    \n",
    "#add the unique ID to the dataframe \n",
    "    varA = 'Unique ID' #column name\n",
    "    pdb_res[varA] = ID #adding the array i wanna add to df\n",
    "    pdb_res\n",
    "    \n",
    "import pyth\n",
    "help(pyth)\n",
    "import rtf2xml\n",
    "string[10].isnumeric()\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
