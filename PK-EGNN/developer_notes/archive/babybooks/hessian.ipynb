{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 24, 3])\n",
      "2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feats_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-85bf64e15070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mlatent_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m#latent_features = F.normalize(latent_features, p=2, dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feats_out' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from egnn_pytorch import EGNN_Network\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#feats = torch.ones((1,24), dtype=int)\n",
    "# Define learnable embeddings\n",
    "\n",
    "\n",
    "coors = torch.tensor([[\n",
    "    [42.677, 7.757, 12.295],   # N\n",
    "    [42.591, 6.743, 12.364],   # H\n",
    "    [43.902, 8.261, 12.895],   # CA\n",
    "    [43.609, 9.188, 13.389],   # HA\n",
    "    [44.899, 8.748, 11.824],   # C\n",
    "    [45.598, 9.722, 12.046],   # O\n",
    "    [44.507, 7.304, 13.893],   # CB\n",
    "    [44.553, 6.216, 13.844],   # HB2\n",
    "    [43.949, 7.467, 14.815],   # HB3\n",
    "    [45.942, 7.714, 14.190],   # CG\n",
    "    [46.624, 7.000, 14.652],   # HG2\n",
    "    [46.297, 7.552, 13.172],   # HG3\n",
    "    [46.098, 8.566, 15.453],   # CD\n",
    "    [45.432, 9.428, 15.421],   # HD2\n",
    "    [45.864, 8.023, 16.369],   # HD3\n",
    "    [47.437, 9.171, 15.645],   # NE\n",
    "    [48.036, 8.718, 16.335],   # HE\n",
    "    [48.159, 9.908, 14.753],   # CZ\n",
    "    [47.793, 10.201, 13.491],  # NH1\n",
    "    [48.497, 10.668, 12.920],  # HH11\n",
    "    [46.880, 10.644, 13.590],  # HH12\n",
    "    [49.340, 10.374, 15.149],  # NH2\n",
    "    [50.143, 9.902, 14.733],   # HH21\n",
    "    [49.831, 10.816, 15.926],  # HH22\n",
    "]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "species = torch.tensor([\n",
    "    0,  # N\n",
    "    1,  # H\n",
    "    2,  # CA\n",
    "    1,  # HA\n",
    "    2,  # C\n",
    "    3,  # O\n",
    "    2,  # CB\n",
    "    1,  # HB2\n",
    "    1,  # HB3\n",
    "    2,  # CG\n",
    "    1,  # HG2\n",
    "    1,  # HG3\n",
    "    2,  # CD\n",
    "    1,  # HD2\n",
    "    1,  # HD3\n",
    "    0,  # NE\n",
    "    1,  # HE\n",
    "    2,  # CZ\n",
    "    0,  # NH1\n",
    "    1,  # HH11\n",
    "    1,  # HH12\n",
    "    0,  # NH2\n",
    "    1,  # HH21\n",
    "    1   # HH22\n",
    "], dtype=torch.int)\n",
    "\n",
    "\n",
    "# Create a tensor with 1s for hydrogen (species == 1) and 0s elsewhere\n",
    "feats = torch.where(species == 1, torch.tensor(1), torch.tensor(0)).unsqueeze(0)\n",
    "\n",
    "\n",
    "# Indices to keep\n",
    "an = [15, 18,21] #nnn\n",
    "cat = [16,17,19,20,22,23]\n",
    "\n",
    "# Create a zero tensor\n",
    "new_species = torch.zeros_like(species)\n",
    "\n",
    "# Set specified indices to 1\n",
    "new_species[an] = -1\n",
    "new_species[cat] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def contrastive_loss(latent_features, species, margin):\n",
    "    loss = 0.0\n",
    "\n",
    "    positive_pairs = [(i, j) for i, j in itertools.combinations(range(len(species)), 2) if species[i] == species[j]]\n",
    "    negative_pairs = [(i, j) for i, j in itertools.combinations(range(3), 2) if species[i] != species[j]]\n",
    "\n",
    "\n",
    "    # Positive pairs\n",
    "    for i, j in positive_pairs:\n",
    "        z_i, z_j = latent_features[i], latent_features[j]\n",
    "        dist = torch.norm(z_i - z_j, p=2)  # Euclidean distance\n",
    "        loss += dist ** 2  # Minimize distance for positive pairs\n",
    "\n",
    "    # Negative pairs\n",
    "    for i, j in negative_pairs:\n",
    "        z_i, z_j = latent_features[i], latent_features[j]\n",
    "        dist = torch.norm(z_i - z_j, p=2)\n",
    "        loss += torch.clamp(margin - dist, min=0) ** 2  # Enforce margin\n",
    "\n",
    "\n",
    "\n",
    "    return loss / (len(positive_pairs) + len(negative_pairs))\n",
    "\n",
    "\n",
    "#low depth = local, high depth = l.r.\n",
    "net = EGNN_Network(\n",
    "    num_tokens = 10, #vocabulary siye, number of unique species\n",
    "    num_positions = 24,  #number of nodes         # unless what you are passing in is an unordered set, set this to the maximum sequence length\n",
    "    dim = 2,# #internal rep size. c has square dependence. richer rep but overfitting for small d.s.\n",
    "    depth = 2, #number of layers #deeper need more memort to store intermediate reps\n",
    "    num_nearest_neighbors = 3, #number of nearest neighbors to consider #make this the max hood size\n",
    "    coor_weights_clamp_value = 2.   # absolute clamped value for the coordinate weights, needed if you increase the num neareest neighbors\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=1e-3)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)\n",
    "#scheduler = LambdaLR(optimizer, lr_lambda=warmup_lr)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# Training loop\n",
    "for epoch in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    print(coors.unsqueeze(0).shape)\n",
    "    # Forward pass\n",
    "    #feats_out, coors_out = net(feats, coors.unsqueeze(0))\n",
    "    print(2)\n",
    "    \n",
    "\n",
    "    # Compute loss\n",
    "    latent_features = feats_out[0]\n",
    "\n",
    "    #latent_features = F.normalize(latent_features, p=2, dim=1)\n",
    "\n",
    "    \n",
    "    #loss = contrastive_loss(latent_features, species, margin=3)\n",
    "\n",
    "    # Backward pass\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(f\"Epoch {epoch}: Loss = {loss.item()}\")\n",
    "    #print(coors_out, feats_out)\n",
    "    \n",
    "\n",
    "\n",
    "    ####\n",
    "    \n",
    "\n",
    "    featsss_, coors_out = net(species.unsqueeze(0), coors)\n",
    "# Apply softmax along a specific dimension (e.g., last dimension)\n",
    "    featss_ = F.softmax(nn.Tanh()(nn.LeakyReLU(negative_slope=0.01)(featsss_)), dim=1)\n",
    "    #featss_ = F.softmax((nn.LeakyReLU(negative_slope=3)(featsss_)), dim=1)  # Sum along dim=1 will be 1    #featss_ = nn.Tanh()(nn.ReLU()(featsss_))\n",
    "    #feats_ = F.normalize(latent_features, p=1, dim=1)  # Normalize for cosine similarity\n",
    "\n",
    "    \n",
    "# Shift and normalize\n",
    "    #shifted_features = nn.Tanh()(featss_) + 1  # Shift to [0, 2]\n",
    "    #normalized_features = shifted_features / shifted_features.sum()  # Normalize to sum to 1\n",
    "\n",
    "# Shift back to [-1, 1] range while preserving sum-to-1\n",
    "    #final_features = 2 * normalized_features - 1\n",
    "\n",
    "    feats_ = featss_  / featss_.max() \n",
    "    #feats_ = featss_  / featss_.abs().max()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # Compute loss\n",
    "    latent_feature = feats_[0]\n",
    "\n",
    "    #latent_features = F.normalize(latent_features, p=2, dim=1)\n",
    "\n",
    "    \n",
    "    L = contrastive_loss(latent_feature, new_species, margin=3)\n",
    "\n",
    "        # Backward pass\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #scheduler.step()\n",
    "\n",
    "    #for name, param in net.named_parameters():\n",
    "    #    if 'coors_mlp' in name or param.grad.norm() < 1e-7:\n",
    "    #        torch.nn.init.xavier_uniform_(param)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Loss = {L.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0536, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.mean(latent_feature, dim=1)\n",
    "out.sum()/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = out.detach().numpy()*coors[0].detach().numpy().T\n",
    "combined = np.column_stack(f).flatten()\n",
    "combined.reshape(-1, 3)\n",
    "def divergence(field):\n",
    "    \"return the divergence of a n-D field\"\n",
    "    return np.gradient(field)\n",
    "d=divergence(combined)\n",
    "\n",
    "D=d.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.6302304,\n",
       " -0.27203915,\n",
       " 0.15107414,\n",
       " 0.4328919,\n",
       " -0.2994846,\n",
       " -0.28939247,\n",
       " 0.20640448,\n",
       " -0.06586999,\n",
       " -0.11000931,\n",
       " -0.15850577,\n",
       " 0.30847052,\n",
       " 0.13495052,\n",
       " -0.24725938,\n",
       " -0.06670755,\n",
       " 1.145556,\n",
       " -0.7427796,\n",
       " -0.1993866,\n",
       " 1.1014365,\n",
       " -0.7487712,\n",
       " -0.54972464,\n",
       " 0.6024828,\n",
       " 12.464174,\n",
       " -9.112336,\n",
       " -4.115159]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(D[0])\n",
    "[np.sum(d) for d in D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.494835"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([9.12401,\n",
    " -5.8246174,\n",
    " -6.7942276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.59453514"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([1.5521183,-0.61356544,-13.533088])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2#4\\cdot\\operatorname{csch}\\left(2\\left(.55x+.5\\right)\\right)-9\n",
    "#24*np.csc(2*(.55*12.59 + .5)) - 9\n",
    "\n",
    "x=0\n",
    "(24*1/(1+x)) - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "species_strings = [\n",
    "    \"N\",    # 0\n",
    "    \"H\",    # 1\n",
    "    \"CA\",   # 2\n",
    "    \"HA\",   # 1\n",
    "    \"C\",    # 2\n",
    "    \"O\",    # 3\n",
    "    \"CB\",   # 2\n",
    "    \"HB2\",  # 1\n",
    "    \"HB3\",  # 1\n",
    "    \"CG\",   # 2\n",
    "    \"HG2\",  # 1\n",
    "    \"HG3\",  # 1\n",
    "    \"CD\",   # 2\n",
    "    \"HD2\",  # 1\n",
    "    \"HD3\",  # 1\n",
    "    \"NE\",   # 0\n",
    "    \"HE\",   # 1\n",
    "    \"CZ\",   # 2\n",
    "    \"NH1\",  # 0\n",
    "    \"HH11\", # 1\n",
    "    \"HH12\", # 1\n",
    "    \"NH2\",  # 0\n",
    "    \"HH21\", # 1\n",
    "    \"HH22\"  # 1\n",
    "]\n",
    "# Create a tensor with 1s for hydrogen (species == 1) and 0s elsewhere\n",
    "feats = torch.where(species == 1, torch.tensor(1), torch.tensor(0)).unsqueeze(0)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(D[:, 0], D[:, 1], D[:, 2], label=\"Updated\")\n",
    "\n",
    "# Add labels to points\n",
    "for i in range(len(D)):\n",
    "    ax.text(D[i, 0], D[i, 1], D[i, 2], species_strings[i], fontsize=9)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"3D Position Transformation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(latent_features, species, margin):\n",
    "    loss = 0.0\n",
    "\n",
    "    positive_pairs = [(i, j) for i, j in itertools.combinations(range(len(species)), 2) if species[i] == species[j]]\n",
    "    negative_pairs = [(i, j) for i, j in itertools.combinations(range(3), 2) if species[i] != species[j]]\n",
    "\n",
    "\n",
    "    # Positive pairs\n",
    "    for i, j in positive_pairs:\n",
    "        z_i, z_j = latent_features[i], latent_features[j]\n",
    "        dist = torch.norm(z_i - z_j, p=2)  # Euclidean distance\n",
    "        loss += dist ** 2  # Minimize distance for positive pairs\n",
    "\n",
    "    # Negative pairs\n",
    "    for i, j in negative_pairs:\n",
    "        z_i, z_j = latent_features[i], latent_features[j]\n",
    "        dist = torch.norm(z_i - z_j, p=2)\n",
    "        loss += torch.clamp(margin - dist, min=0) ** 2  # Enforce margin\n",
    "\n",
    "\n",
    "\n",
    "    return loss / (len(positive_pairs) + len(negative_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 0: Loss = 0.22429630160331726\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 1: Loss = 0.15958939492702484\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 2: Loss = 0.09822990000247955\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 3: Loss = 0.04293624311685562\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 4: Loss = 0.009428063407540321\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 5: Loss = 0.00040097296005114913\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 6: Loss = 0.0002914196811616421\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 7: Loss = 0.00026648485800251365\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 8: Loss = 0.00023198996495921165\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 9: Loss = 0.00020491362374741584\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 10: Loss = 0.0001918808848131448\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 11: Loss = 0.00018757929501589388\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 12: Loss = 0.00018599854956846684\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 13: Loss = 0.00018356303917244077\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 14: Loss = 0.00018045229080598801\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 15: Loss = 0.0001766980713000521\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 16: Loss = 0.00017232532263733447\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 17: Loss = 0.0001672785438131541\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 18: Loss = 0.00016142525419127196\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 19: Loss = 0.0001548520231153816\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 20: Loss = 0.00014783020014874637\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 21: Loss = 0.00013851519906893373\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 22: Loss = 0.00012964752386324108\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 23: Loss = 0.00012453562521841377\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 24: Loss = 0.00011960578558500856\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 25: Loss = 0.00011485866707516834\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 26: Loss = 0.00011027803702745587\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 27: Loss = 0.00010580191883491352\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 28: Loss = 0.00010136755008716136\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 29: Loss = 9.695355402072892e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 30: Loss = 9.257681085728109e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 31: Loss = 8.826998237054795e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 32: Loss = 8.40567663544789e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 33: Loss = 7.99380723037757e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 34: Loss = 7.590585300931707e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 35: Loss = 7.195807847892866e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 36: Loss = 6.810535705881193e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 37: Loss = 6.437023694161326e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 38: Loss = 6.0773210861952975e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 39: Loss = 5.732433055527508e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 40: Loss = 5.402132956078276e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 41: Loss = 5.085821248940192e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 42: Loss = 4.7835779696470127e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 43: Loss = 4.496870678849518e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 44: Loss = 4.2284533265046775e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 45: Loss = 3.9812090108171105e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 46: Loss = 3.757009471883066e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 47: Loss = 3.55572956323158e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 48: Loss = 3.3754829928511754e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 49: Loss = 3.213598392903805e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 50: Loss = 3.0677474569529295e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 51: Loss = 2.936513556051068e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 52: Loss = 2.8194757760502398e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 53: Loss = 2.7166330255568027e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 54: Loss = 2.627855610626284e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 55: Loss = 2.5528095648041926e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 56: Loss = 2.4914153982535936e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 57: Loss = 2.4440805646008812e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 58: Loss = 2.4119244699249975e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 59: Loss = 2.3966076696524397e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 60: Loss = 2.4000852135941386e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 61: Loss = 2.424482772767078e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 62: Loss = 2.4724322429392487e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 63: Loss = 2.5471317712799646e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 64: Loss = 2.6524998247623444e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 65: Loss = 2.792748091451358e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 66: Loss = 2.9721475584665313e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 67: Loss = 3.194495729985647e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 68: Loss = 3.462996755843051e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 69: Loss = 3.77988581021782e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 70: Loss = 4.146447463426739e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 71: Loss = 4.562458707368933e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 72: Loss = 5.025900827604346e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 73: Loss = 5.529159534489736e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 74: Loss = 6.062781540094875e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 75: Loss = 6.62072779959999e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 76: Loss = 7.190007454482839e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 77: Loss = 7.755003753118217e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 78: Loss = 8.298332977574319e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 79: Loss = 8.801701915217564e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 80: Loss = 9.247138223145157e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 81: Loss = 9.618125477572903e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 82: Loss = 9.901410521706566e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 83: Loss = 0.00010087676491821185\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 84: Loss = 0.0001017241011140868\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 85: Loss = 0.00010155861673410982\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 86: Loss = 0.00010043056681752205\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 87: Loss = 9.842743020271882e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 88: Loss = 9.56662988755852e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 89: Loss = 9.2277281510178e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 90: Loss = 8.840062218951061e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 91: Loss = 8.416899072472006e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 92: Loss = 7.970123988343403e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 93: Loss = 7.510215800721198e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 94: Loss = 7.045556412776932e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 95: Loss = 6.58273056615144e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 96: Loss = 6.126577500253916e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 97: Loss = 5.680333561031148e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 98: Loss = 5.2462339226622134e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 99: Loss = 4.8254722059937194e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 100: Loss = 4.418569733388722e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 101: Loss = 4.025897942483425e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 102: Loss = 3.6474324588198215e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 103: Loss = 3.283327168901451e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 104: Loss = 2.9338169042603113e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 105: Loss = 2.5992672817665152e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 106: Loss = 2.280360604345333e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 107: Loss = 1.9781353330472484e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 108: Loss = 1.6938736735028215e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 109: Loss = 1.4291894331108779e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 110: Loss = 1.1859596270369366e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 111: Loss = 9.663457603892311e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 112: Loss = 7.726024705334567e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 113: Loss = 6.070146810088772e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 114: Loss = 4.715756858786335e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 115: Loss = 3.677388804135262e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 116: Loss = 2.957450760732172e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 117: Loss = 2.541855337767629e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 118: Loss = 2.3947607132868143e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 119: Loss = 2.453791466905386e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 120: Loss = 2.644114374561468e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 121: Loss = 2.875649215638987e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 122: Loss = 3.058765742025571e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 123: Loss = 3.116347443210543e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 124: Loss = 2.9939365049358457e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 125: Loss = 2.6695854558056453e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 126: Loss = 2.168511400668649e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 127: Loss = 1.5797706964804092e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 128: Loss = 1.057089548339718e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 129: Loss = 7.763008511574299e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 130: Loss = 8.518373988408712e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 131: Loss = 1.2578542509800172e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 132: Loss = 1.816677354327112e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 133: Loss = 2.2694598555972334e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 134: Loss = 2.372782546444796e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 135: Loss = 2.0070640402991557e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 136: Loss = 1.3090076436128584e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 137: Loss = 6.491836188615707e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 138: Loss = 3.6132632885710336e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 139: Loss = 4.937080007039185e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 140: Loss = 8.444026775578095e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 141: Loss = 1.0571571920081624e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 142: Loss = 8.544529919163324e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 143: Loss = 4.2562737689877395e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 144: Loss = 2.473544213899004e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 145: Loss = 5.420027946456685e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 146: Loss = 9.241304042006959e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 147: Loss = 8.158626201293373e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 148: Loss = 3.449814585110289e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 149: Loss = 1.4041364693184732e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 150: Loss = 3.975354161411815e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 151: Loss = 5.533899525289598e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 152: Loss = 3.349803705532395e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 153: Loss = 1.271516794076888e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 154: Loss = 3.3226399409613805e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 155: Loss = 4.832419335798477e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 156: Loss = 2.0678878343005636e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 157: Loss = 1.1342083183762952e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 158: Loss = 3.1089453500499076e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 159: Loss = 2.1743475997482165e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 160: Loss = 9.491967745134389e-08\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 161: Loss = 2.7568214022721804e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 162: Loss = 2.5449449481129705e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 163: Loss = 1.6804909819256864e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 164: Loss = 7.099436629687261e-07\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 165: Loss = 2.6828729460248724e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 166: Loss = 1.5702011296525598e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 167: Loss = 0.00010615762585075572\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 168: Loss = 0.0006107221124693751\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 169: Loss = 0.001451424090191722\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 170: Loss = 0.00043307265150360763\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 171: Loss = 0.0002709196414798498\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 172: Loss = 0.0006857725675217807\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 173: Loss = 5.029478052165359e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 174: Loss = 0.000550408847630024\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 175: Loss = 3.42319872288499e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 176: Loss = 0.0003600477648433298\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 177: Loss = 7.531489973189309e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 178: Loss = 0.00018224175437353551\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 179: Loss = 0.00015867034380789846\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 180: Loss = 2.7746940759243444e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 181: Loss = 0.00017779230256564915\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 182: Loss = 4.62046627944801e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 183: Loss = 4.108078428544104e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 184: Loss = 0.00012022988812532276\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 185: Loss = 1.83571464731358e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 186: Loss = 3.7595855246763676e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 187: Loss = 7.966155681060627e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 188: Loss = 1.5551879187114537e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 189: Loss = 2.502403367543593e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 190: Loss = 5.654188134940341e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 191: Loss = 1.1528836694196798e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 192: Loss = 1.8009968698606826e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 193: Loss = 4.405764047987759e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 194: Loss = 8.962329957284965e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 195: Loss = 1.175461511593312e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 196: Loss = 3.367690078448504e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 197: Loss = 5.260750185698271e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 198: Loss = 1.1851371709781233e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 199: Loss = 2.537206637498457e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "from egnn_pytorch import EGNN_Network\n",
    "import itertools\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the species indexer with H being 1, O 2, N 3, C 4\n",
    "species_indexer = {\"H\": 1, \"O\": 2, \"N\": 3, \"C\": 4}\n",
    "\n",
    "# Define the input data\n",
    "atoms = [\n",
    "    {\"element\": \"N\", \"x\": 41.226, \"y\": 23.713, \"z\": 1.930},\n",
    "    {\"element\": \"H\", \"x\": 41.066, \"y\": 24.250, \"z\": 1.078},\n",
    "    {\"element\": \"C\", \"x\": 41.242, \"y\": 24.495, \"z\": 3.173},\n",
    "    {\"element\": \"H\", \"x\": 42.132, \"y\": 25.079, \"z\": 3.406},\n",
    "    {\"element\": \"C\", \"x\": 41.309, \"y\": 23.535, \"z\": 4.352},\n",
    "    {\"element\": \"O\", \"x\": 42.103, \"y\": 23.723, \"z\": 5.273},\n",
    "    {\"element\": \"C\", \"x\": 39.983, \"y\": 25.367, \"z\": 3.299},\n",
    "    {\"element\": \"H\", \"x\": 40.092, \"y\": 26.027, \"z\": 4.159},\n",
    "    {\"element\": \"H\", \"x\": 39.103, \"y\": 24.805, \"z\": 3.612},\n",
    "    {\"element\": \"C\", \"x\": 39.782, \"y\": 26.337, \"z\": 2.155},\n",
    "    {\"element\": \"H\", \"x\": 39.427, \"y\": 25.807, \"z\": 1.271},\n",
    "    {\"element\": \"H\", \"x\": 38.936, \"y\": 27.020, \"z\": 2.234},\n",
    "    {\"element\": \"C\", \"x\": 41.052, \"y\": 27.126, \"z\": 1.876},\n",
    "    {\"element\": \"H\", \"x\": 41.323, \"y\": 27.979, \"z\": 2.499},\n",
    "    {\"element\": \"H\", \"x\": 41.977, \"y\": 26.549, \"z\": 1.888},\n",
    "    {\"element\": \"C\", \"x\": 40.953, \"y\": 27.877, \"z\": 0.561},\n",
    "    {\"element\": \"H\", \"x\": 40.794, \"y\": 27.218, \"z\": -0.293},\n",
    "    {\"element\": \"H\", \"x\": 40.175, \"y\": 28.639, \"z\": 0.512},\n",
    "    {\"element\": \"N\", \"x\": 42.213, \"y\": 28.602, \"z\": 0.247},\n",
    "    {\"element\": \"H\", \"x\": 42.015, \"y\": 29.364, \"z\": -0.433},\n",
    "    {\"element\": \"H\", \"x\": 42.905, \"y\": 28.072, \"z\": -0.320},\n",
    "    {\"element\": \"H\", \"x\": 42.816, \"y\": 29.230, \"z\": 0.815},\n",
    "]\n",
    "\n",
    "atoms = [\n",
    "    {\"element\": \"N\", \"x\": 37.224, \"y\": 18.045, \"z\": 15.399},\n",
    "    {\"element\": \"H\", \"x\": 37.961, \"y\": 18.720, \"z\": 15.194},\n",
    "    {\"element\": \"C\", \"x\": 35.933, \"y\": 18.752, \"z\": 15.379},\n",
    "    {\"element\": \"H\", \"x\": 35.648, \"y\": 18.996, \"z\": 16.402},\n",
    "    {\"element\": \"C\", \"x\": 34.768, \"y\": 17.918, \"z\": 14.838},\n",
    "    {\"element\": \"O\", \"x\": 33.656, \"y\": 17.989, \"z\": 15.343},\n",
    "    {\"element\": \"C\", \"x\": 36.039, \"y\": 20.025, \"z\": 14.528},\n",
    "    {\"element\": \"H\", \"x\": 36.354, \"y\": 19.910, \"z\": 13.491},\n",
    "    {\"element\": \"H\", \"x\": 35.123, \"y\": 20.594, \"z\": 14.684},\n",
    "    {\"element\": \"C\", \"x\": 36.859, \"y\": 21.119, \"z\": 15.187},\n",
    "    {\"element\": \"O\", \"x\": 37.272, \"y\": 20.963, \"z\": 16.349},\n",
    "    {\"element\": \"O\", \"x\": 37.087, \"y\": 22.152, \"z\": 14.529},\n",
    "]\n",
    "\n",
    "# Create the positions tensor and species tensor\n",
    "coors = torch.tensor([[atom[\"x\"], atom[\"y\"], atom[\"z\"]] for atom in atoms], dtype=torch.float32)\n",
    "species = torch.tensor([species_indexer[atom[\"element\"]] for atom in atoms], dtype=torch.int32)\n",
    "\n",
    "feats = torch.where(species == 1, torch.tensor(1), torch.tensor(0)).unsqueeze(0)\n",
    "\n",
    "cat, an = [19,20,21], [18]\n",
    "new_species = torch.zeros_like(species)\n",
    "\n",
    "# Set specified indices to 1\n",
    "new_species[an] = -1\n",
    "new_species[cat] = 1\n",
    "\n",
    "# Set specified indices to 1\n",
    "new_species[an] = -1\n",
    "new_species[cat] = 1\n",
    "\n",
    "net = EGNN_Network(\n",
    "    num_tokens = 10, #vocabulary siye, number of unique species\n",
    "    num_positions = 22,  #number of nodes         # unless what you are passing in is an unordered set, set this to the maximum sequence length\n",
    "    dim = 2,# #internal rep size. c has square dependence. richer rep but overfitting for small d.s.\n",
    "    depth = 3, #number of layers #deeper need more memort to store intermediate reps\n",
    "    num_nearest_neighbors = 1, #number of nearest neighbors to consider #make this the max hood size\n",
    "    coor_weights_clamp_value = 2.   # absolute clamped value for the coordinate weights, needed if you increase the num neareest neighbors\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-3)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)\n",
    "#scheduler = LambdaLR(optimizer, lr_lambda=warmup_lr)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    print(coors.unsqueeze(0).shape)\n",
    "    # Forward pass\n",
    "    #feats_out, coors_out = net(feats, coors.unsqueeze(0))\n",
    "    print(2)\n",
    "    \n",
    "\n",
    "    # Compute loss\n",
    "    latent_features = feats_out[0]\n",
    "\n",
    "    #latent_features = F.normalize(latent_features, p=2, dim=1)\n",
    "\n",
    "    \n",
    "    #loss = contrastive_loss(latent_features, species, margin=3)\n",
    "\n",
    "    # Backward pass\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(f\"Epoch {epoch}: Loss = {loss.item()}\")\n",
    "    #print(coors_out, feats_out)\n",
    "    \n",
    "\n",
    "\n",
    "    ####\n",
    "    \n",
    "\n",
    "    featsss_, coors_out = net(species.unsqueeze(0), coors.unsqueeze(0))\n",
    "# Apply softmax along a specific dimension (e.g., last dimension)\n",
    "    featss_ = F.softmax(nn.Tanh()(nn.LeakyReLU(negative_slope=0.01)(featsss_)), dim=1)  # Sum along dim=1 will be 1\n",
    "    #featss_ = nn.Tanh()(nn.ReLU()(featsss_))\n",
    "    #feats_ = F.normalize(latent_features, p=1, dim=1)  # Normalize for cosine similarity\n",
    "\n",
    "    \n",
    "# Shift and normalize\n",
    "    #shifted_features = nn.Tanh()(featss_) + 1  # Shift to [0, 2]\n",
    "    #normalized_features = shifted_features / shifted_features.sum()  # Normalize to sum to 1\n",
    "\n",
    "# Shift back to [-1, 1] range while preserving sum-to-1\n",
    "    #final_features = 2 * normalized_features - 1\n",
    "\n",
    "    feats_ = featss_  / featss_.abs().max() \n",
    "    #feats_ = featss_  / featss_.abs().max()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # Compute loss\n",
    "    latent_feature = feats_[0]\n",
    "\n",
    "    #latent_features = F.normalize(latent_features, p=2, dim=1)\n",
    "\n",
    "    \n",
    "    L = contrastive_loss(latent_feature, new_species, margin=1)\n",
    "\n",
    "        # Backward pass\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #scheduler.step()\n",
    "\n",
    "    #for name, param in net.named_parameters():\n",
    "    #    if 'coors_mlp' in name or param.grad.norm() < 1e-7:\n",
    "    #        torch.nn.init.xavier_uniform_(param)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Loss = {L.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 0: Loss = 0.3286839425563812\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 1: Loss = 0.22481612861156464\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 2: Loss = 0.1643693447113037\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 3: Loss = 0.12915123999118805\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 4: Loss = 0.11505547910928726\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 5: Loss = 0.1137022152543068\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 6: Loss = 0.11165235191583633\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 7: Loss = 0.11103304475545883\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 8: Loss = 0.11066671460866928\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 9: Loss = 0.11035238206386566\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 10: Loss = 0.1098882332444191\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 11: Loss = 0.10847701877355576\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 12: Loss = 0.10783662647008896\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 13: Loss = 0.10655773431062698\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 14: Loss = 0.10511882603168488\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 15: Loss = 0.10295188426971436\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 16: Loss = 0.09922927618026733\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 17: Loss = 0.0916532427072525\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 18: Loss = 0.07562898099422455\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 19: Loss = 0.009355117566883564\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 20: Loss = 0.0039644562639296055\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 21: Loss = 0.00556689640507102\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 22: Loss = 0.004272906109690666\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 23: Loss = 0.004159192088991404\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 24: Loss = 0.002954385709017515\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 25: Loss = 0.002412662375718355\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 26: Loss = 0.002271164208650589\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 27: Loss = 0.0016748731723055243\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 28: Loss = 0.0010104045504704118\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 29: Loss = 0.0006931388634257019\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 30: Loss = 0.0006322860135696828\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 31: Loss = 0.0006714040646329522\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 32: Loss = 0.0007503640372306108\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 33: Loss = 0.0008233906119130552\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 34: Loss = 0.0008615684928372502\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 35: Loss = 0.000890447641722858\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 36: Loss = 0.0009165525552816689\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 37: Loss = 0.0008763960213400424\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 38: Loss = 0.0007432623533532023\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 39: Loss = 0.0006619120249524713\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 40: Loss = 0.0009505337220616639\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 41: Loss = 0.0010290013160556555\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 42: Loss = 0.0006109903333708644\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 43: Loss = 0.00037994791637174785\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 44: Loss = 0.0003402280854061246\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 45: Loss = 0.0003386405878700316\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 46: Loss = 0.00032719061709940434\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 47: Loss = 0.0003166428941767663\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 48: Loss = 0.0003718824009411037\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 49: Loss = 0.000526989926584065\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 50: Loss = 0.0005687501397915184\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 51: Loss = 0.00044708960922434926\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 52: Loss = 0.0003837667463812977\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 53: Loss = 0.0003880635485984385\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 54: Loss = 0.00039284207741729915\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 55: Loss = 0.0003826993051916361\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 56: Loss = 0.00038577240775339305\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 57: Loss = 0.00043392038787715137\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 58: Loss = 0.0004712789668701589\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 59: Loss = 0.000426090438850224\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 60: Loss = 0.00034802945447154343\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 61: Loss = 0.0003003350575454533\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 62: Loss = 0.00028508203104138374\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 63: Loss = 0.00028903724160045385\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 64: Loss = 0.00031023245537653565\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 65: Loss = 0.00035335251595824957\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 66: Loss = 0.00040988854016177356\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 67: Loss = 0.0004466918180696666\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 68: Loss = 0.00044600790715776384\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 69: Loss = 0.0004165967693552375\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 70: Loss = 0.00038954001502133906\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 71: Loss = 0.0003708715667016804\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 72: Loss = 0.0003549469111021608\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 73: Loss = 0.00034359621349722147\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 74: Loss = 0.00034620179212652147\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 75: Loss = 0.0003572491114027798\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 76: Loss = 0.00036424605059437454\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 77: Loss = 0.00035669063800014555\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 78: Loss = 0.00033883663127198815\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 79: Loss = 0.0003236977499909699\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 80: Loss = 0.0003169447008986026\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 81: Loss = 0.0003180011117365211\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 82: Loss = 0.00032558460952714086\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 83: Loss = 0.00033611009712330997\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 84: Loss = 0.0003455273690633476\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 85: Loss = 0.0003479164151940495\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 86: Loss = 0.00033884638105519116\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 87: Loss = 0.00032059659133665264\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 88: Loss = 0.0003013762179762125\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 89: Loss = 0.00028914152062498033\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 90: Loss = 0.00028810740332119167\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 91: Loss = 0.00029843964148312807\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 92: Loss = 0.00031274836510419846\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 93: Loss = 0.0003265440172981471\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 94: Loss = 0.0003340097318869084\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 95: Loss = 0.0003313325869385153\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 96: Loss = 0.00031975997262634337\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 97: Loss = 0.00030494280508719385\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 98: Loss = 0.0002932575880549848\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 99: Loss = 0.00028880065656267107\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 100: Loss = 0.0002924141299445182\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 101: Loss = 0.0003012998204212636\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 102: Loss = 0.00031131491414271295\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 103: Loss = 0.00031799718271940947\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 104: Loss = 0.00031833970570005476\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 105: Loss = 0.00031310919439420104\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 106: Loss = 0.0003059813170693815\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 107: Loss = 0.0003008898929692805\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 108: Loss = 0.00029968551825731993\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 109: Loss = 0.0003027374332305044\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 110: Loss = 0.00030891713686287403\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 111: Loss = 0.0003152466961182654\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 112: Loss = 0.00031883057090453804\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 113: Loss = 0.0003186916874255985\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 114: Loss = 0.0003158587496727705\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 115: Loss = 0.0003124379145447165\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 116: Loss = 0.00031083624344319105\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 117: Loss = 0.00031210287124849856\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 118: Loss = 0.0003155629674438387\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 119: Loss = 0.0003193821175955236\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 120: Loss = 0.0003216119366697967\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 121: Loss = 0.0003217001794837415\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 122: Loss = 0.0003209430433344096\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 123: Loss = 0.0003212784940842539\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 124: Loss = 0.0003239422512706369\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 125: Loss = 0.0003289216256234795\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 126: Loss = 0.0003350967017468065\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 127: Loss = 0.00034093076828867197\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 128: Loss = 0.00034535754821263254\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 129: Loss = 0.00034845067420974374\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 130: Loss = 0.00035143757122568786\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 131: Loss = 0.00035594284418039024\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 132: Loss = 0.000363054103218019\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 133: Loss = 0.00037287353188730776\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 134: Loss = 0.0003846854961011559\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 135: Loss = 0.00039762264350429177\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 136: Loss = 0.0004114072071388364\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 137: Loss = 0.00042627067887224257\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 138: Loss = 0.00044158214586786926\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 139: Loss = 0.0004539899528026581\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 140: Loss = 0.00045661619515158236\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 141: Loss = 0.00044165088911540806\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 142: Loss = 0.00040693380287848413\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 143: Loss = 0.00035918288631364703\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 144: Loss = 0.00030896259704604745\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 145: Loss = 0.00026009444263763726\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 146: Loss = 0.00021524990734178573\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 147: Loss = 0.0001759383303578943\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 148: Loss = 0.00014503792044706643\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 149: Loss = 0.00011949083273066208\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 150: Loss = 9.7110569186043e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 151: Loss = 7.882831414462999e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 152: Loss = 6.596073944820091e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 153: Loss = 5.558801058214158e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 154: Loss = 4.613209603121504e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 155: Loss = 3.93818409065716e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 156: Loss = 3.720169115695171e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 157: Loss = 3.582662247936241e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 158: Loss = 3.528931847540662e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 159: Loss = 3.5532910260371864e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 160: Loss = 3.61844249709975e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 161: Loss = 3.39566649927292e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 162: Loss = 3.144409492961131e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 163: Loss = 2.992279769387096e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 164: Loss = 2.687727646843996e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 165: Loss = 2.4688959456398152e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 166: Loss = 2.2690639525535516e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 167: Loss = 2.030150244536344e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 168: Loss = 1.9401370082050562e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 169: Loss = 1.928142773977015e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 170: Loss = 2.011867763940245e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 171: Loss = 2.1325737179722637e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 172: Loss = 2.1349340386223048e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 173: Loss = 2.124028469552286e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 174: Loss = 2.086015410895925e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 175: Loss = 2.0005330952699296e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 176: Loss = 1.9621284081949852e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 177: Loss = 1.8292357708560303e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 178: Loss = 1.769774462445639e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 179: Loss = 1.590333522472065e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 180: Loss = 1.5487292330362834e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 181: Loss = 1.2587473975145258e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 182: Loss = 1.4022136383573525e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 183: Loss = 7.381713658105582e-06\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 184: Loss = 2.4258404664578848e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 185: Loss = 2.195340312027838e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 186: Loss = 0.00029952495242469013\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 187: Loss = 0.0010448594111949205\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 188: Loss = 0.00019324340973980725\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 189: Loss = 0.000253987469477579\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 190: Loss = 0.000718292489182204\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 191: Loss = 2.5827363060670905e-05\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 192: Loss = 0.0011992516228929162\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 193: Loss = 0.0009399371920153499\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 194: Loss = 0.0008859643712639809\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 195: Loss = 0.0003945310600101948\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 196: Loss = 0.000818391446955502\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 197: Loss = 0.00032798494794405997\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 198: Loss = 0.0007036225288175046\n",
      "torch.Size([1, 22, 3])\n",
      "2\n",
      "Epoch 199: Loss = 2.5574798200977966e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "from egnn_pytorch import EGNN_Network\n",
    "import itertools\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the species indexer with H being 1, O 2, N 3, C 4\n",
    "species_indexer = {\"H\": 1, \"O\": 2, \"N\": 3, \"C\": 4}\n",
    "\n",
    "# Define the input data\n",
    "atoms = [\n",
    "    {\"element\": \"N\", \"x\": 41.226, \"y\": 23.713, \"z\": 1.930},\n",
    "    {\"element\": \"H\", \"x\": 41.066, \"y\": 24.250, \"z\": 1.078},\n",
    "    {\"element\": \"C\", \"x\": 41.242, \"y\": 24.495, \"z\": 3.173},\n",
    "    {\"element\": \"H\", \"x\": 42.132, \"y\": 25.079, \"z\": 3.406},\n",
    "    {\"element\": \"C\", \"x\": 41.309, \"y\": 23.535, \"z\": 4.352},\n",
    "    {\"element\": \"O\", \"x\": 42.103, \"y\": 23.723, \"z\": 5.273},\n",
    "    {\"element\": \"C\", \"x\": 39.983, \"y\": 25.367, \"z\": 3.299},\n",
    "    {\"element\": \"H\", \"x\": 40.092, \"y\": 26.027, \"z\": 4.159},\n",
    "    {\"element\": \"H\", \"x\": 39.103, \"y\": 24.805, \"z\": 3.612},\n",
    "    {\"element\": \"C\", \"x\": 39.782, \"y\": 26.337, \"z\": 2.155},\n",
    "    {\"element\": \"H\", \"x\": 39.427, \"y\": 25.807, \"z\": 1.271},\n",
    "    {\"element\": \"H\", \"x\": 38.936, \"y\": 27.020, \"z\": 2.234},\n",
    "    {\"element\": \"C\", \"x\": 41.052, \"y\": 27.126, \"z\": 1.876},\n",
    "    {\"element\": \"H\", \"x\": 41.323, \"y\": 27.979, \"z\": 2.499},\n",
    "    {\"element\": \"H\", \"x\": 41.977, \"y\": 26.549, \"z\": 1.888},\n",
    "    {\"element\": \"C\", \"x\": 40.953, \"y\": 27.877, \"z\": 0.561},\n",
    "    {\"element\": \"H\", \"x\": 40.794, \"y\": 27.218, \"z\": -0.293},\n",
    "    {\"element\": \"H\", \"x\": 40.175, \"y\": 28.639, \"z\": 0.512},\n",
    "    {\"element\": \"N\", \"x\": 42.213, \"y\": 28.602, \"z\": 0.247},\n",
    "    {\"element\": \"H\", \"x\": 42.015, \"y\": 29.364, \"z\": -0.433},\n",
    "    {\"element\": \"H\", \"x\": 42.905, \"y\": 28.072, \"z\": -0.320},\n",
    "    {\"element\": \"H\", \"x\": 42.816, \"y\": 29.230, \"z\": 0.815},\n",
    "]\n",
    "\n",
    "atoms = [\n",
    "    {\"element\": \"N\", \"x\": 37.224, \"y\": 18.045, \"z\": 15.399},\n",
    "    {\"element\": \"H\", \"x\": 37.961, \"y\": 18.720, \"z\": 15.194},\n",
    "    {\"element\": \"C\", \"x\": 35.933, \"y\": 18.752, \"z\": 15.379},\n",
    "    {\"element\": \"H\", \"x\": 35.648, \"y\": 18.996, \"z\": 16.402},\n",
    "    {\"element\": \"C\", \"x\": 34.768, \"y\": 17.918, \"z\": 14.838},\n",
    "    {\"element\": \"O\", \"x\": 33.656, \"y\": 17.989, \"z\": 15.343},\n",
    "    {\"element\": \"C\", \"x\": 36.039, \"y\": 20.025, \"z\": 14.528},\n",
    "    {\"element\": \"H\", \"x\": 36.354, \"y\": 19.910, \"z\": 13.491},\n",
    "    {\"element\": \"H\", \"x\": 35.123, \"y\": 20.594, \"z\": 14.684},\n",
    "    {\"element\": \"C\", \"x\": 36.859, \"y\": 21.119, \"z\": 15.187},\n",
    "    {\"element\": \"O\", \"x\": 37.272, \"y\": 20.963, \"z\": 16.349},\n",
    "    {\"element\": \"O\", \"x\": 37.087, \"y\": 22.152, \"z\": 14.529},\n",
    "]\n",
    "\n",
    "atoms = [\n",
    "    {\"element\": \"N\", \"x\": 26.247, \"y\": 16.324, \"z\": -2.445},\n",
    "    {\"element\": \"H\", \"x\": 26.116, \"y\": 17.333, \"z\": -2.516},\n",
    "    {\"element\": \"C\", \"x\": 26.111, \"y\": 15.468, \"z\": -3.621},\n",
    "    {\"element\": \"H\", \"x\": 25.112, \"y\": 15.032, \"z\": -3.591},\n",
    "    {\"element\": \"C\", \"x\": 27.259, \"y\": 14.466, \"z\": -3.633},\n",
    "    {\"element\": \"O\", \"x\": 27.066, \"y\": 13.285, \"z\": -3.944},\n",
    "    {\"element\": \"C\", \"x\": 26.138, \"y\": 16.346, \"z\": -4.880},\n",
    "    {\"element\": \"H\", \"x\": 25.580, \"y\": 17.275, \"z\": -4.761},\n",
    "    {\"element\": \"H\", \"x\": 27.139, \"y\": 16.613, \"z\": -5.219},\n",
    "    {\"element\": \"C\", \"x\": 25.397, \"y\": 15.770, \"z\": -6.066},\n",
    "    {\"element\": \"H\", \"x\": 25.797, \"y\": 14.757, \"z\": -6.103},\n",
    "    {\"element\": \"H\", \"x\": 24.324, \"y\": 15.683, \"z\": -5.897},\n",
    "    {\"element\": \"C\", \"x\": 25.421, \"y\": 16.709, \"z\": -7.262},\n",
    "    {\"element\": \"H\", \"x\": 24.664, \"y\": 17.473, \"z\": -7.085},\n",
    "    {\"element\": \"H\", \"x\": 26.278, \"y\": 17.381, \"z\": -7.289},\n",
    "    {\"element\": \"C\", \"x\": 24.776, \"y\": 16.042, \"z\": -8.470},\n",
    "    {\"element\": \"H\", \"x\": 23.694, \"y\": 15.938, \"z\": -8.388},\n",
    "    {\"element\": \"H\", \"x\": 24.985, \"y\": 14.981, \"z\": -8.610},\n",
    "    {\"element\": \"N\", \"x\": 25.037, \"y\": 16.744, \"z\": -9.755},\n",
    "    {\"element\": \"H\", \"x\": 24.108, \"y\": 17.180, \"z\": -9.924},\n",
    "    {\"element\": \"H\", \"x\": 25.858, \"y\": 17.382, \"z\": -9.748},\n",
    "    {\"element\": \"H\", \"x\": 25.420, \"y\": 16.012, \"z\": -10.387},\n",
    "]\n",
    "\n",
    "atoms = [\n",
    "    {\"element\": \"N\", \"x\": 41.226, \"y\": 23.713, \"z\": 1.930},\n",
    "    {\"element\": \"H\", \"x\": 41.066, \"y\": 24.250, \"z\": 1.078},\n",
    "    {\"element\": \"C\", \"x\": 41.242, \"y\": 24.495, \"z\": 3.173},\n",
    "    {\"element\": \"H\", \"x\": 42.132, \"y\": 25.079, \"z\": 3.406},\n",
    "    {\"element\": \"C\", \"x\": 41.309, \"y\": 23.535, \"z\": 4.352},\n",
    "    {\"element\": \"O\", \"x\": 42.103, \"y\": 23.723, \"z\": 5.273},\n",
    "    {\"element\": \"C\", \"x\": 39.983, \"y\": 25.367, \"z\": 3.299},\n",
    "    {\"element\": \"H\", \"x\": 40.092, \"y\": 26.027, \"z\": 4.159},\n",
    "    {\"element\": \"H\", \"x\": 39.103, \"y\": 24.805, \"z\": 3.612},\n",
    "    {\"element\": \"C\", \"x\": 39.782, \"y\": 26.337, \"z\": 2.155},\n",
    "    {\"element\": \"H\", \"x\": 39.427, \"y\": 25.807, \"z\": 1.271},\n",
    "    {\"element\": \"H\", \"x\": 38.936, \"y\": 27.020, \"z\": 2.234},\n",
    "    {\"element\": \"C\", \"x\": 41.052, \"y\": 27.126, \"z\": 1.876},\n",
    "    {\"element\": \"H\", \"x\": 41.323, \"y\": 27.979, \"z\": 2.499},\n",
    "    {\"element\": \"H\", \"x\": 41.977, \"y\": 26.549, \"z\": 1.888},\n",
    "    {\"element\": \"C\", \"x\": 40.953, \"y\": 27.877, \"z\": 0.561},\n",
    "    {\"element\": \"H\", \"x\": 40.794, \"y\": 27.218, \"z\": -0.293},\n",
    "    {\"element\": \"H\", \"x\": 40.175, \"y\": 28.639, \"z\": 0.512},\n",
    "    {\"element\": \"N\", \"x\": 42.213, \"y\": 28.602, \"z\": 0.247},\n",
    "    {\"element\": \"H\", \"x\": 42.015, \"y\": 29.364, \"z\": -0.433},\n",
    "    {\"element\": \"H\", \"x\": 42.905, \"y\": 28.072, \"z\": -0.320},\n",
    "    {\"element\": \"H\", \"x\": 42.816, \"y\": 29.230, \"z\": 0.815},\n",
    "]\n",
    "\n",
    "\n",
    "# Create the positions tensor and species tensor\n",
    "coors = torch.tensor([[atom[\"x\"], atom[\"y\"], atom[\"z\"]] for atom in atoms], dtype=torch.float32)\n",
    "species = torch.tensor([species_indexer[atom[\"element\"]] for atom in atoms], dtype=torch.int32)\n",
    "\n",
    "feats = torch.where(species == 1, torch.tensor(1), torch.tensor(0)).unsqueeze(0)\n",
    "\n",
    "cat, an = [], [10, 11]\n",
    "new_species = torch.zeros_like(species)\n",
    "#cat, an = [19,20,21], [18]\n",
    "new_species = torch.zeros_like(species)\n",
    "\n",
    "# Set specified indices to 1\n",
    "new_species[an] = -1\n",
    "#new_species[cat] = 1\n",
    "\n",
    "\n",
    "feats = torch.where(species == 1, torch.tensor(1), torch.tensor(0)).unsqueeze(0)\n",
    "\n",
    "cat, an = [19,20,21], [18]\n",
    "new_species = torch.zeros_like(species)\n",
    "\n",
    "# Set specified indices to 1\n",
    "new_species[an] = -1\n",
    "new_species[cat] = 1\n",
    "\n",
    "\n",
    "net = EGNN_Network(\n",
    "    num_tokens = 10, #vocabulary siye, number of unique species\n",
    "    num_positions = 22,  #number of nodes         # unless what you are passing in is an unordered set, set this to the maximum sequence length\n",
    "    dim = 2,# #internal rep size. c has square dependence. richer rep but overfitting for small d.s.\n",
    "    depth = 2, #number of layers #deeper need more memort to store intermediate reps\n",
    "    num_nearest_neighbors = 1, #number of nearest neighbors to consider #make this the max hood size\n",
    "    coor_weights_clamp_value = 2.   # absolute clamped value for the coordinate weights, needed if you increase the num neareest neighbors\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=.1, weight_decay=1e-3)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)\n",
    "#scheduler = LambdaLR(optimizer, lr_lambda=warmup_lr)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    print(coors.unsqueeze(0).shape)\n",
    "    # Forward pass\n",
    "    #feats_out, coors_out = net(feats, coors.unsqueeze(0))\n",
    "    print(2)\n",
    "    \n",
    "\n",
    "    # Compute loss\n",
    "    latent_features = feats_out[0]\n",
    "\n",
    "    #latent_features = F.normalize(latent_features, p=2, dim=1)\n",
    "\n",
    "    \n",
    "    #loss = contrastive_loss(latent_features, species, margin=3)\n",
    "\n",
    "    # Backward pass\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(f\"Epoch {epoch}: Loss = {loss.item()}\")\n",
    "    #print(coors_out, feats_out)\n",
    "    \n",
    "\n",
    "\n",
    "    ####\n",
    "    \n",
    "\n",
    "    featsss_, coors_out = net(species.unsqueeze(0), coors.unsqueeze(0))\n",
    "# Apply softmax along a specific dimension (e.g., last dimension)\n",
    "    featss_ = F.softmax((nn.LeakyReLU(negative_slope=1)(featsss_)), dim=1)  # Sum along dim=1 will be 1\n",
    "    #featss_ = nn.Tanh()(nn.ReLU()(featsss_))\n",
    "    #feats_ = F.normalize(latent_features, p=1, dim=1)  # Normalize for cosine similarity\n",
    "\n",
    "    \n",
    "# Shift and normalize\n",
    "    #shifted_features = nn.Tanh()(featss_) + 1  # Shift to [0, 2]\n",
    "    #normalized_features = shifted_features / shifted_features.sum()  # Normalize to sum to 1\n",
    "\n",
    "# Shift back to [-1, 1] range while preserving sum-to-1\n",
    "    #final_features = 2 * normalized_features - 1\n",
    "\n",
    "    feats_ = featss_  / featss_.max()\n",
    "    #feats_ = featss_  / featss_.abs().max()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # Compute loss\n",
    "    latent_feature = feats_[0]\n",
    "\n",
    "    #latent_features = F.normalize(latent_features, p=2, dim=1)\n",
    "\n",
    "    \n",
    "    L = contrastive_loss(latent_feature, new_species, margin=1)\n",
    "\n",
    "        # Backward pass\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #scheduler.step()\n",
    "\n",
    "    #for name, param in net.named_parameters():\n",
    "    #    if 'coors_mlp' in name or param.grad.norm() < 1e-7:\n",
    "    #        torch.nn.init.xavier_uniform_(param)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Loss = {L.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3167, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-8.913857,\n",
       " -0.10279441,\n",
       " 0.44592404,\n",
       " -0.04929018,\n",
       " 0.25939298,\n",
       " -0.19936419,\n",
       " -0.3163705,\n",
       " -0.009790182,\n",
       " 0.03968072,\n",
       " -0.2913344,\n",
       " -0.2394228,\n",
       " 0.50669503,\n",
       " -0.017035007,\n",
       " 0.18722916,\n",
       " -0.2299726,\n",
       " -0.24552464,\n",
       " -0.22909021,\n",
       " 7.802106,\n",
       " -7.557108,\n",
       " -0.0071115494,\n",
       " -0.04055071,\n",
       " -10.102495]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.mean(latent_feature, dim=1)\n",
    "print(out.sum()/22)\n",
    "f = out.detach().numpy()*coors.detach().numpy().T\n",
    "combined = np.column_stack(f).flatten()\n",
    "combined.reshape(-1, 3)\n",
    "d=divergence(combined)\n",
    "\n",
    "D=d.reshape(-1,3)\n",
    "\n",
    "b = [np.sum(d) for d in D]\n",
    "[np.sum(d) for d in D]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28999999999999915"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10.76-10.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836.8000000000001"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".2*4184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-28.271889,\n",
    " -0.36738682,\n",
    " 1.5135813,\n",
    " -0.32116222,\n",
    " 0.87352943,\n",
    " -0.60547066,\n",
    " -0.89973354,\n",
    " -0.061395645,\n",
    " 0.037075996,\n",
    " -0.8764038,\n",
    " -0.6790924,\n",
    " 1.4825373,\n",
    " -0.0011920929,\n",
    " 0.6411257,\n",
    " -0.84130955,\n",
    " -0.71056366,\n",
    " -0.7323513,\n",
    " 1.277668,\n",
    " -0.1032505,\n",
    " 0.12924671,\n",
    " -35.581375]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[np.sum(d) for d in D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.13269715011119843\n",
      "Epoch 1: Loss = 0.0885026752948761\n",
      "Epoch 2: Loss = 0.0614171139895916\n",
      "Epoch 3: Loss = 0.031289029866456985\n",
      "Epoch 4: Loss = 0.0002529259363655001\n",
      "Epoch 5: Loss = 0.00016426891670562327\n",
      "Epoch 6: Loss = 0.00042275863233953714\n",
      "Epoch 7: Loss = 0.0003760211693588644\n",
      "Epoch 8: Loss = 0.0002540201530791819\n",
      "Epoch 9: Loss = 0.00015526522474829108\n",
      "Epoch 10: Loss = 0.0001015293673845008\n",
      "Epoch 11: Loss = 7.900214404799044e-05\n",
      "Epoch 12: Loss = 7.086759433150291e-05\n",
      "Epoch 13: Loss = 6.867018237244338e-05\n",
      "Epoch 14: Loss = 6.856499385321513e-05\n",
      "Epoch 15: Loss = 6.823255534982309e-05\n",
      "Epoch 16: Loss = 6.645588291576132e-05\n",
      "Epoch 17: Loss = 6.358714017551392e-05\n",
      "Epoch 18: Loss = 6.0972692153882235e-05\n",
      "Epoch 19: Loss = 5.973753286525607e-05\n",
      "Epoch 20: Loss = 6.008254786138423e-05\n",
      "Epoch 21: Loss = 6.143035716377199e-05\n",
      "Epoch 22: Loss = 6.302803376456723e-05\n",
      "Epoch 23: Loss = 6.4389496401418e-05\n",
      "Epoch 24: Loss = 6.538118759635836e-05\n",
      "Epoch 25: Loss = 6.610295531572774e-05\n",
      "Epoch 26: Loss = 6.671601295238361e-05\n",
      "Epoch 27: Loss = 6.73254908178933e-05\n",
      "Epoch 28: Loss = 6.796286470489576e-05\n",
      "Epoch 29: Loss = 6.861672591185197e-05\n",
      "Epoch 30: Loss = 6.926088099135086e-05\n",
      "Epoch 31: Loss = 6.985978689044714e-05\n",
      "Epoch 32: Loss = 7.037376053631306e-05\n",
      "Epoch 33: Loss = 7.078983617248014e-05\n",
      "Epoch 34: Loss = 7.113707397365943e-05\n",
      "Epoch 35: Loss = 7.145620475057513e-05\n",
      "Epoch 36: Loss = 6.852991646155715e-05\n",
      "Epoch 37: Loss = 6.636149919359013e-05\n",
      "Epoch 38: Loss = 6.535292777698487e-05\n",
      "Epoch 39: Loss = 6.569684774149209e-05\n",
      "Epoch 40: Loss = 6.766038131900132e-05\n",
      "Epoch 41: Loss = 7.157162326620892e-05\n",
      "Epoch 42: Loss = 7.778708823025227e-05\n",
      "Epoch 43: Loss = 8.661799802212045e-05\n",
      "Epoch 44: Loss = 9.821507410379127e-05\n",
      "Epoch 45: Loss = 0.00011241500033065677\n",
      "Epoch 46: Loss = 0.00012859718117397279\n",
      "Epoch 47: Loss = 0.00014560544514097273\n",
      "Epoch 48: Loss = 0.000161802425282076\n",
      "Epoch 49: Loss = 0.00017530775221530348\n",
      "Epoch 50: Loss = 0.0001843989739427343\n",
      "Epoch 51: Loss = 0.0001879409101093188\n",
      "Epoch 52: Loss = 0.000185677083209157\n",
      "Epoch 53: Loss = 0.000178225091076456\n",
      "Epoch 54: Loss = 0.000166835990967229\n",
      "Epoch 55: Loss = 0.00015301424718927592\n",
      "Epoch 56: Loss = 0.0001381894835503772\n",
      "Epoch 57: Loss = 0.00012350408360362053\n",
      "Epoch 58: Loss = 0.00010974077304126695\n",
      "Epoch 59: Loss = 9.734589548315853e-05\n",
      "Epoch 60: Loss = 8.650450763525441e-05\n",
      "Epoch 61: Loss = 7.722423470113426e-05\n",
      "Epoch 62: Loss = 6.941550236660987e-05\n",
      "Epoch 63: Loss = 6.293663318501785e-05\n",
      "Epoch 64: Loss = 5.76356724195648e-05\n",
      "Epoch 65: Loss = 5.335940659279004e-05\n",
      "Epoch 66: Loss = 4.996448114980012e-05\n",
      "Epoch 67: Loss = 4.731477747554891e-05\n",
      "Epoch 68: Loss = 4.527867349679582e-05\n",
      "Epoch 69: Loss = 4.3723044655052945e-05\n",
      "Epoch 70: Loss = 4.2510822822805494e-05\n",
      "Epoch 71: Loss = 4.1498718928778544e-05\n",
      "Epoch 72: Loss = 4.053961674799211e-05\n",
      "Epoch 73: Loss = 3.949588426621631e-05\n",
      "Epoch 74: Loss = 3.826010288321413e-05\n",
      "Epoch 75: Loss = 3.6783760151593015e-05\n",
      "Epoch 76: Loss = 3.511390968924388e-05\n",
      "Epoch 77: Loss = 3.3400596294086426e-05\n",
      "Epoch 78: Loss = 3.185087916790508e-05\n",
      "Epoch 79: Loss = 3.062136238440871e-05\n",
      "Epoch 80: Loss = 2.967739237647038e-05\n",
      "Epoch 81: Loss = 2.8853201001766138e-05\n",
      "Epoch 82: Loss = 2.7255357053945772e-05\n",
      "Epoch 83: Loss = 2.5780373107409105e-05\n",
      "Epoch 84: Loss = 2.4636658054077998e-05\n",
      "Epoch 85: Loss = 2.4339013179996982e-05\n",
      "Epoch 86: Loss = 2.4910403226385824e-05\n",
      "Epoch 87: Loss = 2.5717556127347052e-05\n",
      "Epoch 88: Loss = 2.575941471150145e-05\n",
      "Epoch 89: Loss = 2.4109678633976728e-05\n",
      "Epoch 90: Loss = 2.0709308955702e-05\n",
      "Epoch 91: Loss = 1.7206933989655226e-05\n",
      "Epoch 92: Loss = 1.594623245182447e-05\n",
      "Epoch 93: Loss = 1.7214017134392634e-05\n",
      "Epoch 94: Loss = 1.9134340618620627e-05\n",
      "Epoch 95: Loss = 1.9450044419500045e-05\n",
      "Epoch 96: Loss = 1.7816222680266947e-05\n",
      "Epoch 97: Loss = 1.4394759091373999e-05\n",
      "Epoch 98: Loss = 1.148537194239907e-05\n",
      "Epoch 99: Loss = 1.2894937754026614e-05\n",
      "Epoch 100: Loss = 1.6528028936591e-05\n",
      "Epoch 101: Loss = 1.4407853086595424e-05\n",
      "Epoch 102: Loss = 9.890175533655565e-06\n",
      "Epoch 103: Loss = 9.964021046471316e-06\n",
      "Epoch 104: Loss = 1.2326519026828464e-05\n",
      "Epoch 105: Loss = 1.2682448868872598e-05\n",
      "Epoch 106: Loss = 8.433684342890047e-06\n",
      "Epoch 107: Loss = 8.373684067919385e-06\n",
      "Epoch 108: Loss = 1.07131836557528e-05\n",
      "Epoch 109: Loss = 9.016476724355016e-06\n",
      "Epoch 110: Loss = 6.6302341110713314e-06\n",
      "Epoch 111: Loss = 9.403778676642105e-06\n",
      "Epoch 112: Loss = 9.338449672213756e-06\n",
      "Epoch 113: Loss = 2.3639993742108345e-05\n",
      "Epoch 114: Loss = 0.00016824161866679788\n",
      "Epoch 115: Loss = 0.0009240577928721905\n",
      "Epoch 116: Loss = 0.0012952012475579977\n",
      "Epoch 117: Loss = 5.794690878246911e-05\n",
      "Epoch 118: Loss = 0.0009612730355001986\n",
      "Epoch 119: Loss = 4.3157539039384574e-05\n",
      "Epoch 120: Loss = 0.0006358720711432397\n",
      "Epoch 121: Loss = 7.71201157476753e-05\n",
      "Epoch 122: Loss = 0.00035089204902760684\n",
      "Epoch 123: Loss = 0.0002119808050338179\n",
      "Epoch 124: Loss = 4.688477565650828e-05\n",
      "Epoch 125: Loss = 0.0002476283407304436\n",
      "Epoch 126: Loss = 0.00013495940947905183\n",
      "Epoch 127: Loss = 1.5763587725814432e-05\n",
      "Epoch 128: Loss = 0.00011214122787350789\n",
      "Epoch 129: Loss = 0.0001309419167228043\n",
      "Epoch 130: Loss = 3.4940108889713883e-05\n",
      "Epoch 131: Loss = 2.0865410988335498e-05\n",
      "Epoch 132: Loss = 7.884502701926976e-05\n",
      "Epoch 133: Loss = 7.472700235666707e-05\n",
      "Epoch 134: Loss = 2.068376670649741e-05\n",
      "Epoch 135: Loss = 1.3205455616116524e-05\n",
      "Epoch 136: Loss = 4.753495522891171e-05\n",
      "Epoch 137: Loss = 4.84948541270569e-05\n",
      "Epoch 138: Loss = 1.5220734894683119e-05\n",
      "Epoch 139: Loss = 9.6604762802599e-06\n",
      "Epoch 140: Loss = 3.3579952287254855e-05\n",
      "Epoch 141: Loss = 3.2500389352208003e-05\n",
      "Epoch 142: Loss = 7.253188414324541e-06\n",
      "Epoch 143: Loss = 9.048811989487149e-06\n",
      "Epoch 144: Loss = 2.9355580409173854e-05\n",
      "Epoch 145: Loss = 2.0037483409396373e-05\n",
      "Epoch 146: Loss = 2.313697905265144e-06\n",
      "Epoch 147: Loss = 1.510039783170214e-05\n",
      "Epoch 148: Loss = 2.103835686284583e-05\n",
      "Epoch 149: Loss = 4.071082912560087e-06\n",
      "Epoch 150: Loss = 1.0435860531288199e-05\n",
      "Epoch 151: Loss = 1.721962144074496e-05\n",
      "Epoch 152: Loss = 2.7012999908038182e-06\n",
      "Epoch 153: Loss = 1.1928763342439197e-05\n",
      "Epoch 154: Loss = 1.0750437468232121e-05\n",
      "Epoch 155: Loss = 3.0335909286804963e-06\n",
      "Epoch 156: Loss = 1.420118314854335e-05\n",
      "Epoch 157: Loss = 1.6630662003080943e-06\n",
      "Epoch 158: Loss = 1.1050913599319756e-05\n",
      "Epoch 159: Loss = 3.570924263840425e-06\n",
      "Epoch 160: Loss = 8.401888408116065e-06\n",
      "Epoch 161: Loss = 4.383989107736852e-06\n",
      "Epoch 162: Loss = 8.321547284140252e-06\n",
      "Epoch 163: Loss = 1.5984237506927457e-06\n",
      "Epoch 164: Loss = 1.0152979484701063e-05\n",
      "Epoch 165: Loss = 5.783013534710335e-07\n",
      "Epoch 166: Loss = 7.560032827313989e-06\n",
      "Epoch 167: Loss = 6.090806436986895e-06\n",
      "Epoch 168: Loss = 8.571453236072557e-07\n",
      "Epoch 169: Loss = 7.385583103314275e-06\n",
      "Epoch 170: Loss = 8.284532668767497e-06\n",
      "Epoch 171: Loss = 2.1180451312829973e-06\n",
      "Epoch 172: Loss = 1.2114380751881981e-06\n",
      "Epoch 173: Loss = 6.021480658091605e-06\n",
      "Epoch 174: Loss = 1.4008470316184685e-05\n",
      "Epoch 175: Loss = 2.654512536537368e-05\n",
      "Epoch 176: Loss = 5.583171878242865e-05\n",
      "Epoch 177: Loss = 0.00014001458475831896\n",
      "Epoch 178: Loss = 0.00039422299596481025\n",
      "Epoch 179: Loss = 0.0009326331783086061\n",
      "Epoch 180: Loss = 0.0012502914760261774\n",
      "Epoch 181: Loss = 0.00029917893698439\n",
      "Epoch 182: Loss = 0.00024092909006867558\n",
      "Epoch 183: Loss = 0.0004963056417182088\n",
      "Epoch 184: Loss = 2.0430579752428457e-05\n",
      "Epoch 185: Loss = 0.00034460914321243763\n",
      "Epoch 186: Loss = 2.0748413589899428e-05\n",
      "Epoch 187: Loss = 0.00021954270778223872\n",
      "Epoch 188: Loss = 6.576140731340274e-05\n",
      "Epoch 189: Loss = 8.764416998019442e-05\n",
      "Epoch 190: Loss = 0.00013215409126132727\n",
      "Epoch 191: Loss = 8.045797585509717e-06\n",
      "Epoch 192: Loss = 0.0001231394417118281\n",
      "Epoch 193: Loss = 2.9640070351888426e-05\n",
      "Epoch 194: Loss = 4.2805258999578655e-05\n",
      "Epoch 195: Loss = 8.255610737251118e-05\n",
      "Epoch 196: Loss = 1.110069320020557e-06\n",
      "Epoch 197: Loss = 6.431493966374546e-05\n",
      "Epoch 198: Loss = 2.6921432436211035e-05\n",
      "Epoch 199: Loss = 1.9336916011525318e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-28.271889,\n",
       " -0.36738682,\n",
       " 1.5135813,\n",
       " -0.32116222,\n",
       " 0.87352943,\n",
       " -0.60547066,\n",
       " -0.89973354,\n",
       " -0.061395645,\n",
       " 0.037075996,\n",
       " -0.8764038,\n",
       " -0.6790924,\n",
       " 1.4825373,\n",
       " -0.0011920929,\n",
       " 0.6411257,\n",
       " -0.84130955,\n",
       " -0.71056366,\n",
       " -0.7323513,\n",
       " 1.277668,\n",
       " -0.1032505,\n",
       " 0.12924671,\n",
       " -35.581375]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "from egnn_pytorch import EGNN_Network\n",
    "import itertools\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the species indexer with H being 1, O 2, N 3, C 4\n",
    "species_indexer = {\"H\": 1, \"O\": 2, \"N\": 3, \"C\": 4}\n",
    "\n",
    "# Define the input data\n",
    "atoms = [\n",
    "    {\"element\": \"N\", \"x\": 41.226, \"y\": 23.713, \"z\": 1.930},\n",
    "    {\"element\": \"H\", \"x\": 41.066, \"y\": 24.250, \"z\": 1.078},\n",
    "    {\"element\": \"C\", \"x\": 41.242, \"y\": 24.495, \"z\": 3.173},\n",
    "    {\"element\": \"H\", \"x\": 42.132, \"y\": 25.079, \"z\": 3.406},\n",
    "    {\"element\": \"C\", \"x\": 41.309, \"y\": 23.535, \"z\": 4.352},\n",
    "    {\"element\": \"O\", \"x\": 42.103, \"y\": 23.723, \"z\": 5.273},\n",
    "    {\"element\": \"C\", \"x\": 39.983, \"y\": 25.367, \"z\": 3.299},\n",
    "    {\"element\": \"H\", \"x\": 40.092, \"y\": 26.027, \"z\": 4.159},\n",
    "    {\"element\": \"H\", \"x\": 39.103, \"y\": 24.805, \"z\": 3.612},\n",
    "    {\"element\": \"C\", \"x\": 39.782, \"y\": 26.337, \"z\": 2.155},\n",
    "    {\"element\": \"H\", \"x\": 39.427, \"y\": 25.807, \"z\": 1.271},\n",
    "    {\"element\": \"H\", \"x\": 38.936, \"y\": 27.020, \"z\": 2.234},\n",
    "    {\"element\": \"C\", \"x\": 41.052, \"y\": 27.126, \"z\": 1.876},\n",
    "    {\"element\": \"H\", \"x\": 41.323, \"y\": 27.979, \"z\": 2.499},\n",
    "    {\"element\": \"H\", \"x\": 41.977, \"y\": 26.549, \"z\": 1.888},\n",
    "    {\"element\": \"C\", \"x\": 40.953, \"y\": 27.877, \"z\": 0.561},\n",
    "    {\"element\": \"H\", \"x\": 40.794, \"y\": 27.218, \"z\": -0.293},\n",
    "    {\"element\": \"H\", \"x\": 40.175, \"y\": 28.639, \"z\": 0.512},\n",
    "    {\"element\": \"N\", \"x\": 42.213, \"y\": 28.602, \"z\": 0.247},\n",
    "    {\"element\": \"H\", \"x\": 42.015, \"y\": 29.364, \"z\": -0.433},\n",
    "    {\"element\": \"H\", \"x\": 42.905, \"y\": 28.072, \"z\": -0.320}\n",
    "]\n",
    "\n",
    "# Create the positions tensor and species tensor\n",
    "coors = torch.tensor([[atom[\"x\"], atom[\"y\"], atom[\"z\"]] for atom in atoms], dtype=torch.float32)\n",
    "species = torch.tensor([species_indexer[atom[\"element\"]] for atom in atoms], dtype=torch.int32)\n",
    "\n",
    "feats = torch.where(species == 1, torch.tensor(1), torch.tensor(0)).unsqueeze(0)\n",
    "\n",
    "cat, an = [19,20], [18]\n",
    "new_species = torch.zeros_like(species)\n",
    "cat, an = [19,20], [18]\n",
    "new_species = torch.zeros_like(species)\n",
    "\n",
    "# Set specified indices to 1\n",
    "new_species[an] = -1\n",
    "new_species[cat] = 1\n",
    "\n",
    "# Set specified indices to 1\n",
    "new_species[an] = -1\n",
    "new_species[cat] = 1\n",
    "\n",
    "net = EGNN_Network(\n",
    "    num_tokens = 10, #vocabulary siye, number of unique species\n",
    "    num_positions = 21,  #number of nodes         # unless what you are passing in is an unordered set, set this to the maximum sequence length\n",
    "    dim = 4,# #internal rep size. c has square dependence. richer rep but overfitting for small d.s.\n",
    "    depth = 3, #number of layers #deeper need more memort to store intermediate reps\n",
    "    num_nearest_neighbors = 1, #number of nearest neighbors to consider #make this the max hood size\n",
    "    coor_weights_clamp_value = 2.   # absolute clamped value for the coordinate weights, needed if you increase the num neareest neighbors\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-3)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)\n",
    "#scheduler = LambdaLR(optimizer, lr_lambda=warmup_lr)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    featsss_, coors_out = net(species.unsqueeze(0), coors.unsqueeze(0))\n",
    "# Apply softmax along a specific dimension (e.g., last dimension)\n",
    "    featss_ = F.softmax(nn.Tanh()(nn.LeakyReLU(negative_slope=0.01)(featsss_)), dim=1)  # Sum along dim=1 will be 1\n",
    "    #featss_ = nn.Tanh()(nn.ReLU()(featsss_))\n",
    "    #feats_ = F.normalize(latent_features, p=1, dim=1)  # Normalize for cosine similarity\n",
    "\n",
    "    \n",
    "# Shift and normalize\n",
    "    #shifted_features = nn.Tanh()(featss_) + 1  # Shift to [0, 2]\n",
    "    #normalized_features = shifted_features / shifted_features.sum()  # Normalize to sum to 1\n",
    "\n",
    "# Shift back to [-1, 1] range while preserving sum-to-1\n",
    "    #final_features = 2 * normalized_features - 1\n",
    "\n",
    "    feats_ = featss_  / featss_.abs().max() \n",
    "    #feats_ = featss_  / featss_.abs().max()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # Compute loss\n",
    "    latent_feature = feats_[0]\n",
    "\n",
    "    #latent_features = F.normalize(latent_features, p=2, dim=1)\n",
    "\n",
    "    \n",
    "    L = contrastive_loss(latent_feature, new_species, margin=1)\n",
    "\n",
    "        # Backward pass\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #scheduler.step()\n",
    "\n",
    "    #for name, param in net.named_parameters():\n",
    "    #    if 'coors_mlp' in name or param.grad.norm() < 1e-7:\n",
    "    #        torch.nn.init.xavier_uniform_(param)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Loss = {L.item()}\")\n",
    "\n",
    "\n",
    "out = torch.mean(latent_feature, dim=1)\n",
    "out.sum()/22\n",
    "f = out.detach().numpy()*coors.detach().numpy().T\n",
    "combined = np.column_stack(f).flatten()\n",
    "combined.reshape(-1, 3)\n",
    "d=divergence(combined)\n",
    "\n",
    "D=d.reshape(-1,3)\n",
    "[np.sum(d) for d in D]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9936, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-28.271889,\n",
       " -0.36738682,\n",
       " 1.5135813,\n",
       " -0.32116222,\n",
       " 0.87352943,\n",
       " -0.60547066,\n",
       " -0.89973354,\n",
       " -0.061395645,\n",
       " 0.037075996,\n",
       " -0.8764038,\n",
       " -0.6790924,\n",
       " 1.4825373,\n",
       " -0.0011920929,\n",
       " 0.6411257,\n",
       " -0.84130955,\n",
       " -0.71056366,\n",
       " -0.7323513,\n",
       " 1.277668,\n",
       " -0.1032505,\n",
       " 0.12924671,\n",
       " -35.581375]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.mean(latent_feature, dim=1)\n",
    "print(out.sum()/21)\n",
    "f = out.detach().numpy()*coors.detach().numpy().T\n",
    "combined = np.column_stack(f).flatten()\n",
    "combined.reshape(-1, 3)\n",
    "d=divergence(combined)\n",
    "\n",
    "D=d.reshape(-1,3)\n",
    "[np.sum(d) for d in D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat, an = [19,20,21], [18]\n",
    "new_species = torch.zeros_like(species)\n",
    "\n",
    "# Set specified indices to 1\n",
    "new_species[an] = -1\n",
    "new_species[cat] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "species_strings = ['N', 'H', 'CA', 'HA', 'C', 'O', 'CB', 'HB2', 'HB3', 'CG', 'HG2', 'HG3', 'CD', 'HD2', 'HD3', 'CE', 'HE2', 'HE3', 'NZ', 'HZ1', 'HZ2', 'HZ3']\n",
    "\n",
    "# Create a tensor with 1s for hydrogen (species == 1) and 0s elsewhere\n",
    "feats = torch.where(species == 1, torch.tensor(1), torch.tensor(0)).unsqueeze(0)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(D[:, 0], D[:, 1], D[:, 2], label=\"Updated\")\n",
    "\n",
    "# Add labels to points\n",
    "for i in range(len(D)):\n",
    "    ax.text(D[i, 0], D[i, 1], D[i, 2], species_strings[i], fontsize=9)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"3D Position Transformation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
