{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs dir: ../../../data/pkegnn_INS/inputs/*.npz\n",
      "Whole model          : 32,510\n",
      "{'runid': '20250722_064106-noH', 'num_nbrs': 100, 'num_nbrs_egnn': 11, 'learning_rate': [0.005], 'dataset': ('../../../data/pkegnn_INS/inputs/*.npz', 7, 30), 'epochs': 30, 'dim': 12, 'depth': 2, 'basis': 8, 'hidden_dim': 4, 'num_heads': 20, 'dropout': [0.04, 0.03], 'rbf cutoff': 20.0, 'loss': L1Loss(), 'params': 32510}\n",
      "Epoch   0 | train L1 = 1.1970\n",
      "              |  val L1 = 1.2643\n",
      "Epoch   1 | train L1 = 1.1889\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a8d25777cecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;31m#model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_residues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_res\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# (R, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a8d25777cecc>\u001b[0m in \u001b[0;36mforward_residues\u001b[0;34m(z_r, x_r)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# ---------- RBF on *input* coords (already (R,N,3)) ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;31m#d   = torch.cdist(x_r, x_r)            # (R, N, N)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     \u001b[0mrbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbf_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m# (R, N, N, basis)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a8d25777cecc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dist)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutoff\u001b[0m     \u001b[0;31m# [K]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0md\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# [B,N,N,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "#from architecture import *\n",
    "#model=load_model(N_NEIGHBORS)\n",
    "#loaders=hoods(INPUT_DIR,N_NEIGHBORS)\n",
    "\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "from egnn_pytorch import EGNN_Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "\n",
    "#EGNN\n",
    "\n",
    "class EGNNBlock(nn.Module):\n",
    "    \"\"\"todo: try to take head out here\n",
    "    egnn_net --> layer norm --> ffn head\"\"\"\n",
    "    def __init__(self, dim, depth,hidden_dim,dropout,\n",
    "                 num_positions, num_tokens,\n",
    "                 num_nearest_neighbors,\n",
    "                 norm_coors):\n",
    "        super().__init__()\n",
    "        self.egnn = EGNN_Network(\n",
    "            dim=dim, depth=depth, dropout=dropout,\n",
    "            num_positions=num_positions,\n",
    "            num_tokens=num_tokens,\n",
    "            num_nearest_neighbors=num_nearest_neighbors,\n",
    "            norm_coors=norm_coors\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim*dim),\n",
    "            nn.PReLU(),# LU(),\n",
    "            nn.Linear(hidden_dim*dim, dim),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "    def forward(self, z, x):\n",
    "        (h_list, coords) = self.egnn(z, x)\n",
    "        h = h_list # [B,N,dim]\n",
    "        h2 = h\n",
    "        h  = self.norm1(h + h2)\n",
    "        h2 = self.ffn(h)\n",
    "        h  = self.norm2(h + h2)\n",
    "        return [h], coords\n",
    "\n",
    "class StackedEGNN(nn.Module):\n",
    "    \"\"\"TODO understand depth\"\"\"\n",
    "    def __init__(self, dim, depth, hidden_dim, dropout,\n",
    "                 num_positions, num_tokens,\n",
    "                 num_nearest_neighbors,\n",
    "                 norm_coors):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EGNNBlock(dim, depth, hidden_dim, dropout,\n",
    "                      num_positions, num_tokens,\n",
    "                      num_nearest_neighbors,\n",
    "                      norm_coors)\n",
    "            for _ in range(1)\n",
    "        ])\n",
    "    def forward(self, z, x):\n",
    "        coords = x\n",
    "        h_list = None\n",
    "        for block in self.blocks:\n",
    "            if h_list is None:\n",
    "                h_list, coords = block(z, x)\n",
    "            else:\n",
    "                h_list, coords = block(z, coords)\n",
    "        return h_list, coords\n",
    "\n",
    "# --- RBF with learnable cutoff ---\n",
    "class LearnableRBF(nn.Module):\n",
    "    \"\"\"TODO change cutout\"\"\"\n",
    "    def __init__(self, num_basis=16, cutoff=10.0):\n",
    "        super().__init__()\n",
    "        #self.pairwise = torch.norm(x.unsqueeze(1) - x.unsqueeze(0), dim=-1)\n",
    "        self.cutoff = nn.Parameter(torch.tensor(cutoff))\n",
    "        self.mu     = nn.Parameter(torch.linspace(0.0, 1.0, num_basis))\n",
    "        self.gamma  = nn.Parameter(torch.tensor(12.0))\n",
    "    \n",
    "    def pairwise_distances(self, dist):\n",
    "        return torch.norm(dist.unsqueeze(1) - dist.unsqueeze(0), dim=-1)\n",
    "\n",
    "    \n",
    "    def forward(self, dist):\n",
    "        # dist: [B,N,N]\n",
    "        dist = self.pairwise_distances(dist)\n",
    "        mu = self.mu * self.cutoff     # [K]\n",
    "        d  = dist.unsqueeze(-1)        # [B,N,N,1]\n",
    "        return torch.exp(-self.gamma * (d - mu)**2)\n",
    "\n",
    "\n",
    "#Attn. note encoding dropout of 0.03\n",
    "#TODO: SPECIFy max len and dropout.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=1000, dropout=0.03):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        pos = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float)\n",
    "                        * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        cosp = torch.cos(pos * div)\n",
    "        pe[:, 1::2] = cosp[:, : pe[:, 1::2].shape[1]]\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[: x.size(0)])\n",
    "\n",
    "# --- Transformer‐style AttentionBlock ---\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoding = PositionalEncoding(embed_dim)\n",
    "        self.attn  = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.ffn   = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(embed_dim * hidden_dim, embed_dim),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        # x: [seq_len, batch, embed_dim]\n",
    "        x = self.encoding(x)\n",
    "        a, _ = self.attn(x, x, x, key_padding_mask=key_padding_mask)\n",
    "        x    = self.norm1(x + a)\n",
    "        f    = self.ffn(x)\n",
    "        x    = self.norm2(x + f)\n",
    "        return x,_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import datetime, time\n",
    "#from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "#from pkegnn import *\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 100\n",
    "BATCH_SIZE  =  1         # not safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "conv=nn.Conv1d(1, 1, 7, padding=3).to(device)\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "# 3) instantiate everything\n",
    "dim, basis = 12, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=4\n",
    "dropout=0.04\n",
    "cutoff=20.0\n",
    "num_neighbors=11\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"-noH\"\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    B      = len(batch)\n",
    "    S_max  = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "\n",
    "    # --- allocate on CPU (no device=...) ---------------\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 )\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32)\n",
    "    ys   = torch.full  ((B, S_max), float(\"nan\"),  dtype=torch.float32)\n",
    "    mask = torch.zeros (B, S_max,               dtype=torch.bool)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs [b, :S] = z\n",
    "        pos[b, :S] = pos_b\n",
    "        ys [b, :S] = y\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask\n",
    "\n",
    "\n",
    "def count_params(model: torch.nn.Module, trainable_only: bool = True) -> int:\n",
    "    \"\"\"\n",
    "    Returns the total number of (optionally trainable) parameters.\n",
    "    \"\"\"\n",
    "    if trainable_only:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../../../data/pkegnn_INS/inputs/*.npz\"\n",
    "print(\"inputs dir:\", INPUTS_DIR)\n",
    "all_paths = sorted(glob.glob(INPUTS_DIR))\n",
    "#print(all_paths)\n",
    "#split=0.75\n",
    "#t=int(len(all_paths) *.75) - 1\n",
    "\n",
    "#v=int(len(all_paths) *.25)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:2] + all_paths[5:10], all_paths[20:50]\n",
    "#print(train_paths[0],val_paths[0])\n",
    "nconv=nn.Conv1d(N_NEIGHBORS,1,dim+basis).to(device)\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=dim + basis,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(1, 1).to(device)\n",
    "#pred_head2 = nn.Linear(1, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=True, norm_coors=True, norm_feats=True, fourier_features=6, valid_radius=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(conv.parameters()) +\n",
    "    list(nconv.parameters()) +\n",
    "\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "modell=[egnn_net, protein_egnn, nconv,rbf_layer,mha_layer,pred_head,conv] ####\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 30 # or whatever you like\n",
    "total_all    = count_params(torch.nn.ModuleList(\n",
    "                    modell))\n",
    "\n",
    "\n",
    "print(f\"Whole model          : {total_all:,}\")\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"num_nbrs\": N_NEIGHBORS,\n",
    "        \"num_nbrs_egnn\": num_neighbors,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds),len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"hidden_dim\":hidden_dim,\n",
    "        \"num_heads\":dim+basis, #!\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion,\n",
    "        \"params\":total_all}\n",
    "        #\"architect\":str(modell).encode()}\n",
    "\n",
    "print(config)\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "    \n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE) #TODO suppress _\n",
    "    tok=nconv(tok.to(device).permute(1,0,2)).to(device)\n",
    "    #tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); protein_egnn.train(); conv.train(); nconv.train();pred_head.train(); #p#red_head2.train(); \n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        #print(feats)\n",
    "        preds = pred_head(feats.to(device))    \n",
    "        t         = preds.to(device)[:,0].T.unsqueeze(2)         # (1, R, 1) on GPU\n",
    "        centroids = centroids.to(device)  # (1, R, 3) on GPU\n",
    "\n",
    "        protein_egnn = protein_egnn.to(device)             # make sure weights are there\n",
    "        preds = protein_egnn(t, centroids)[0].permute(1,2,0)\n",
    "        #preds = pred_head2(preds.to(device))\n",
    "        #loss  = criterion(preds.flatten(), y_res)\n",
    "        with autocast():\n",
    "                preds=conv(preds).to(device)\n",
    "\n",
    "                loss  = criterion(preds.flatten(), y_res)\n",
    "            \n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "    tmean=np.mean(tr_losses)\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {tmean:.4f}\")\n",
    "    tloss.append(tmean.item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); protein_egnn.eval(); conv.eval(); nconv.eval();pred_head.eval(); #pred_head2.eval(); \n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "            preds = pred_head(feats.to(device))    \n",
    "            t         = preds.to(device)[:,0].T.unsqueeze(2)         # (1, R, 1) on GPU\n",
    "            centroids = centroids.to(device)  # (1, R, 3) on GPU\n",
    "\n",
    "            protein_egnn = protein_egnn.to(device)             # make sure weights are there\n",
    "            preds = protein_egnn(t, centroids)[0].permute(1,2,0)\n",
    "            #preds = pred_head2(preds.to(device))\n",
    "            with autocast():\n",
    "                preds=conv(preds).to(device)\n",
    "\n",
    "                loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss) ###his is so inefficient. batch the proteins and for free bye cpu\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    if vl_losses: #cpu\n",
    "        vl=torch.mean(torch.stack(vl_losses))\n",
    "        print(f\"              |  val L1 = {vl.item():.4f}\")\n",
    "    else:\n",
    "        print(\"E70\")\n",
    "        \n",
    "    #L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(vl)\n",
    "    vloss.append(vl.item())\n",
    "    \n",
    "    if epoch in [100,200,300,400,500,600,700,800,900]: #TODO doesnt work\n",
    "        # 5) save a single timestamped checkpoint\n",
    "        elapsed_min = (time.time() - t0) / 60\n",
    "        timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        checkpoint = {\n",
    "            \"epoch\":         epoch+1,\n",
    "            \"elapsed_min\":   elapsed_min,\n",
    "            \"net\":           egnn_net.state_dict(),\n",
    "            \"mha\":           mha_layer.state_dict(),\n",
    "            \"model\":         protein_egnn.state_dict(),\n",
    "            \"convs\":         [conv.state_dict(), nconv.state_dict()],\n",
    "            \"lin\":           pred_head.state_dict(),\n",
    "            \"rbf\":           rbf_layer.state_dict(),\n",
    "            \"optimizer\":     optimizer.state_dict(),\n",
    "            \"scheduler\":     scheduler.state_dict(),\n",
    "            \"train_history\": tloss,\n",
    "            \"val_history\":   vloss,\n",
    "            \"config\":        config,\n",
    "        }\n",
    "        torch.save(checkpoint, f\"./checkpoints/benchmark_1049inputs_{runid}-checkpoint_{timestamp}.pt\")\n",
    "        #torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "        print(f\"Saved checkpoint ./checkpoints/benchmark_1049inputs_{runid}-checkpoint_{timestamp}.pt\", f\"({elapsed_min:.1f} min)\")\n",
    "        #os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"convs\":         [conv.state_dict(), nconv.state_dict()],\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "    \"config\":        config,\n",
    "}\n",
    "torch.save(checkpoint, f\"../../../data/all_checkpoints/think_{runid}-checkpoint_{timestamp}.pt\")\n",
    "#torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint ../../../data/all_checkpoints/think_{runid}-checkpoint_{timestamp}.pt\", elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#plt.plot(vloss)\n",
    "#plt.plot(tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs dir: ../../../data/pkegnn_INS/inputs/*.npz\n",
      "Whole model          : 32,510\n",
      "{'runid': '20250722_064258-noH', 'num_nbrs': 100, 'num_nbrs_egnn': 11, 'learning_rate': [0.005], 'dataset': ('../../../data/pkegnn_INS/inputs/*.npz', 7, 30), 'epochs': 30, 'dim': 12, 'depth': 2, 'basis': 8, 'hidden_dim': 4, 'num_heads': 20, 'dropout': [0.04, 0.03], 'rbf cutoff': 20.0, 'loss': MSELoss(), 'params': 32510}\n",
      "Epoch   0 | train L1 = 3.4039\n",
      "              |  val L1 = 3.5645\n",
      "Epoch   1 | train L1 = 3.3587\n",
      "              |  val L1 = 3.5654\n",
      "Epoch   2 | train L1 = 3.4136\n",
      "              |  val L1 = 3.5626\n",
      "Epoch   3 | train L1 = 3.3351\n",
      "              |  val L1 = 3.5361\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f5f0d5f8e766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mtr_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "#from architecture import *\n",
    "#model=load_model(N_NEIGHBORS)\n",
    "#loaders=hoods(INPUT_DIR,N_NEIGHBORS)\n",
    "\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "from egnn_pytorch import EGNN_Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "\n",
    "#EGNN\n",
    "\n",
    "class EGNNBlock(nn.Module):\n",
    "    \"\"\"todo: try to take head out here\n",
    "    egnn_net --> layer norm --> ffn head\"\"\"\n",
    "    def __init__(self, dim, depth,hidden_dim,dropout,\n",
    "                 num_positions, num_tokens,\n",
    "                 num_nearest_neighbors,\n",
    "                 norm_coors):\n",
    "        super().__init__()\n",
    "        self.egnn = EGNN_Network(\n",
    "            dim=dim, depth=depth, dropout=dropout,\n",
    "            num_positions=num_positions,\n",
    "            num_tokens=num_tokens,\n",
    "            num_nearest_neighbors=num_nearest_neighbors,\n",
    "            norm_coors=norm_coors\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim*dim),\n",
    "            nn.PReLU(),# LU(),\n",
    "            nn.Linear(hidden_dim*dim, dim),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "    def forward(self, z, x):\n",
    "        (h_list, coords) = self.egnn(z, x)\n",
    "        h = h_list # [B,N,dim]\n",
    "        h2 = h\n",
    "        h  = self.norm1(h + h2)\n",
    "        h2 = self.ffn(h)\n",
    "        h  = self.norm2(h + h2)\n",
    "        return [h], coords\n",
    "\n",
    "class StackedEGNN(nn.Module):\n",
    "    \"\"\"TODO understand depth\"\"\"\n",
    "    def __init__(self, dim, depth, hidden_dim, dropout,\n",
    "                 num_positions, num_tokens,\n",
    "                 num_nearest_neighbors,\n",
    "                 norm_coors):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EGNNBlock(dim, depth, hidden_dim, dropout,\n",
    "                      num_positions, num_tokens,\n",
    "                      num_nearest_neighbors,\n",
    "                      norm_coors)\n",
    "            for _ in range(1)\n",
    "        ])\n",
    "    def forward(self, z, x):\n",
    "        coords = x\n",
    "        h_list = None\n",
    "        for block in self.blocks:\n",
    "            if h_list is None:\n",
    "                h_list, coords = block(z, x)\n",
    "            else:\n",
    "                h_list, coords = block(z, coords)\n",
    "        return h_list, coords\n",
    "\n",
    "# --- RBF with learnable cutoff ---\n",
    "class LearnableRBF(nn.Module):\n",
    "    \"\"\"TODO change cutout\"\"\"\n",
    "    def __init__(self, num_basis=16, cutoff=10.0):\n",
    "        super().__init__()\n",
    "        #self.pairwise = torch.norm(x.unsqueeze(1) - x.unsqueeze(0), dim=-1)\n",
    "        self.cutoff = nn.Parameter(torch.tensor(cutoff))\n",
    "        self.mu     = nn.Parameter(torch.linspace(0.0, 1.0, num_basis))\n",
    "        self.gamma  = nn.Parameter(torch.tensor(12.0))\n",
    "    \n",
    "    def pairwise_distances(self, dist):\n",
    "        return torch.norm(dist.unsqueeze(1) - dist.unsqueeze(0), dim=-1)\n",
    "\n",
    "    \n",
    "    def forward(self, dist):\n",
    "        # dist: [B,N,N]\n",
    "        dist = self.pairwise_distances(dist)\n",
    "        mu = self.mu * self.cutoff     # [K]\n",
    "        d  = dist.unsqueeze(-1)        # [B,N,N,1]\n",
    "        return torch.exp(-self.gamma * (d - mu)**2)\n",
    "\n",
    "\n",
    "#Attn. note encoding dropout of 0.03\n",
    "#TODO: SPECIFy max len and dropout.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=1000, dropout=0.03):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        pos = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float)\n",
    "                        * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        cosp = torch.cos(pos * div)\n",
    "        pe[:, 1::2] = cosp[:, : pe[:, 1::2].shape[1]]\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[: x.size(0)])\n",
    "\n",
    "# --- Transformer‐style AttentionBlock ---\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoding = PositionalEncoding(embed_dim)\n",
    "        self.attn  = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.ffn   = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(embed_dim * hidden_dim, embed_dim),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        # x: [seq_len, batch, embed_dim]\n",
    "        x = self.encoding(x)\n",
    "        a, _ = self.attn(x, x, x, key_padding_mask=key_padding_mask)\n",
    "        x    = self.norm1(x + a)\n",
    "        f    = self.ffn(x)\n",
    "        x    = self.norm2(x + f)\n",
    "        return x,_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import datetime, time\n",
    "#from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "#from pkegnn import *\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 100\n",
    "BATCH_SIZE  =  1         # not safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "conv=nn.Conv1d(1, 1, 7, padding=3).to(device)\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "# 3) instantiate everything\n",
    "dim, basis = 12, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=4\n",
    "dropout=0.04\n",
    "cutoff=20.0\n",
    "num_neighbors=11\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"-noH\"\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    B      = len(batch)\n",
    "    S_max  = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "\n",
    "    # --- allocate on CPU (no device=...) ---------------\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 )\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32)\n",
    "    ys   = torch.full  ((B, S_max), float(\"nan\"),  dtype=torch.float32)\n",
    "    mask = torch.zeros (B, S_max,               dtype=torch.bool)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs [b, :S] = z\n",
    "        pos[b, :S] = pos_b\n",
    "        ys [b, :S] = y\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask\n",
    "\n",
    "\n",
    "def count_params(model: torch.nn.Module, trainable_only: bool = True) -> int:\n",
    "    \"\"\"\n",
    "    Returns the total number of (optionally trainable) parameters.\n",
    "    \"\"\"\n",
    "    if trainable_only:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../../../data/pkegnn_INS/inputs/*.npz\"\n",
    "print(\"inputs dir:\", INPUTS_DIR)\n",
    "all_paths = sorted(glob.glob(INPUTS_DIR))\n",
    "#print(all_paths)\n",
    "#split=0.75\n",
    "#t=int(len(all_paths) *.75) - 1\n",
    "\n",
    "#v=int(len(all_paths) *.25)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:2] + all_paths[5:10], all_paths[20:50]\n",
    "#print(train_paths[0],val_paths[0])\n",
    "nconv=nn.Conv1d(N_NEIGHBORS,1,dim+basis).to(device)\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=dim + basis,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(1, 1).to(device)\n",
    "#pred_head2 = nn.Linear(1, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=True, norm_coors=True, norm_feats=True, fourier_features=6, valid_radius=8)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(conv.parameters()) +\n",
    "    list(nconv.parameters()) +\n",
    "\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "modell=[egnn_net, protein_egnn, nconv,rbf_layer,mha_layer,pred_head,conv] ####\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 30 # or whatever you like\n",
    "total_all    = count_params(torch.nn.ModuleList(\n",
    "                    modell))\n",
    "\n",
    "\n",
    "print(f\"Whole model          : {total_all:,}\")\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"num_nbrs\": N_NEIGHBORS,\n",
    "        \"num_nbrs_egnn\": num_neighbors,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds),len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"hidden_dim\":hidden_dim,\n",
    "        \"num_heads\":dim+basis, #!\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion,\n",
    "        \"params\":total_all}\n",
    "        #\"architect\":str(modell).encode()}\n",
    "\n",
    "print(config)\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "    \n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE) #TODO suppress _\n",
    "    tok=nconv(tok.to(device).permute(1,0,2)).to(device)\n",
    "    #tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); protein_egnn.train(); conv.train(); nconv.train();pred_head.train(); #p#red_head2.train(); \n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        #print(feats)\n",
    "        preds = pred_head(feats.to(device))    \n",
    "        t         = preds.to(device)[:,0].T.unsqueeze(2)         # (1, R, 1) on GPU\n",
    "        centroids = centroids.to(device)  # (1, R, 3) on GPU\n",
    "\n",
    "        protein_egnn = protein_egnn.to(device)             # make sure weights are there\n",
    "        preds = protein_egnn(t, centroids)[0].permute(1,2,0)\n",
    "        #preds = pred_head2(preds.to(device))\n",
    "        #loss  = criterion(preds.flatten(), y_res)\n",
    "        with autocast():\n",
    "                preds=conv(preds).to(device)\n",
    "\n",
    "                loss  = criterion(preds.flatten(), y_res)\n",
    "            \n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "    tmean=np.mean(tr_losses)\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {tmean:.4f}\")\n",
    "    tloss.append(tmean.item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); protein_egnn.eval(); conv.eval(); nconv.eval();pred_head.eval(); #pred_head2.eval(); \n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "            preds = pred_head(feats.to(device))    \n",
    "            t         = preds.to(device)[:,0].T.unsqueeze(2)         # (1, R, 1) on GPU\n",
    "            centroids = centroids.to(device)  # (1, R, 3) on GPU\n",
    "\n",
    "            protein_egnn = protein_egnn.to(device)             # make sure weights are there\n",
    "            preds = protein_egnn(t, centroids)[0].permute(1,2,0)\n",
    "            #preds = pred_head2(preds.to(device))\n",
    "            with autocast():\n",
    "                preds=conv(preds).to(device)\n",
    "\n",
    "                loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss) ###his is so inefficient. batch the proteins and for free bye cpu\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    if vl_losses: #cpu\n",
    "        vl=torch.mean(torch.stack(vl_losses))\n",
    "        print(f\"              |  val L1 = {vl.item():.4f}\")\n",
    "    else:\n",
    "        print(\"E70\")\n",
    "        \n",
    "    #L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(vl)\n",
    "    vloss.append(vl.item())\n",
    "    \n",
    "    if epoch in [100,200,300,400,500,600,700,800,900]: #TODO doesnt work\n",
    "        # 5) save a single timestamped checkpoint\n",
    "        elapsed_min = (time.time() - t0) / 60\n",
    "        timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        checkpoint = {\n",
    "            \"epoch\":         epoch+1,\n",
    "            \"elapsed_min\":   elapsed_min,\n",
    "            \"net\":           egnn_net.state_dict(),\n",
    "            \"mha\":           mha_layer.state_dict(),\n",
    "            \"model\":         protein_egnn.state_dict(),\n",
    "            \"convs\":         [conv.state_dict(), nconv.state_dict()],\n",
    "            \"lin\":           pred_head.state_dict(),\n",
    "            \"rbf\":           rbf_layer.state_dict(),\n",
    "            \"optimizer\":     optimizer.state_dict(),\n",
    "            \"scheduler\":     scheduler.state_dict(),\n",
    "            \"train_history\": tloss,\n",
    "            \"val_history\":   vloss,\n",
    "            \"config\":        config,\n",
    "        }\n",
    "        torch.save(checkpoint, f\"./checkpoints/benchmark_1049inputs_{runid}-checkpoint_{timestamp}.pt\")\n",
    "        #torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "        print(f\"Saved checkpoint ./checkpoints/benchmark_1049inputs_{runid}-checkpoint_{timestamp}.pt\", f\"({elapsed_min:.1f} min)\")\n",
    "        #os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"convs\":         [conv.state_dict(), nconv.state_dict()],\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "    \"config\":        config,\n",
    "}\n",
    "torch.save(checkpoint, f\"../../../data/all_checkpoints/think_{runid}-checkpoint_{timestamp}.pt\")\n",
    "#torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint ../../../data/all_checkpoints/think_{runid}-checkpoint_{timestamp}.pt\", elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#plt.plot(vloss)\n",
    "#plt.plot(tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs dir: ../../../data/pkegnn_INS/inputs/*.npz\n",
      "Whole model          : 8,300\n",
      "{'runid': '20250722_070304-noH', 'num_nbrs': 100, 'num_nbrs_egnn': 11, 'learning_rate': [0.005], 'dataset': ('../../../data/pkegnn_INS/inputs/*.npz', 7, 30), 'epochs': 30, 'dim': 2, 'depth': 2, 'basis': 3, 'hidden_dim': 4, 'num_heads': 5, 'dropout': [0.01, 0.03], 'rbf cutoff': 20.0, 'loss': MSELoss(), 'params': 8300}\n",
      "Epoch   0 | train L1 = 3.4387\n",
      "              |  val L1 = 3.5404\n",
      "Epoch   1 | train L1 = 3.3785\n",
      "              |  val L1 = 3.5102\n",
      "Epoch   2 | train L1 = 3.3216\n",
      "              |  val L1 = 3.4797\n",
      "Epoch   3 | train L1 = 3.3790\n",
      "              |  val L1 = 3.4402\n",
      "Epoch   4 | train L1 = 3.2455\n",
      "              |  val L1 = 3.3964\n",
      "Epoch   5 | train L1 = 3.1465\n",
      "              |  val L1 = 3.3739\n",
      "Epoch   6 | train L1 = 3.1250\n",
      "              |  val L1 = 3.2656\n",
      "Epoch   7 | train L1 = 3.0110\n",
      "              |  val L1 = 3.1852\n",
      "Epoch   8 | train L1 = 2.9403\n",
      "              |  val L1 = 3.0988\n",
      "Epoch   9 | train L1 = 2.8295\n",
      "              |  val L1 = 2.9957\n",
      "Epoch  10 | train L1 = 2.7409\n",
      "              |  val L1 = 2.9368\n",
      "Epoch  11 | train L1 = 2.6935\n",
      "              |  val L1 = 2.9027\n",
      "Epoch  12 | train L1 = 2.7223\n",
      "              |  val L1 = 2.9044\n",
      "Epoch  13 | train L1 = 2.6377\n",
      "              |  val L1 = 2.9253\n",
      "Epoch  14 | train L1 = 2.6243\n",
      "              |  val L1 = 2.8549\n",
      "Epoch  15 | train L1 = 2.8390\n",
      "              |  val L1 = 2.8988\n",
      "Epoch  16 | train L1 = 2.5958\n",
      "              |  val L1 = 2.9885\n",
      "Epoch  17 | train L1 = 2.6158\n",
      "              |  val L1 = 2.8305\n",
      "Epoch  18 | train L1 = 2.5595\n",
      "              |  val L1 = 2.8702\n",
      "Epoch  19 | train L1 = 2.5965\n",
      "              |  val L1 = 2.8485\n",
      "Epoch  20 | train L1 = 2.5118\n",
      "              |  val L1 = 2.8473\n",
      "Epoch  21 | train L1 = 2.5203\n",
      "              |  val L1 = 2.8609\n",
      "Epoch  22 | train L1 = 2.5126\n",
      "              |  val L1 = 2.8864\n",
      "Epoch  23 | train L1 = 2.4990\n",
      "              |  val L1 = 2.8754\n",
      "Epoch  24 | train L1 = 2.5340\n",
      "              |  val L1 = 2.8765\n",
      "Epoch  25 | train L1 = 2.5254\n",
      "              |  val L1 = 2.9628\n",
      "Epoch  26 | train L1 = 2.5899\n",
      "              |  val L1 = 2.8973\n",
      "Epoch  27 | train L1 = 2.5280\n",
      "              |  val L1 = 2.9268\n",
      "Epoch  28 | train L1 = 2.4844\n",
      "              |  val L1 = 2.8732\n",
      "Epoch  29 | train L1 = 2.4985\n",
      "              |  val L1 = 2.8782\n",
      "Saved checkpoint ../../../data/all_checkpoints/think_20250722_070304-noH-checkpoint_20250722_071713.pt 14.149751456578572\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "#from architecture import *\n",
    "#model=load_model(N_NEIGHBORS)\n",
    "#loaders=hoods(INPUT_DIR,N_NEIGHBORS)\n",
    "\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "from egnn_pytorch import EGNN_Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "\n",
    "#EGNN\n",
    "\n",
    "class EGNNBlock(nn.Module):\n",
    "    \"\"\"todo: try to take head out here\n",
    "    egnn_net --> layer norm --> ffn head\"\"\"\n",
    "    def __init__(self, dim, depth,hidden_dim,dropout,\n",
    "                 num_positions, num_tokens,\n",
    "                 num_nearest_neighbors,\n",
    "                 norm_coors):\n",
    "        super().__init__()\n",
    "        self.egnn = EGNN_Network(\n",
    "            dim=dim, depth=depth, dropout=dropout,\n",
    "            num_positions=num_positions,\n",
    "            num_tokens=num_tokens,\n",
    "            num_nearest_neighbors=num_nearest_neighbors,\n",
    "            norm_coors=norm_coors\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim*dim),\n",
    "            nn.PReLU(),# LU(),\n",
    "            nn.Linear(hidden_dim*dim, dim),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "    def forward(self, z, x):\n",
    "        (h_list, coords) = self.egnn(z, x)\n",
    "        h = h_list # [B,N,dim]\n",
    "        h2 = h\n",
    "        h  = self.norm1(h + h2)\n",
    "        h2 = self.ffn(h)\n",
    "        h  = self.norm2(h + h2)\n",
    "        return [h], coords\n",
    "\n",
    "class StackedEGNN(nn.Module):\n",
    "    \"\"\"TODO understand depth\"\"\"\n",
    "    def __init__(self, dim, depth, hidden_dim, dropout,\n",
    "                 num_positions, num_tokens,\n",
    "                 num_nearest_neighbors,\n",
    "                 norm_coors):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EGNNBlock(dim, depth, hidden_dim, dropout,\n",
    "                      num_positions, num_tokens,\n",
    "                      num_nearest_neighbors,\n",
    "                      norm_coors)\n",
    "            for _ in range(1)\n",
    "        ])\n",
    "    def forward(self, z, x):\n",
    "        coords = x\n",
    "        h_list = None\n",
    "        for block in self.blocks:\n",
    "            if h_list is None:\n",
    "                h_list, coords = block(z, x)\n",
    "            else:\n",
    "                h_list, coords = block(z, coords)\n",
    "        return h_list, coords\n",
    "\n",
    "# --- RBF with learnable cutoff ---\n",
    "class LearnableRBF(nn.Module):\n",
    "    \"\"\"TODO change cutout\"\"\"\n",
    "    def __init__(self, num_basis=16, cutoff=10.0):\n",
    "        super().__init__()\n",
    "        #self.pairwise = torch.norm(x.unsqueeze(1) - x.unsqueeze(0), dim=-1)\n",
    "        self.cutoff = nn.Parameter(torch.tensor(cutoff))\n",
    "        self.mu     = nn.Parameter(torch.linspace(0.0, 1.0, num_basis))\n",
    "        self.gamma  = nn.Parameter(torch.tensor(12.0))\n",
    "    \n",
    "    def pairwise_distances(self, dist):\n",
    "        return torch.norm(dist.unsqueeze(1) - dist.unsqueeze(0), dim=-1)\n",
    "\n",
    "    \n",
    "    def forward(self, dist):\n",
    "        # dist: [B,N,N]\n",
    "        dist = self.pairwise_distances(dist)\n",
    "        mu = self.mu * self.cutoff     # [K]\n",
    "        d  = dist.unsqueeze(-1)        # [B,N,N,1]\n",
    "        return torch.exp(-self.gamma * (d - mu)**2)\n",
    "\n",
    "\n",
    "#Attn. note encoding dropout of 0.03\n",
    "#TODO: SPECIFy max len and dropout.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=1000, dropout=0.03):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        pos = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float)\n",
    "                        * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        cosp = torch.cos(pos * div)\n",
    "        pe[:, 1::2] = cosp[:, : pe[:, 1::2].shape[1]]\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[: x.size(0)])\n",
    "\n",
    "# --- Transformer‐style AttentionBlock ---\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoding = PositionalEncoding(embed_dim)\n",
    "        self.attn  = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.ffn   = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(embed_dim * hidden_dim, embed_dim),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        # x: [seq_len, batch, embed_dim]\n",
    "        x = self.encoding(x)\n",
    "        a, _ = self.attn(x, x, x, key_padding_mask=key_padding_mask)\n",
    "        x    = self.norm1(x + a)\n",
    "        f    = self.ffn(x)\n",
    "        x    = self.norm2(x + f)\n",
    "        return x,_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import datetime, time\n",
    "#from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "#from pkegnn import *\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 100\n",
    "BATCH_SIZE  =  1         # not safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "conv=nn.Conv1d(1, 1, 7, padding=3).to(device)\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 3 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=4\n",
    "dropout=0.01\n",
    "cutoff=20.0\n",
    "num_neighbors=11\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"-noH\"\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    B      = len(batch)\n",
    "    S_max  = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "\n",
    "    # --- allocate on CPU (no device=...) ---------------\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 )\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32)\n",
    "    ys   = torch.full  ((B, S_max), float(\"nan\"),  dtype=torch.float32)\n",
    "    mask = torch.zeros (B, S_max,               dtype=torch.bool)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs [b, :S] = z\n",
    "        pos[b, :S] = pos_b\n",
    "        ys [b, :S] = y\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask\n",
    "\n",
    "\n",
    "def count_params(model: torch.nn.Module, trainable_only: bool = True) -> int:\n",
    "    \"\"\"\n",
    "    Returns the total number of (optionally trainable) parameters.\n",
    "    \"\"\"\n",
    "    if trainable_only:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../../../data/pkegnn_INS/inputs/*.npz\"\n",
    "print(\"inputs dir:\", INPUTS_DIR)\n",
    "all_paths = sorted(glob.glob(INPUTS_DIR))\n",
    "#print(all_paths)\n",
    "#split=0.75\n",
    "#t=int(len(all_paths) *.75) - 1\n",
    "\n",
    "#v=int(len(all_paths) *.25)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:2] + all_paths[5:10], all_paths[20:50]\n",
    "#print(train_paths[0],val_paths[0])\n",
    "nconv=nn.Conv1d(N_NEIGHBORS,1,dim+basis).to(device)\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=dim + basis,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(1, 1).to(device)\n",
    "#pred_head2 = nn.Linear(1, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=True, norm_coors=True, norm_feats=True, fourier_features=6, valid_radius=8)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(conv.parameters()) +\n",
    "    list(nconv.parameters()) +\n",
    "\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "modell=[egnn_net, protein_egnn, nconv,rbf_layer,mha_layer,pred_head,conv] ####\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 30 # or whatever you like\n",
    "total_all    = count_params(torch.nn.ModuleList(\n",
    "                    modell))\n",
    "\n",
    "\n",
    "print(f\"Whole model          : {total_all:,}\")\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"num_nbrs\": N_NEIGHBORS,\n",
    "        \"num_nbrs_egnn\": num_neighbors,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds),len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"hidden_dim\":hidden_dim,\n",
    "        \"num_heads\":dim+basis, #!\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion,\n",
    "        \"params\":total_all}\n",
    "        #\"architect\":str(modell).encode()}\n",
    "\n",
    "print(config)\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "    \n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE) #TODO suppress _\n",
    "    tok=nconv(tok.to(device).permute(1,0,2)).to(device)\n",
    "    #tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); protein_egnn.train(); conv.train(); nconv.train();pred_head.train(); #p#red_head2.train(); \n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        #print(feats)\n",
    "        preds = pred_head(feats.to(device))    \n",
    "        t         = preds.to(device)[:,0].T.unsqueeze(2)         # (1, R, 1) on GPU\n",
    "        centroids = centroids.to(device)  # (1, R, 3) on GPU\n",
    "\n",
    "        protein_egnn = protein_egnn.to(device)             # make sure weights are there\n",
    "        preds = protein_egnn(t, centroids)[0].permute(1,2,0)\n",
    "        #preds = pred_head2(preds.to(device))\n",
    "        #loss  = criterion(preds.flatten(), y_res)\n",
    "        with autocast():\n",
    "                preds=conv(preds).to(device)\n",
    "\n",
    "                loss  = criterion(preds.flatten(), y_res)\n",
    "            \n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "    tmean=np.mean(tr_losses)\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {tmean:.4f}\")\n",
    "    tloss.append(tmean.item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); protein_egnn.eval(); conv.eval(); nconv.eval();pred_head.eval(); #pred_head2.eval(); \n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "            preds = pred_head(feats.to(device))    \n",
    "            t         = preds.to(device)[:,0].T.unsqueeze(2)         # (1, R, 1) on GPU\n",
    "            centroids = centroids.to(device)  # (1, R, 3) on GPU\n",
    "\n",
    "            protein_egnn = protein_egnn.to(device)             # make sure weights are there\n",
    "            preds = protein_egnn(t, centroids)[0].permute(1,2,0)\n",
    "            #preds = pred_head2(preds.to(device))\n",
    "            with autocast():\n",
    "                preds=conv(preds).to(device)\n",
    "\n",
    "                loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss) ###his is so inefficient. batch the proteins and for free bye cpu\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    if vl_losses: #cpu\n",
    "        vl=torch.mean(torch.stack(vl_losses))\n",
    "        print(f\"              |  val L1 = {vl.item():.4f}\")\n",
    "    else:\n",
    "        print(\"E70\")\n",
    "        \n",
    "    #L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(vl)\n",
    "    vloss.append(vl.item())\n",
    "    \n",
    "    if epoch in [100,200,300,400,500,600,700,800,900]: #TODO doesnt work\n",
    "        # 5) save a single timestamped checkpoint\n",
    "        elapsed_min = (time.time() - t0) / 60\n",
    "        timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        checkpoint = {\n",
    "            \"epoch\":         epoch+1,\n",
    "            \"elapsed_min\":   elapsed_min,\n",
    "            \"net\":           egnn_net.state_dict(),\n",
    "            \"mha\":           mha_layer.state_dict(),\n",
    "            \"model\":         protein_egnn.state_dict(),\n",
    "            \"convs\":         [conv.state_dict(), nconv.state_dict()],\n",
    "            \"lin\":           pred_head.state_dict(),\n",
    "            \"rbf\":           rbf_layer.state_dict(),\n",
    "            \"optimizer\":     optimizer.state_dict(),\n",
    "            \"scheduler\":     scheduler.state_dict(),\n",
    "            \"train_history\": tloss,\n",
    "            \"val_history\":   vloss,\n",
    "            \"config\":        config,\n",
    "        }\n",
    "        torch.save(checkpoint, f\"./checkpoints/benchmark_1049inputs_{runid}-checkpoint_{timestamp}.pt\")\n",
    "        #torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "        print(f\"Saved checkpoint ./checkpoints/benchmark_1049inputs_{runid}-checkpoint_{timestamp}.pt\", f\"({elapsed_min:.1f} min)\")\n",
    "        #os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"convs\":         [conv.state_dict(), nconv.state_dict()],\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "    \"config\":        config,\n",
    "}\n",
    "torch.save(checkpoint, f\"../../../data/all_checkpoints/think_{runid}-checkpoint_{timestamp}.pt\")\n",
    "#torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint ../../../data/all_checkpoints/think_{runid}-checkpoint_{timestamp}.pt\", elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#plt.plot(vloss)\n",
    "#plt.plot(tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs dir: ../../../data/pkegnn_INS/inputs/*.npz\n",
      "Whole model          : 8,170\n",
      "{'runid': '20250722_064838-noH', 'num_nbrs': 100, 'num_nbrs_egnn': 11, 'learning_rate': [0.005], 'dataset': ('../../../data/pkegnn_INS/inputs/*.npz', 7, 30), 'epochs': 30, 'dim': 2, 'depth': 2, 'basis': 3, 'hidden_dim': 2, 'num_heads': 5, 'dropout': [0.01, 0.03], 'rbf cutoff': 20.0, 'loss': MSELoss(), 'params': 8170}\n",
      "Epoch   0 | train L1 = 3.4201\n",
      "              |  val L1 = 3.5333\n",
      "Epoch   1 | train L1 = 3.3301\n",
      "              |  val L1 = 3.5031\n",
      "Epoch   2 | train L1 = 3.3419\n",
      "              |  val L1 = 3.4873\n",
      "Epoch   3 | train L1 = 3.3260\n",
      "              |  val L1 = 3.4646\n",
      "Epoch   4 | train L1 = 3.2425\n",
      "              |  val L1 = 3.4168\n",
      "Epoch   5 | train L1 = 3.1919\n",
      "              |  val L1 = 3.4210\n",
      "Epoch   6 | train L1 = 3.1190\n",
      "              |  val L1 = 3.3061\n",
      "Epoch   7 | train L1 = 3.0348\n",
      "              |  val L1 = 3.2341\n",
      "Epoch   8 | train L1 = 2.9286\n",
      "              |  val L1 = 3.1698\n",
      "Epoch   9 | train L1 = 2.8849\n",
      "              |  val L1 = 3.0513\n",
      "Epoch  10 | train L1 = 2.7313\n",
      "              |  val L1 = 3.0060\n",
      "Epoch  11 | train L1 = 2.7805\n",
      "              |  val L1 = 2.9647\n",
      "Epoch  12 | train L1 = 2.7559\n",
      "              |  val L1 = 2.9254\n",
      "Epoch  13 | train L1 = 2.6983\n",
      "              |  val L1 = 2.9479\n",
      "Epoch  14 | train L1 = 2.6202\n",
      "              |  val L1 = 2.9183\n",
      "Epoch  15 | train L1 = 2.5073\n",
      "              |  val L1 = 2.9616\n",
      "Epoch  16 | train L1 = 2.5439\n",
      "              |  val L1 = 2.8970\n",
      "Epoch  17 | train L1 = 2.5486\n",
      "              |  val L1 = 2.9025\n",
      "Epoch  18 | train L1 = 2.5714\n",
      "              |  val L1 = 2.8929\n",
      "Epoch  19 | train L1 = 2.4952\n",
      "              |  val L1 = 2.8789\n",
      "Epoch  20 | train L1 = 2.5248\n",
      "              |  val L1 = 2.8993\n",
      "Epoch  21 | train L1 = 2.5217\n",
      "              |  val L1 = 2.8781\n",
      "Epoch  22 | train L1 = 3.2169\n",
      "              |  val L1 = 3.0764\n",
      "Epoch  23 | train L1 = 2.7106\n",
      "              |  val L1 = 2.9037\n",
      "Epoch  24 | train L1 = 2.6066\n",
      "              |  val L1 = 2.9261\n",
      "Epoch  25 | train L1 = 2.5609\n",
      "              |  val L1 = 2.8891\n",
      "Epoch  26 | train L1 = 2.6745\n",
      "              |  val L1 = 2.9079\n",
      "Epoch  27 | train L1 = 2.5376\n",
      "              |  val L1 = 2.8822\n",
      "Epoch  28 | train L1 = 2.6173\n",
      "              |  val L1 = 2.8905\n",
      "Epoch  29 | train L1 = 2.6610\n",
      "              |  val L1 = 2.9204\n",
      "Saved checkpoint ../../../data/all_checkpoints/think_20250722_064838-noH-checkpoint_20250722_070250.pt 14.19367785056432\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "#from architecture import *\n",
    "#model=load_model(N_NEIGHBORS)\n",
    "#loaders=hoods(INPUT_DIR,N_NEIGHBORS)\n",
    "\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "from egnn_pytorch import EGNN_Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "\n",
    "#EGNN\n",
    "\n",
    "class EGNNBlock(nn.Module):\n",
    "    \"\"\"todo: try to take head out here\n",
    "    egnn_net --> layer norm --> ffn head\"\"\"\n",
    "    def __init__(self, dim, depth,hidden_dim,dropout,\n",
    "                 num_positions, num_tokens,\n",
    "                 num_nearest_neighbors,\n",
    "                 norm_coors):\n",
    "        super().__init__()\n",
    "        self.egnn = EGNN_Network(\n",
    "            dim=dim, depth=depth, dropout=dropout,\n",
    "            num_positions=num_positions,\n",
    "            num_tokens=num_tokens,\n",
    "            num_nearest_neighbors=num_nearest_neighbors,\n",
    "            norm_coors=norm_coors\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim*dim),\n",
    "            nn.PReLU(),# LU(),\n",
    "            nn.Linear(hidden_dim*dim, dim),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "    def forward(self, z, x):\n",
    "        (h_list, coords) = self.egnn(z, x)\n",
    "        h = h_list # [B,N,dim]\n",
    "        h2 = h\n",
    "        h  = self.norm1(h + h2)\n",
    "        h2 = self.ffn(h)\n",
    "        h  = self.norm2(h + h2)\n",
    "        return [h], coords\n",
    "\n",
    "class StackedEGNN(nn.Module):\n",
    "    \"\"\"TODO understand depth\"\"\"\n",
    "    def __init__(self, dim, depth, hidden_dim, dropout,\n",
    "                 num_positions, num_tokens,\n",
    "                 num_nearest_neighbors,\n",
    "                 norm_coors):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EGNNBlock(dim, depth, hidden_dim, dropout,\n",
    "                      num_positions, num_tokens,\n",
    "                      num_nearest_neighbors,\n",
    "                      norm_coors)\n",
    "            for _ in range(1)\n",
    "        ])\n",
    "    def forward(self, z, x):\n",
    "        coords = x\n",
    "        h_list = None\n",
    "        for block in self.blocks:\n",
    "            if h_list is None:\n",
    "                h_list, coords = block(z, x)\n",
    "            else:\n",
    "                h_list, coords = block(z, coords)\n",
    "        return h_list, coords\n",
    "\n",
    "# --- RBF with learnable cutoff ---\n",
    "class LearnableRBF(nn.Module):\n",
    "    \"\"\"TODO change cutout\"\"\"\n",
    "    def __init__(self, num_basis=16, cutoff=10.0):\n",
    "        super().__init__()\n",
    "        #self.pairwise = torch.norm(x.unsqueeze(1) - x.unsqueeze(0), dim=-1)\n",
    "        self.cutoff = nn.Parameter(torch.tensor(cutoff))\n",
    "        self.mu     = nn.Parameter(torch.linspace(0.0, 1.0, num_basis))\n",
    "        self.gamma  = nn.Parameter(torch.tensor(12.0))\n",
    "    \n",
    "    def pairwise_distances(self, dist):\n",
    "        return torch.norm(dist.unsqueeze(1) - dist.unsqueeze(0), dim=-1)\n",
    "\n",
    "    \n",
    "    def forward(self, dist):\n",
    "        # dist: [B,N,N]\n",
    "        dist = self.pairwise_distances(dist)\n",
    "        mu = self.mu * self.cutoff     # [K]\n",
    "        d  = dist.unsqueeze(-1)        # [B,N,N,1]\n",
    "        return torch.exp(-self.gamma * (d - mu)**2)\n",
    "\n",
    "\n",
    "#Attn. note encoding dropout of 0.03\n",
    "#TODO: SPECIFy max len and dropout.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=1000, dropout=0.03):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        pos = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float)\n",
    "                        * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        cosp = torch.cos(pos * div)\n",
    "        pe[:, 1::2] = cosp[:, : pe[:, 1::2].shape[1]]\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[: x.size(0)])\n",
    "\n",
    "# --- Transformer‐style AttentionBlock ---\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoding = PositionalEncoding(embed_dim)\n",
    "        self.attn  = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.ffn   = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * hidden_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(embed_dim * hidden_dim, embed_dim),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        # x: [seq_len, batch, embed_dim]\n",
    "        x = self.encoding(x)\n",
    "        a, _ = self.attn(x, x, x, key_padding_mask=key_padding_mask)\n",
    "        x    = self.norm1(x + a)\n",
    "        f    = self.ffn(x)\n",
    "        x    = self.norm2(x + f)\n",
    "        return x,_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import datetime, time\n",
    "#from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "#from pkegnn import *\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 100\n",
    "BATCH_SIZE  =  1         # not safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "conv=nn.Conv1d(1, 1, 7, padding=3).to(device)\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 3 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=2\n",
    "dropout=0.01\n",
    "cutoff=20.0\n",
    "num_neighbors=11\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"-noH\"\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    B      = len(batch)\n",
    "    S_max  = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "\n",
    "    # --- allocate on CPU (no device=...) ---------------\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 )\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32)\n",
    "    ys   = torch.full  ((B, S_max), float(\"nan\"),  dtype=torch.float32)\n",
    "    mask = torch.zeros (B, S_max,               dtype=torch.bool)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs [b, :S] = z\n",
    "        pos[b, :S] = pos_b\n",
    "        ys [b, :S] = y\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask\n",
    "\n",
    "\n",
    "def count_params(model: torch.nn.Module, trainable_only: bool = True) -> int:\n",
    "    \"\"\"\n",
    "    Returns the total number of (optionally trainable) parameters.\n",
    "    \"\"\"\n",
    "    if trainable_only:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../../../data/pkegnn_INS/inputs/*.npz\"\n",
    "print(\"inputs dir:\", INPUTS_DIR)\n",
    "all_paths = sorted(glob.glob(INPUTS_DIR))\n",
    "#print(all_paths)\n",
    "#split=0.75\n",
    "#t=int(len(all_paths) *.75) - 1\n",
    "\n",
    "#v=int(len(all_paths) *.25)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:2] + all_paths[5:10], all_paths[20:50]\n",
    "#print(train_paths[0],val_paths[0])\n",
    "nconv=nn.Conv1d(N_NEIGHBORS,1,dim+basis).to(device)\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=dim + basis,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(1, 1).to(device)\n",
    "#pred_head2 = nn.Linear(1, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=True, norm_coors=True, norm_feats=True, fourier_features=6, valid_radius=8)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(conv.parameters()) +\n",
    "    list(nconv.parameters()) +\n",
    "\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "modell=[egnn_net, protein_egnn, nconv,rbf_layer,mha_layer,pred_head,conv] ####\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 30 # or whatever you like\n",
    "total_all    = count_params(torch.nn.ModuleList(\n",
    "                    modell))\n",
    "\n",
    "\n",
    "print(f\"Whole model          : {total_all:,}\")\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"num_nbrs\": N_NEIGHBORS,\n",
    "        \"num_nbrs_egnn\": num_neighbors,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds),len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"hidden_dim\":hidden_dim,\n",
    "        \"num_heads\":dim+basis, #!\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion,\n",
    "        \"params\":total_all}\n",
    "        #\"architect\":str(modell).encode()}\n",
    "\n",
    "print(config)\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "    \n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE) #TODO suppress _\n",
    "    tok=nconv(tok.to(device).permute(1,0,2)).to(device)\n",
    "    #tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); protein_egnn.train(); conv.train(); nconv.train();pred_head.train(); #p#red_head2.train(); \n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        #print(feats)\n",
    "        preds = pred_head(feats.to(device))    \n",
    "        t         = preds.to(device)[:,0].T.unsqueeze(2)         # (1, R, 1) on GPU\n",
    "        centroids = centroids.to(device)  # (1, R, 3) on GPU\n",
    "\n",
    "        protein_egnn = protein_egnn.to(device)             # make sure weights are there\n",
    "        preds = protein_egnn(t, centroids)[0].permute(1,2,0)\n",
    "        #preds = pred_head2(preds.to(device))\n",
    "        #loss  = criterion(preds.flatten(), y_res)\n",
    "        with autocast():\n",
    "                preds=conv(preds).to(device)\n",
    "\n",
    "                loss  = criterion(preds.flatten(), y_res)\n",
    "            \n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "    tmean=np.mean(tr_losses)\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {tmean:.4f}\")\n",
    "    tloss.append(tmean.item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); protein_egnn.eval(); conv.eval(); nconv.eval();pred_head.eval(); #pred_head2.eval(); \n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "            preds = pred_head(feats.to(device))    \n",
    "            t         = preds.to(device)[:,0].T.unsqueeze(2)         # (1, R, 1) on GPU\n",
    "            centroids = centroids.to(device)  # (1, R, 3) on GPU\n",
    "\n",
    "            protein_egnn = protein_egnn.to(device)             # make sure weights are there\n",
    "            preds = protein_egnn(t, centroids)[0].permute(1,2,0)\n",
    "            #preds = pred_head2(preds.to(device))\n",
    "            with autocast():\n",
    "                preds=conv(preds).to(device)\n",
    "\n",
    "                loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss) ###his is so inefficient. batch the proteins and for free bye cpu\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    if vl_losses: #cpu\n",
    "        vl=torch.mean(torch.stack(vl_losses))\n",
    "        print(f\"              |  val L1 = {vl.item():.4f}\")\n",
    "    else:\n",
    "        print(\"E70\")\n",
    "        \n",
    "    #L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(vl)\n",
    "    vloss.append(vl.item())\n",
    "    \n",
    "    if epoch in [100,200,300,400,500,600,700,800,900]: #TODO doesnt work\n",
    "        # 5) save a single timestamped checkpoint\n",
    "        elapsed_min = (time.time() - t0) / 60\n",
    "        timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        checkpoint = {\n",
    "            \"epoch\":         epoch+1,\n",
    "            \"elapsed_min\":   elapsed_min,\n",
    "            \"net\":           egnn_net.state_dict(),\n",
    "            \"mha\":           mha_layer.state_dict(),\n",
    "            \"model\":         protein_egnn.state_dict(),\n",
    "            \"convs\":         [conv.state_dict(), nconv.state_dict()],\n",
    "            \"lin\":           pred_head.state_dict(),\n",
    "            \"rbf\":           rbf_layer.state_dict(),\n",
    "            \"optimizer\":     optimizer.state_dict(),\n",
    "            \"scheduler\":     scheduler.state_dict(),\n",
    "            \"train_history\": tloss,\n",
    "            \"val_history\":   vloss,\n",
    "            \"config\":        config,\n",
    "        }\n",
    "        torch.save(checkpoint, f\"./checkpoints/benchmark_1049inputs_{runid}-checkpoint_{timestamp}.pt\")\n",
    "        #torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "        print(f\"Saved checkpoint ./checkpoints/benchmark_1049inputs_{runid}-checkpoint_{timestamp}.pt\", f\"({elapsed_min:.1f} min)\")\n",
    "        #os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"convs\":         [conv.state_dict(), nconv.state_dict()],\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "    \"config\":        config,\n",
    "}\n",
    "torch.save(checkpoint, f\"../../../data/all_checkpoints/think_{runid}-checkpoint_{timestamp}.pt\")\n",
    "#torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint ../../../data/all_checkpoints/think_{runid}-checkpoint_{timestamp}.pt\", elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#plt.plot(vloss)\n",
    "#plt.plot(tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
