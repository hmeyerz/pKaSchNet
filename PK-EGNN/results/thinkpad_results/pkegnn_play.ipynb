{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.2356\n",
      "              |  val L1 = 1.1295\n",
      "Epoch   1 | train L1 = 1.1770\n",
      "              |  val L1 = 1.0956\n",
      "Epoch   2 | train L1 = 1.1546\n",
      "              |  val L1 = 1.0406\n",
      "Epoch   3 | train L1 = 1.1256\n",
      "              |  val L1 = 1.0146\n",
      "Epoch   4 | train L1 = 1.1073\n",
      "              |  val L1 = 1.0132\n",
      "Epoch   5 | train L1 = 1.1076\n",
      "              |  val L1 = 0.9852\n",
      "Epoch   6 | train L1 = 1.1029\n",
      "              |  val L1 = 0.9681\n",
      "Epoch   7 | train L1 = 1.0883\n",
      "              |  val L1 = 0.9632\n",
      "Epoch   8 | train L1 = 1.0987\n",
      "              |  val L1 = 0.9729\n",
      "Epoch   9 | train L1 = 1.1257\n",
      "              |  val L1 = 1.0661\n",
      "Epoch  10 | train L1 = 1.1613\n",
      "              |  val L1 = 1.0608\n",
      "Epoch  11 | train L1 = 1.1604\n",
      "              |  val L1 = 1.0141\n",
      "Epoch  12 | train L1 = 1.1258\n",
      "              |  val L1 = 1.0110\n",
      "Epoch  13 | train L1 = 1.1140\n",
      "              |  val L1 = 1.0060\n",
      "Epoch  14 | train L1 = 1.0900\n",
      "              |  val L1 = 1.0023\n",
      "Epoch  15 | train L1 = 1.0942\n",
      "              |  val L1 = 1.0541\n",
      "Epoch  16 | train L1 = 1.2079\n",
      "              |  val L1 = 1.1686\n",
      "Epoch  17 | train L1 = 1.2054\n",
      "              |  val L1 = 1.1587\n",
      "Epoch  18 | train L1 = 1.1952\n",
      "              |  val L1 = 1.1582\n",
      "Epoch  19 | train L1 = 1.2093\n",
      "              |  val L1 = 1.1488\n",
      "Epoch  20 | train L1 = 1.1942\n",
      "              |  val L1 = 1.1387\n",
      "Saved checkpoint_20250713_204823.pt (0.8 min) 0.7634433150291443\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 15\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=256\n",
    "num_global_tokens=256\n",
    "dropout=0.02\n",
    "cutoff=10.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../inputs/*.npz\"\n",
    "all_paths = glob.glob(INPUTS_DIR)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 21  # or whatever you like\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds) + len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"num edge and global tokens\": [num_edge_tokens,num_global_tokens],\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "    tloss.append(np.mean(tr_losses).item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss.item())\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n",
    "    scheduler.step(loss) \n",
    "    vloss.append(np.mean(vl_losses).item())\n",
    "    \n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "}\n",
    "torch.save(checkpoint, f\"./{runid}-checkpoint_{timestamp}.pt\")\n",
    "torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\",elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fix scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.2356\n",
      "              |  val L1 = 1.1295\n",
      "Epoch   1 | train L1 = 1.1770\n",
      "              |  val L1 = 1.0956\n",
      "Epoch   2 | train L1 = 1.1575\n",
      "              |  val L1 = 1.0465\n",
      "Epoch   3 | train L1 = 1.1255\n",
      "              |  val L1 = 1.0123\n",
      "Epoch   4 | train L1 = 1.1085\n",
      "              |  val L1 = 1.0101\n",
      "Epoch   5 | train L1 = 1.1098\n",
      "              |  val L1 = 0.9833\n",
      "Epoch   6 | train L1 = 1.1022\n",
      "              |  val L1 = 0.9626\n",
      "Epoch   7 | train L1 = 1.0896\n",
      "              |  val L1 = 0.9661\n",
      "Epoch   8 | train L1 = 1.0962\n",
      "              |  val L1 = 0.9800\n",
      "Epoch   9 | train L1 = 1.0910\n",
      "              |  val L1 = 1.0344\n",
      "Epoch  10 | train L1 = 1.1102\n",
      "              |  val L1 = 1.0579\n",
      "Epoch  11 | train L1 = 1.1028\n",
      "              |  val L1 = 0.9507\n",
      "Epoch  12 | train L1 = 1.0994\n",
      "              |  val L1 = 0.9421\n",
      "Epoch  13 | train L1 = 1.0836\n",
      "              |  val L1 = 0.9418\n",
      "Epoch  14 | train L1 = 1.0606\n",
      "              |  val L1 = 0.9340\n",
      "Epoch  15 | train L1 = 1.0533\n",
      "              |  val L1 = 0.9259\n",
      "Epoch  16 | train L1 = 1.0583\n",
      "              |  val L1 = 0.9150\n",
      "Epoch  17 | train L1 = 1.0199\n",
      "              |  val L1 = 0.8991\n",
      "Epoch  18 | train L1 = 1.0081\n",
      "              |  val L1 = 0.9181\n",
      "Epoch  19 | train L1 = 1.0192\n",
      "              |  val L1 = 0.8912\n",
      "Epoch  20 | train L1 = 0.9983\n",
      "              |  val L1 = 0.9034\n",
      "Saved checkpoint_20250713_205241.pt (0.8 min) 0.8459444920221965\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 15\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=256\n",
    "num_global_tokens=256\n",
    "dropout=0.02\n",
    "cutoff=10.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../inputs/*.npz\"\n",
    "all_paths = glob.glob(INPUTS_DIR)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 21  # or whatever you like\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds) + len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"num edge and global tokens\": [num_edge_tokens,num_global_tokens],\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "    tloss.append(np.mean(tr_losses).item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss)\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n",
    "    L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(L)\n",
    "    vloss.append(L.item())\n",
    "    \n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "}\n",
    "torch.save(checkpoint, f\"./{runid}-checkpoint_{timestamp}.pt\")\n",
    "torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\",elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.2356\n",
      "              |  val L1 = 1.1295\n",
      "Epoch   1 | train L1 = 1.1770\n",
      "              |  val L1 = 1.0956\n",
      "Epoch   2 | train L1 = 1.1575\n",
      "              |  val L1 = 1.0465\n",
      "Epoch   3 | train L1 = 1.1255\n",
      "              |  val L1 = 1.0123\n",
      "Epoch   4 | train L1 = 1.1085\n",
      "              |  val L1 = 1.0101\n",
      "Epoch   5 | train L1 = 1.1098\n",
      "              |  val L1 = 0.9833\n",
      "Epoch   6 | train L1 = 1.1022\n",
      "              |  val L1 = 0.9626\n",
      "Epoch   7 | train L1 = 1.0896\n",
      "              |  val L1 = 0.9661\n",
      "Epoch   8 | train L1 = 1.0964\n",
      "              |  val L1 = 0.9841\n",
      "Epoch   9 | train L1 = 1.0933\n",
      "              |  val L1 = 1.0415\n",
      "Epoch  10 | train L1 = 1.1144\n",
      "              |  val L1 = 1.0438\n",
      "Epoch  11 | train L1 = 1.1100\n",
      "              |  val L1 = 0.9604\n",
      "Epoch  12 | train L1 = 1.0953\n",
      "              |  val L1 = 0.9550\n",
      "Epoch  13 | train L1 = 1.0857\n",
      "              |  val L1 = 0.9498\n",
      "Epoch  14 | train L1 = 1.0760\n",
      "              |  val L1 = 0.9426\n",
      "Epoch  15 | train L1 = 1.0604\n",
      "              |  val L1 = 0.9507\n",
      "Epoch  16 | train L1 = 1.0770\n",
      "              |  val L1 = 0.9310\n",
      "Epoch  17 | train L1 = 1.0464\n",
      "              |  val L1 = 0.9230\n",
      "Epoch  18 | train L1 = 1.0294\n",
      "              |  val L1 = 0.9169\n",
      "Epoch  19 | train L1 = 1.0303\n",
      "              |  val L1 = 0.9143\n",
      "Epoch  20 | train L1 = 1.0200\n",
      "              |  val L1 = 0.9008\n",
      "Saved checkpoint_20250713_205401.pt (0.9 min) 0.857046910127004\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 15\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=256\n",
    "num_global_tokens=256\n",
    "dropout=0.02\n",
    "cutoff=10.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../inputs/*.npz\"\n",
    "all_paths = glob.glob(INPUTS_DIR)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 21  # or whatever you like\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds) + len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"num edge and global tokens\": [num_edge_tokens,num_global_tokens],\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "    tloss.append(np.mean(tr_losses).item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss)\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n",
    "    L=torch.mean(torch.stack(vl_losses))\n",
    "    #scheduler.step(L)\n",
    "    vloss.append(L.item())\n",
    "    \n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "}\n",
    "torch.save(checkpoint, f\"./{runid}-checkpoint_{timestamp}.pt\")\n",
    "torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\")\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500 neighhb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.3514\n",
      "              |  val L1 = 1.1910\n",
      "Epoch   1 | train L1 = 1.2250\n",
      "              |  val L1 = 1.1788\n",
      "Epoch   2 | train L1 = 1.2219\n",
      "              |  val L1 = 1.1743\n",
      "Epoch   3 | train L1 = 1.2180\n",
      "              |  val L1 = 1.1764\n",
      "Epoch   4 | train L1 = 1.2070\n",
      "              |  val L1 = 1.1663\n",
      "Epoch   5 | train L1 = 1.2033\n",
      "              |  val L1 = 1.1773\n",
      "Epoch   6 | train L1 = 1.1979\n",
      "              |  val L1 = 1.1735\n",
      "Epoch   7 | train L1 = 1.1861\n",
      "              |  val L1 = 1.1799\n",
      "Epoch   8 | train L1 = 1.1892\n",
      "              |  val L1 = 1.1799\n",
      "Epoch   9 | train L1 = 1.1859\n",
      "              |  val L1 = 1.1859\n",
      "Saved checkpoint_20250713_210810.pt (7.9 min) 7.94516411225001\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 200\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=10\n",
    "num_global_tokens=10\n",
    "dropout=0.02\n",
    "cutoff=20.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../inputs/*.npz\"\n",
    "all_paths = glob.glob(INPUTS_DIR)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 10  # or whatever you like\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds) + len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"num edge and global tokens\": [num_edge_tokens,num_global_tokens],\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "    tloss.append(np.mean(tr_losses).item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss)\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n",
    "    L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(L)\n",
    "    vloss.append(L.item())\n",
    "    \n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "    \"config\":        config,\n",
    "}\n",
    "torch.save(checkpoint, f\"./{runid}-checkpoint_{timestamp}.pt\")\n",
    "torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\",elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 200\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=10\n",
    "num_global_tokens=10\n",
    "dropout=0.02\n",
    "cutoff=20.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../inputs/*.npz\"\n",
    "all_paths = glob.glob(INPUTS_DIR)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 10  # or whatever you like\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds) + len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"num edge and global tokens\": [num_edge_tokens,num_global_tokens],\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "    tloss.append(np.mean(tr_losses).item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss)\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n",
    "    L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(L)\n",
    "    vloss.append(L.item())\n",
    "    \n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "    \"config\":        config,\n",
    "}\n",
    "torch.save(checkpoint, f\"./{runid}-checkpoint_{timestamp}.pt\")\n",
    "torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\",elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(vloss)\n",
    "plt.plot(tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd63b6fdbe0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(vloss)\n",
    "plt.plot(tloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.2774\n",
      "              |  val L1 = 1.1737\n",
      "Epoch   1 | train L1 = 1.2256\n",
      "              |  val L1 = 1.1772\n",
      "Epoch   2 | train L1 = 1.2328\n",
      "              |  val L1 = 1.1695\n",
      "Epoch   3 | train L1 = 1.2238\n",
      "              |  val L1 = 1.1768\n",
      "Epoch   4 | train L1 = 1.2128\n",
      "              |  val L1 = 1.1652\n",
      "Epoch   5 | train L1 = 1.2160\n",
      "              |  val L1 = 1.1475\n",
      "Epoch   6 | train L1 = 1.1904\n",
      "              |  val L1 = 1.1052\n",
      "Epoch   7 | train L1 = 1.1674\n",
      "              |  val L1 = 1.0540\n",
      "Epoch   8 | train L1 = 1.1476\n",
      "              |  val L1 = 1.0413\n",
      "Epoch   9 | train L1 = 1.1455\n",
      "              |  val L1 = 1.0148\n",
      "Saved checkpoint_20250713_211846.pt (3.8 min) 3.8067312598228455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd63dae4668>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 100\n",
    "BATCH_SIZE  =  1         # not safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=10\n",
    "num_global_tokens=10\n",
    "dropout=0.02\n",
    "cutoff=20.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the (not) variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../inputs/*.npz\"\n",
    "all_paths = glob.glob(INPUTS_DIR)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 10  # or whatever you like\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds) + len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"num edge and global tokens\": [num_edge_tokens,num_global_tokens],\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "    tloss.append(np.mean(tr_losses).item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss)\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n",
    "    L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(L)\n",
    "    vloss.append(L.item())\n",
    "    \n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "    \"config\":        config,\n",
    "}\n",
    "torch.save(checkpoint, f\"./{runid}-checkpoint_{timestamp}.pt\")\n",
    "torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\",elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(vloss)\n",
    "plt.plot(tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.3376\n",
      "              |  val L1 = 1.1855\n",
      "Epoch   1 | train L1 = 1.2257\n",
      "              |  val L1 = 1.1819\n",
      "Epoch   2 | train L1 = 1.2231\n",
      "              |  val L1 = 1.1741\n",
      "Epoch   3 | train L1 = 1.2204\n",
      "              |  val L1 = 1.1762\n",
      "Epoch   4 | train L1 = 1.2125\n",
      "              |  val L1 = 1.1718\n",
      "Epoch   5 | train L1 = 1.2018\n",
      "              |  val L1 = 1.1737\n",
      "Epoch   6 | train L1 = 1.1969\n",
      "              |  val L1 = 1.1747\n",
      "Epoch   7 | train L1 = 1.1814\n",
      "              |  val L1 = 1.1865\n",
      "Epoch   8 | train L1 = 1.1826\n",
      "              |  val L1 = 1.1812\n",
      "Epoch   9 | train L1 = 1.1824\n",
      "              |  val L1 = 1.2160\n",
      "Saved checkpoint_20250713_212415.pt (4.8 min) 4.841254552205403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd63dab59e8>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 150\n",
    "BATCH_SIZE  =  1         # not safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=10\n",
    "num_global_tokens=10\n",
    "dropout=0.02\n",
    "cutoff=20.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the (not) variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../inputs/*.npz\"\n",
    "all_paths = glob.glob(INPUTS_DIR)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 10  # or whatever you like\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds) + len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"num edge and global tokens\": [num_edge_tokens,num_global_tokens],\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "    tloss.append(np.mean(tr_losses).item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss)\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n",
    "    L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(L)\n",
    "    vloss.append(L.item())\n",
    "    \n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "    \"config\":        config,\n",
    "}\n",
    "torch.save(checkpoint, f\"./{runid}-checkpoint_{timestamp}.pt\")\n",
    "torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\",elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(vloss)\n",
    "plt.plot(tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.2774\n",
      "              |  val L1 = 1.1737\n",
      "Epoch   1 | train L1 = 1.2256\n",
      "              |  val L1 = 1.1772\n",
      "Epoch   2 | train L1 = 1.2328\n",
      "              |  val L1 = 1.1695\n",
      "Epoch   3 | train L1 = 1.2238\n",
      "              |  val L1 = 1.1768\n",
      "Epoch   4 | train L1 = 1.2128\n",
      "              |  val L1 = 1.1652\n",
      "Epoch   5 | train L1 = 1.2160\n",
      "              |  val L1 = 1.1475\n",
      "Epoch   6 | train L1 = 1.1904\n",
      "              |  val L1 = 1.1052\n",
      "Epoch   7 | train L1 = 1.1674\n",
      "              |  val L1 = 1.0540\n",
      "Epoch   8 | train L1 = 1.1476\n",
      "              |  val L1 = 1.0413\n",
      "Epoch   9 | train L1 = 1.1455\n",
      "              |  val L1 = 1.0148\n",
      "Saved checkpoint_20250713_212837.pt (2.9 min) 2.866321818033854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd63db0fda0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from egnn_pytorch import EGNN\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 100\n",
    "BATCH_SIZE  =  1         # not safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=N_NEIGHBORS, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=10\n",
    "num_global_tokens=10\n",
    "dropout=0.02\n",
    "cutoff=20.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the (not) variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "INPUTS_DIR=\"../inputs/*.npz\"\n",
    "all_paths = glob.glob(INPUTS_DIR)\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "epochs = 10  # or whatever you like\n",
    "\n",
    "config={\"runid\": runid,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": (INPUTS_DIR,len(train_ds) + len(val_ds)),\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"num edge and global tokens\": [num_edge_tokens,num_global_tokens],\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"loss\": criterion}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "tloss, vloss = [], []\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "    tmean=np.mean(tr_losses)\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {tmean:.4f}\")\n",
    "    tloss.append(tmean.item())\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss)\n",
    "\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    vl=torch.mean(vl_losses)\n",
    "    print(f\"              |  val L1 = {vl.item():.4f}\")\n",
    "    L=torch.mean(torch.stack(vl_losses))\n",
    "    scheduler.step(L)\n",
    "    vloss.append(L.item())\n",
    "    \n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           egnn_net.state_dict(),\n",
    "    \"mha\":           mha_layer.state_dict(),\n",
    "    \"model\":         protein_egnn.state_dict(),\n",
    "    \"lin\":           pred_head.state_dict(),\n",
    "    \"rbf\":           rbf_layer.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tloss,\n",
    "    \"val_history\":   vloss,\n",
    "    \"config\":        config,\n",
    "}\n",
    "torch.save(checkpoint, f\"./results/{runid}-checkpoint_{timestamp}.pt\")\n",
    "#torch.save(checkpoint, f\"./test-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\",elapsed_min)\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(vloss)\n",
    "plt.plot(tloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
