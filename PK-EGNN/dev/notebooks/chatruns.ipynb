{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run‑ID: 20250726_215148\n",
      "params 17695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] train MAE:1.3717 | val MAE:1.0425 || train MSE:3.8119 | val MSE:2.1939\n",
      "[2/5] train MAE:1.3013 | val MAE:1.1405 || train MSE:3.7406 | val MSE:2.5144\n",
      "[3/5] train MAE:1.3006 | val MAE:1.0161 || train MSE:3.7640 | val MSE:2.1072\n",
      "[4/5] train MAE:1.2782 | val MAE:1.0175 || train MSE:3.6054 | val MSE:2.1122\n",
      "[5/5] train MAE:1.2581 | val MAE:1.0355 || train MSE:3.5746 | val MSE:2.1833\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "import numpy as np\n",
    "from egnn_pytorch import EGNN\n",
    "from architecture import (StackedEGNN,\n",
    "                          LearnableRBF,\n",
    "                          AttentionBlock,\n",
    "                          TunableBlock)\n",
    "import time, datetime\n",
    "import glob\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ================================================================\n",
    "# 0) dashboard  – tweak here\n",
    "# ================================================================\n",
    "class Cfg(dict):\n",
    "    __getattr__ = dict.__getitem__; __setattr__ = dict.__setitem__\n",
    "cfg = Cfg(\n",
    "    dim=12, basis=6, depth=2, hidden_dim=4, dropout=0.02,\n",
    "    num_neighbors=8, hood_k=100,                      # <── hood size\n",
    "    aggregator='linear', use_rbf=False, use_attn=False,\n",
    "    use_nconv=False, use_pred_head=True,\n",
    "    norm_coors=True,\n",
    "\n",
    "    loss_type='mae', sched_metric='val_mae', study_metrics=True,\n",
    "    lr=5e-3, epochs=5, batch_size=1, device='cpu',\n",
    "    seed=0, analysis_mode=False, save_attn=False,      # <── new switch\n",
    "    num_paths=4,                                   # cap #files\n",
    "    split_mode='random', split_ratio=0.8, split_seed=0,\n",
    "    runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    ")\n",
    "print(\"Run‑ID:\", cfg.runid)\n",
    "\n",
    "# ================================================================\n",
    "# 1) reproducibility\n",
    "# ================================================================\n",
    "import random, os, numpy as np, torch, glob, datetime\n",
    "random.seed(cfg.seed);  np.random.seed(cfg.seed);  torch.manual_seed(cfg.seed)\n",
    "torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# ================================================================\n",
    "# 2) helper: split + dataset + collate\n",
    "# ================================================================\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class InMemDS(Dataset):\n",
    "    def __init__(self, paths, k):\n",
    "        self.data=[]; self.ids=[]\n",
    "        nbr=NearestNeighbors(k, algorithm='brute')\n",
    "        for p in paths:\n",
    "            try:\n",
    "                d=np.load(p, allow_pickle=True)\n",
    "                z,pos,sites,y=d['z'],d['pos'],d['sites'],d['pks']\n",
    "                if len(sites)==0: continue\n",
    "                nbr.fit(pos); idx=nbr.kneighbors(sites,return_distance=False)\n",
    "                self.data.append((torch.from_numpy(z[idx]),\n",
    "                                  torch.from_numpy(pos[idx]),\n",
    "                                  torch.from_numpy(y)))\n",
    "                self.ids.append(os.path.splitext(os.path.basename(p))[0])\n",
    "            except Exception as e: print(\"skip\",p,e)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        z,pos,y=self.data[i]\n",
    "        return (z,pos,y,self.ids[i])\n",
    "\n",
    "def pad(batch, k, device, return_ids):\n",
    "    if return_ids: ids=[b[3] for b in batch]\n",
    "    B=len(batch); S=max(b[0].shape[0] for b in batch)\n",
    "    zs=torch.zeros(B,S,k,dtype=torch.int32,device=device)\n",
    "    pos=torch.zeros(B,S,k,3,dtype=torch.float32,device=device)\n",
    "    ys=torch.full((B,S),float('nan'),device=device)\n",
    "    mask=torch.zeros(B,S,dtype=torch.bool,device=device)\n",
    "    for b,(z,p,y,_) in enumerate(batch):\n",
    "        s=z.shape[0]; zs[b,:s]=z.to(device); pos[b,:s]=p.to(device)\n",
    "        ys[b,:s]=y.to(device); mask[b,:s]=True\n",
    "    return (zs,pos,ys,mask,ids) if return_ids else (zs,pos,ys,mask)\n",
    "\n",
    "def split(paths):\n",
    "    if cfg.num_paths: paths=paths[:cfg.num_paths]\n",
    "    rng=np.random.RandomState(cfg.split_seed)\n",
    "    idx=rng.permutation(len(paths)); cut=int(len(paths)*cfg.split_ratio)\n",
    "    return [paths[i] for i in idx[:cut]], [paths[i] for i in idx[cut:]]\n",
    "\n",
    "# ================================================================\n",
    "# 3) model (unchanged architecture.py)\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,c):\n",
    "        super().__init__()\n",
    "        self.egnn=StackedEGNN(c.dim,c.depth,c.hidden_dim,c.dropout,\n",
    "                              c.hood_k,98,c.num_neighbors,c.norm_coors).to(c.device)\n",
    "        self.rbf =TunableBlock(LearnableRBF(c.basis,10.).to(c.device),c.use_rbf)\n",
    "        self.attn=TunableBlock(AttentionBlock(c.dim+c.basis,c.dim+c.basis,c.hidden_dim)\\\n",
    "                               .to(c.device),c.use_attn)\n",
    "        if c.aggregator.startswith('nconv'):\n",
    "            self.nconv=nn.Conv1d(c.hood_k,1,c.dim+c.basis).to(c.device)\n",
    "            out=1\n",
    "        else: self.nconv=None; out=c.dim+c.basis\n",
    "        self.head=nn.Linear(out,1).to(c.device) if c.use_pred_head else nn.Identity()\n",
    "        self.prot=EGNN(dim=1,update_coors=True,num_nearest_neighbors=3).to(c.device)\n",
    "    def forward(self,z,x):\n",
    "        h,coord=self.egnn(z,x); h=h[0]\n",
    "        cent=coord.mean(1,keepdim=True)\n",
    "        r=self.rbf(cent,coord) if cfg.use_rbf else h.new_zeros(h.size(0),cfg.hood_k,cfg.basis)\n",
    "        tok=torch.cat((r.transpose(1,2),h.transpose(1,2)),1)\n",
    "        tok,_=self.attn(tok.permute(2,0,1)); tok=tok.permute(1,0,2)\n",
    "        tok=self.nconv(tok).squeeze(-1) if self.nconv is not None else tok.max(1).values\n",
    "        p=self.head(tok); p=self.prot(p.unsqueeze(0),cent.permute(1,0,2))[0].squeeze(0)\n",
    "        return p\n",
    "model=Model(cfg); print(\"params\",sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# ================================================================\n",
    "# 4) loaders\n",
    "# ================================================================\n",
    "allp=glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "tr,val=split(allp)\n",
    "tr_ds=InMemDS(tr,cfg.hood_k); val_ds=InMemDS(val,cfg.hood_k)\n",
    "collate=lambda b: pad(b,cfg.hood_k,cfg.device,cfg.analysis_mode)\n",
    "tr_loader=DataLoader(tr_ds,batch_size=cfg.batch_size,shuffle=True,collate_fn=collate)\n",
    "va_loader=DataLoader(val_ds,batch_size=cfg.batch_size,shuffle=False,collate_fn=collate)\n",
    "\n",
    "# ================================================================\n",
    "# 5) training util\n",
    "# ================================================================\n",
    "primary_fn = nn.L1Loss() if cfg.loss_type=='mae' else nn.MSELoss()\n",
    "secondary_fn= nn.MSELoss() if cfg.study_metrics and cfg.loss_type=='mae' else \\\n",
    "              nn.L1Loss() if cfg.study_metrics else None\n",
    "pname='MAE' if cfg.loss_type=='mae' else 'MSE'; sname='MSE' if pname=='MAE' else 'MAE'\n",
    "opt=torch.optim.AdamW(model.parameters(),lr=cfg.lr)\n",
    "sch=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,'min',0.5,3)\n",
    "scaler=GradScaler(enabled=(cfg.device=='cuda'))\n",
    "\n",
    "def run(loader,train):\n",
    "    model.train() if train else model.eval()\n",
    "    ps=ss=0;n=0\n",
    "    for batch in loader:\n",
    "        if cfg.analysis_mode: z,x,y,m,ids=batch\n",
    "        else:                 z,x,y,m=batch\n",
    "        v=m.view(-1); z=z.view(-1,z.size(2))[v].to(cfg.device)\n",
    "        x=x.view(-1,x.size(2),3)[v].to(cfg.device); y=y.view(-1)[v].to(cfg.device)\n",
    "        with autocast(enabled=(cfg.device=='cuda')):\n",
    "            pred=model(z,x).flatten(); loss=primary_fn(pred,y)\n",
    "            sec=secondary_fn(pred,y).item() if secondary_fn else 0.0\n",
    "        if train:\n",
    "            opt.zero_grad(); scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        ps+=loss.item(); ss+=sec; n+=1\n",
    "    return ps/n, (ss/n if secondary_fn else None)\n",
    "\n",
    "# ================================================================\n",
    "# 6) train\n",
    "# ================================================================\n",
    "for e in range(cfg.epochs):\n",
    "    tr_p,tr_s=run(tr_loader,True)\n",
    "    va_p,va_s=run(va_loader,False)\n",
    "    sch.step(va_p)\n",
    "    msg=f\"[{e+1}/{cfg.epochs}] train {pname}:{tr_p:.4f} | val {pname}:{va_p:.4f}\"\n",
    "    if secondary_fn: msg+=f\" || train {sname}:{tr_s:.4f} | val {sname}:{va_s:.4f}\"\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run‑ID: 20250726_215321\n",
      "params 17695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-593010b842cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mtr_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0mva_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mva_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0msch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-593010b842cc>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(loader, train)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprimary_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0msec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msecondary_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-593010b842cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_rbf\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhood_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnconv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "import numpy as np\n",
    "from egnn_pytorch import EGNN\n",
    "from architecture import (StackedEGNN,\n",
    "                          LearnableRBF,\n",
    "                          AttentionBlock,\n",
    "                          TunableBlock)\n",
    "import time, datetime\n",
    "import glob\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ================================================================\n",
    "# 0) dashboard  – tweak here\n",
    "# ================================================================\n",
    "class Cfg(dict):\n",
    "    __getattr__ = dict.__getitem__; __setattr__ = dict.__setitem__\n",
    "cfg = Cfg(\n",
    "    dim=12, basis=6, depth=2, hidden_dim=4, dropout=0.02,\n",
    "    num_neighbors=8, hood_k=100,                      # <── hood size\n",
    "    aggregator='linear', use_rbf=True, use_attn=False,\n",
    "    use_nconv=False, use_pred_head=True,\n",
    "    norm_coors=True,\n",
    "\n",
    "    loss_type='mae', sched_metric='val_mae', study_metrics=True,\n",
    "    lr=5e-3, epochs=5, batch_size=1, device='cpu',\n",
    "    seed=0, analysis_mode=False, save_attn=False,      # <── new switch\n",
    "    num_paths=4,                                   # cap #files\n",
    "    split_mode='random', split_ratio=0.8, split_seed=0,\n",
    "    runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    ")\n",
    "print(\"Run‑ID:\", cfg.runid)\n",
    "\n",
    "# ================================================================\n",
    "# 1) reproducibility\n",
    "# ================================================================\n",
    "import random, os, numpy as np, torch, glob, datetime\n",
    "random.seed(cfg.seed);  np.random.seed(cfg.seed);  torch.manual_seed(cfg.seed)\n",
    "torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# ================================================================\n",
    "# 2) helper: split + dataset + collate\n",
    "# ================================================================\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class InMemDS(Dataset):\n",
    "    def __init__(self, paths, k):\n",
    "        self.data=[]; self.ids=[]\n",
    "        nbr=NearestNeighbors(k, algorithm='brute')\n",
    "        for p in paths:\n",
    "            try:\n",
    "                d=np.load(p, allow_pickle=True)\n",
    "                z,pos,sites,y=d['z'],d['pos'],d['sites'],d['pks']\n",
    "                if len(sites)==0: continue\n",
    "                nbr.fit(pos); idx=nbr.kneighbors(sites,return_distance=False)\n",
    "                self.data.append((torch.from_numpy(z[idx]),\n",
    "                                  torch.from_numpy(pos[idx]),\n",
    "                                  torch.from_numpy(y)))\n",
    "                self.ids.append(os.path.splitext(os.path.basename(p))[0])\n",
    "            except Exception as e: print(\"skip\",p,e)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        z,pos,y=self.data[i]\n",
    "        return (z,pos,y,self.ids[i])\n",
    "\n",
    "def pad(batch, k, device, return_ids):\n",
    "    if return_ids: ids=[b[3] for b in batch]\n",
    "    B=len(batch); S=max(b[0].shape[0] for b in batch)\n",
    "    zs=torch.zeros(B,S,k,dtype=torch.int32,device=device)\n",
    "    pos=torch.zeros(B,S,k,3,dtype=torch.float32,device=device)\n",
    "    ys=torch.full((B,S),float('nan'),device=device)\n",
    "    mask=torch.zeros(B,S,dtype=torch.bool,device=device)\n",
    "    for b,(z,p,y,_) in enumerate(batch):\n",
    "        s=z.shape[0]; zs[b,:s]=z.to(device); pos[b,:s]=p.to(device)\n",
    "        ys[b,:s]=y.to(device); mask[b,:s]=True\n",
    "    return (zs,pos,ys,mask,ids) if return_ids else (zs,pos,ys,mask)\n",
    "\n",
    "def split(paths):\n",
    "    if cfg.num_paths: paths=paths[:cfg.num_paths]\n",
    "    rng=np.random.RandomState(cfg.split_seed)\n",
    "    idx=rng.permutation(len(paths)); cut=int(len(paths)*cfg.split_ratio)\n",
    "    return [paths[i] for i in idx[:cut]], [paths[i] for i in idx[cut:]]\n",
    "\n",
    "# ================================================================\n",
    "# 3) model (unchanged architecture.py)\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,c):\n",
    "        super().__init__()\n",
    "        self.egnn=StackedEGNN(c.dim,c.depth,c.hidden_dim,c.dropout,\n",
    "                              c.hood_k,98,c.num_neighbors,c.norm_coors).to(c.device)\n",
    "        self.rbf =TunableBlock(LearnableRBF(c.basis,10.).to(c.device),c.use_rbf)\n",
    "        self.attn=TunableBlock(AttentionBlock(c.dim+c.basis,c.dim+c.basis,c.hidden_dim)\\\n",
    "                               .to(c.device),c.use_attn)\n",
    "        if c.aggregator.startswith('nconv'):\n",
    "            self.nconv=nn.Conv1d(c.hood_k,1,c.dim+c.basis).to(c.device)\n",
    "            out=1\n",
    "        else: self.nconv=None; out=c.dim+c.basis\n",
    "        self.head=nn.Linear(out,1).to(c.device) if c.use_pred_head else nn.Identity()\n",
    "        self.prot=EGNN(dim=1,update_coors=True,num_nearest_neighbors=3).to(c.device)\n",
    "    def forward(self,z,x):\n",
    "        h,coord=self.egnn(z,x); h=h[0]\n",
    "        cent=coord.mean(1,keepdim=True)\n",
    "        r=self.rbf(cent,coord) if cfg.use_rbf else h.new_zeros(h.size(0),cfg.hood_k,cfg.basis)\n",
    "        tok=torch.cat((r.transpose(1,2),h.transpose(1,2)),1)\n",
    "        tok,_=self.attn(tok.permute(2,0,1)); tok=tok.permute(1,0,2)\n",
    "        tok=self.nconv(tok).squeeze(-1) if self.nconv is not None else tok.max(1).values\n",
    "        p=self.head(tok); p=self.prot(p.unsqueeze(0),cent.permute(1,0,2))[0].squeeze(0)\n",
    "        return p\n",
    "model=Model(cfg); print(\"params\",sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# ================================================================\n",
    "# 4) loaders\n",
    "# ================================================================\n",
    "allp=glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "tr,val=split(allp)\n",
    "tr_ds=InMemDS(tr,cfg.hood_k); val_ds=InMemDS(val,cfg.hood_k)\n",
    "collate=lambda b: pad(b,cfg.hood_k,cfg.device,cfg.analysis_mode)\n",
    "tr_loader=DataLoader(tr_ds,batch_size=cfg.batch_size,shuffle=True,collate_fn=collate)\n",
    "va_loader=DataLoader(val_ds,batch_size=cfg.batch_size,shuffle=False,collate_fn=collate)\n",
    "\n",
    "# ================================================================\n",
    "# 5) training util\n",
    "# ================================================================\n",
    "primary_fn = nn.L1Loss() if cfg.loss_type=='mae' else nn.MSELoss()\n",
    "secondary_fn= nn.MSELoss() if cfg.study_metrics and cfg.loss_type=='mae' else \\\n",
    "              nn.L1Loss() if cfg.study_metrics else None\n",
    "pname='MAE' if cfg.loss_type=='mae' else 'MSE'; sname='MSE' if pname=='MAE' else 'MAE'\n",
    "opt=torch.optim.AdamW(model.parameters(),lr=cfg.lr)\n",
    "sch=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,'min',0.5,3)\n",
    "scaler=GradScaler(enabled=(cfg.device=='cuda'))\n",
    "\n",
    "def run(loader,train):\n",
    "    model.train() if train else model.eval()\n",
    "    ps=ss=0;n=0\n",
    "    for batch in loader:\n",
    "        if cfg.analysis_mode: z,x,y,m,ids=batch\n",
    "        else:                 z,x,y,m=batch\n",
    "        v=m.view(-1); z=z.view(-1,z.size(2))[v].to(cfg.device)\n",
    "        x=x.view(-1,x.size(2),3)[v].to(cfg.device); y=y.view(-1)[v].to(cfg.device)\n",
    "        with autocast(enabled=(cfg.device=='cuda')):\n",
    "            pred=model(z,x).flatten(); loss=primary_fn(pred,y)\n",
    "            sec=secondary_fn(pred,y).item() if secondary_fn else 0.0\n",
    "        if train:\n",
    "            opt.zero_grad(); scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        ps+=loss.item(); ss+=sec; n+=1\n",
    "    return ps/n, (ss/n if secondary_fn else None)\n",
    "\n",
    "# ================================================================\n",
    "# 6) train\n",
    "# ================================================================\n",
    "for e in range(cfg.epochs):\n",
    "    tr_p,tr_s=run(tr_loader,True)\n",
    "    va_p,va_s=run(va_loader,False)\n",
    "    sch.step(va_p)\n",
    "    msg=f\"[{e+1}/{cfg.epochs}] train {pname}:{tr_p:.4f} | val {pname}:{va_p:.4f}\"\n",
    "    if secondary_fn: msg+=f\" || train {sname}:{tr_s:.4f} | val {sname}:{va_s:.4f}\"\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run‑ID: 20250726_221026\n",
      "params: 17695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (270x201 and 3x6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-709eb687fe3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mtr_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0mva_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mva_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"[{e+1}/{cfg.epochs}] train {pname}:{tr_p:.4f} | val {pname}:{va_p:.4f}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-709eb687fe3d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(loader, train)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-709eb687fe3d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, x)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_prot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             preds = self.prot(preds.unsqueeze(0),\n\u001b[0;32m--> 161\u001b[0;31m                               cent.permute(1, 0, 2))[0].squeeze(0)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# final conv (1×k across residues)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/egnn_pytorch/egnn_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feats, coors, edges, mask, adj_mat)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0medge_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mm_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_gate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (270x201 and 3x6)"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 0) dashboard  – change anything here\n",
    "# ================================================================\n",
    "class Cfg(dict):\n",
    "    __getattr__ = dict.__getitem__; __setattr__ = dict.__setitem__\n",
    "cfg = Cfg(\n",
    "    # backbone\n",
    "    dim=12, basis=6, depth=2, hidden_dim=4, dropout=0.02,\n",
    "    num_neighbors=8, hood_k=100, norm_coors=True,\n",
    "    # blocks\n",
    "    aggregator='linear', use_rbf=False, use_attn=False,\n",
    "    use_nconv=True, use_pred_head=False,\n",
    "    # training\n",
    "    loss_type='mae', study_metrics=True, lr=5e-3, epochs=3, batch_size=1,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    # reproducibility & misc\n",
    "    seed=0, analysis_mode=False, save_attn=False,\n",
    "    num_paths=2,\n",
    "    split_ratio=0.8, split_seed=0,\n",
    "    runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    ")\n",
    "print(\"Run‑ID:\", cfg.runid)\n",
    "\n",
    "# ================================================================\n",
    "# 1) reproducibility\n",
    "# ================================================================\n",
    "import random, os, numpy as np, torch, glob, datetime\n",
    "random.seed(cfg.seed); np.random.seed(cfg.seed); torch.manual_seed(cfg.seed)\n",
    "torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# ================================================================\n",
    "# 2) dataset helpers\n",
    "# ================================================================\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class HoodDS(Dataset):\n",
    "    def __init__(self, paths, k):\n",
    "        self.data=[]; self.ids=[]\n",
    "        nbr=NearestNeighbors(k,algorithm='brute')\n",
    "        for p in paths:\n",
    "            try:\n",
    "                d=np.load(p,allow_pickle=True)\n",
    "                if len(d['sites'])==0: continue\n",
    "                nbr.fit(d['pos']); idx=nbr.kneighbors(d['sites'],return_distance=False)\n",
    "                self.data.append((torch.from_numpy(d['z'][idx]),\n",
    "                                  torch.from_numpy(d['pos'][idx]),\n",
    "                                  torch.from_numpy(d['pks'])))\n",
    "                self.ids.append(os.path.splitext(os.path.basename(p))[0])\n",
    "            except Exception as e: print(\"skip\",p,e)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        z,p,y=self.data[i]; return z,p,y,self.ids[i]\n",
    "\n",
    "def pad(batch,k,device,ret_ids):\n",
    "    ids=[b[3] for b in batch] if ret_ids else None\n",
    "    B=len(batch); S=max(b[0].shape[0] for b in batch)\n",
    "    zt=torch.zeros(B,S,k,dtype=torch.int32,device=device)\n",
    "    pt=torch.zeros(B,S,k,3,dtype=torch.float32,device=device)\n",
    "    yt=torch.full((B,S),float('nan'),device=device); mt=torch.zeros(B,S,dtype=torch.bool,device=device)\n",
    "    for b,(z,p,y,_) in enumerate(batch):\n",
    "        s=z.shape[0]; zt[b,:s]=z; pt[b,:s]=p; yt[b,:s]=y; mt[b,:s]=True\n",
    "    return (zt,pt,yt,mt,ids) if ret_ids else (zt,pt,yt,mt)\n",
    "\n",
    "def split(paths):\n",
    "    if cfg.num_paths: paths=paths[:cfg.num_paths]\n",
    "    rng=np.random.RandomState(cfg.split_seed)\n",
    "    idx=rng.permutation(len(paths)); cut=int(len(paths)*cfg.split_ratio)\n",
    "    return [paths[i] for i in idx[:cut]], [paths[i] for i in idx[cut:]]\n",
    "\n",
    "# ================================================================\n",
    "# 3) model\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn\n",
    "# ================================================================\n",
    "# 3)  fully‑tunable Model (drop‑in replacement)\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn, torch\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.c = cfg                          # keep a local copy\n",
    "\n",
    "        # ---------- residue‑level EGNN backbone -------------------\n",
    "        self.egnn = StackedEGNN(\n",
    "            cfg.dim, cfg.depth, cfg.hidden_dim, cfg.dropout,\n",
    "            cfg.hood_k, 98, cfg.num_neighbors, cfg.get('norm_coors', True)\n",
    "        ).to(cfg.device)\n",
    "\n",
    "        # ---------- optional blocks --------------------------------\n",
    "        self.rbf  = TunableBlock(LearnableRBF(cfg.basis, 10.).to(cfg.device),\n",
    "                                 cfg.use_rbf)\n",
    "        self.attn = TunableBlock(AttentionBlock(cfg.dim + cfg.basis,\n",
    "                                                cfg.dim + cfg.basis,\n",
    "                                                cfg.hidden_dim).to(cfg.device),\n",
    "                                 cfg.use_attn)\n",
    "\n",
    "        # ---------- neighbour → scalar aggregators -----------------\n",
    "        C = cfg.dim + cfg.basis                        # feature channels\n",
    "        if cfg.aggregator == 'linear':\n",
    "            self.agg = nn.Linear(C, 1).to(cfg.device)\n",
    "        elif cfg.aggregator == 'nconv':\n",
    "            # in‑channels = hood_k, kernel = C   (N,C) layout\n",
    "            self.agg = nn.Conv1d(cfg.hood_k, 1, kernel_size=C, padding=0).to(cfg.device)\n",
    "        elif cfg.aggregator == 'pool':                 # max‑pool *without* linear\n",
    "            self.agg = None\n",
    "        else:\n",
    "            raise ValueError(\"aggregator must be 'linear', 'nconv', or 'pool'\")\n",
    "\n",
    "        # ---------- optional boost  (pred_head2) -------------------\n",
    "        self.boost = nn.Linear(1, 1).to(cfg.device) if cfg.get('use_boost', False) else nn.Identity()\n",
    "\n",
    "        # ---------- protein‑level EGNN & final conv ----------------\n",
    "        self.use_prot = cfg.get('use_prot_egnn', True)\n",
    "        self.prot = (EGNN(dim=1, update_coors=True, num_nearest_neighbors=3)\n",
    "                     .to(cfg.device)) if self.use_prot else nn.Identity()\n",
    "\n",
    "        self.use_conv = cfg.get('use_conv', False)\n",
    "        if self.use_conv:\n",
    "            k = cfg.get('conv_kernel', 7)\n",
    "            self.conv = nn.Conv1d(1, 1, k, padding=k // 2).to(cfg.device)\n",
    "        else:\n",
    "            self.conv = nn.Identity()\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    def forward(self, z, x):                       # z:(R,N) , x:(R,N,3)\n",
    "        h, coord = self.egnn(z, x); h = h[0]       # (R,N,dim)\n",
    "\n",
    "        cent = coord.mean(1, keepdim=True)         # (R,1,3)\n",
    "        if self.c.use_rbf:\n",
    "            r = self.rbf(cent, coord).transpose(1, 2)          # (R,basis,N)\n",
    "        else:\n",
    "            r = h.new_zeros(h.size(0), self.c.basis, self.c.hood_k)\n",
    "\n",
    "        tok = torch.cat((r, h.transpose(1, 2)), 1)             # (R,C,N)\n",
    "\n",
    "        # ---- attention (tuple‑safe) ------------------------------\n",
    "        out = self.attn(tok.permute(2, 0, 1))\n",
    "        tok = out[0] if isinstance(out, (tuple, list)) else out\n",
    "        tok = tok.permute(1, 0, 2)                              # (R,N,C)\n",
    "\n",
    "        # ---- aggregation paths -----------------------------------\n",
    "        if self.c.aggregator == 'linear':\n",
    "            pooled = tok.max(1).values                          # (R,C)\n",
    "            preds  = self.agg(pooled)                           # (R,1)\n",
    "        elif self.c.aggregator == 'nconv':\n",
    "            preds  = self.agg(tok).squeeze(-1)                  # (R,1)\n",
    "        else:                                                   # 'pool'\n",
    "            preds  = tok.max(1).values.unsqueeze(-1)            # (R,1)\n",
    "\n",
    "        # optional boost\n",
    "        preds = self.boost(preds)\n",
    "\n",
    "        # protein‑level EGNN\n",
    "        if self.use_prot:\n",
    "            preds = self.prot(preds.unsqueeze(0),\n",
    "                              cent.permute(1, 0, 2))[0].squeeze(0)\n",
    "\n",
    "        # final conv (1×k across residues)\n",
    "        if self.use_conv:\n",
    "            preds = self.conv(preds.T.unsqueeze(0)).squeeze(0).T  # (R,1)\n",
    "\n",
    "        return preds\n",
    "\n",
    "model=Model(cfg)\n",
    "cfg.update(dict(\n",
    "    use_rbf       = False,\n",
    "    use_attn      = False,\n",
    "    aggregator    = 'nconv',      # 'linear', 'nconv', 'pool'\n",
    "    use_boost     = False,        # pred_head2\n",
    "    use_prot_egnn = True,\n",
    "    use_conv      = False\n",
    "))\n",
    "print(\"params:\",sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# ================================================================\n",
    "# 4) loaders\n",
    "# ================================================================\n",
    "allp=glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "tr,val=split(allp)\n",
    "train_ds=HoodDS(tr,cfg.hood_k); val_ds=HoodDS(val,cfg.hood_k)\n",
    "coll=lambda b: pad(b,cfg.hood_k,cfg.device,cfg.analysis_mode)\n",
    "tr_loader=DataLoader(train_ds,batch_size=cfg.batch_size,shuffle=True ,collate_fn=coll)\n",
    "va_loader=DataLoader(val_ds,batch_size=cfg.batch_size,shuffle=False,collate_fn=coll)\n",
    "\n",
    "# ================================================================\n",
    "# 5) training utils\n",
    "# ================================================================\n",
    "p_fn=nn.L1Loss() if cfg.loss_type=='mae' else nn.MSELoss()\n",
    "s_fn=nn.MSELoss() if cfg.study_metrics and cfg.loss_type=='mae' else \\\n",
    "     nn.L1Loss() if cfg.study_metrics else None\n",
    "pname='MAE' if cfg.loss_type=='mae' else 'MSE'; sname='MSE' if pname=='MAE' else 'MAE'\n",
    "opt=torch.optim.AdamW(model.parameters(),lr=cfg.lr)\n",
    "sch=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,'min',0.5,3)\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler=GradScaler(enabled=(cfg.device=='cuda'))\n",
    "\n",
    "def run(loader,train):\n",
    "    model.train() if train else model.eval(); P=S=0;n=0\n",
    "    for batch in loader:\n",
    "        z,x,y,m,*rest=batch        # rest = [ids] or []\n",
    "        v=m.view(-1); z=z.view(-1,z.size(2))[v].to(cfg.device)\n",
    "        x=x.view(-1,x.size(2),3)[v].to(cfg.device); y=y.view(-1)[v].to(cfg.device)\n",
    "        with autocast(enabled=(cfg.device=='cuda')):\n",
    "            pred=model(z,x).flatten(); loss=p_fn(pred,y); sec=s_fn(pred,y).item() if s_fn else 0.\n",
    "        if train:\n",
    "            opt.zero_grad(); scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        P+=loss.item(); S+=sec; n+=1\n",
    "    return P/n, (S/n if s_fn else None)\n",
    "\n",
    "# ================================================================\n",
    "# 6) train\n",
    "# ================================================================\n",
    "for e in range(cfg.epochs):\n",
    "    tr_p,tr_s=run(tr_loader,True)\n",
    "    va_p,va_s=run(va_loader,False); sch.step(va_p)\n",
    "    msg=f\"[{e+1}/{cfg.epochs}] train {pname}:{tr_p:.4f} | val {pname}:{va_p:.4f}\"\n",
    "    if s_fn: msg+=f\" || train {sname}:{tr_s:.4f} | val {sname}:{va_s:.4f}\"\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run‑ID: 20250726_220313\n",
      "params: 17676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (270x37 and 3x6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c267f1cc4469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mtr_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mva_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mva_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"[{e+1}/{cfg.epochs}] train {pname}:{tr_p:.4f} | val {pname}:{va_p:.4f}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c267f1cc4469>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(loader, train)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b2f3ff59142b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;31m# (R,N,C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnconv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/egnn_pytorch/egnn_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feats, coors, edges, mask, adj_mat)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0medge_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mm_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_gate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (270x37 and 3x6)"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 0) dashboard  – change anything here\n",
    "# ================================================================\n",
    "class Cfg(dict):\n",
    "    __getattr__ = dict.__getitem__; __setattr__ = dict.__setitem__\n",
    "cfg = Cfg(\n",
    "    # backbone\n",
    "    dim=12, basis=6, depth=2, hidden_dim=4, dropout=0.02,\n",
    "    num_neighbors=8, hood_k=100, norm_coors=True,\n",
    "    # blocks\n",
    "    aggregator='linear', use_rbf=False, use_attn=False,\n",
    "    use_nconv=True, use_pred_head=False,\n",
    "    # training\n",
    "    loss_type='mae', study_metrics=True, lr=5e-3, epochs=3, batch_size=1,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    # reproducibility & misc\n",
    "    seed=0, analysis_mode=False, save_attn=False,\n",
    "    num_paths=2,\n",
    "    split_ratio=0.8, split_seed=0,\n",
    "    runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    ")\n",
    "print(\"Run‑ID:\", cfg.runid)\n",
    "\n",
    "# ================================================================\n",
    "# 1) reproducibility\n",
    "# ================================================================\n",
    "import random, os, numpy as np, torch, glob, datetime\n",
    "random.seed(cfg.seed); np.random.seed(cfg.seed); torch.manual_seed(cfg.seed)\n",
    "torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# ================================================================\n",
    "# 2) dataset helpers\n",
    "# ================================================================\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class HoodDS(Dataset):\n",
    "    def __init__(self, paths, k):\n",
    "        self.data=[]; self.ids=[]\n",
    "        nbr=NearestNeighbors(k,algorithm='brute')\n",
    "        for p in paths:\n",
    "            try:\n",
    "                d=np.load(p,allow_pickle=True)\n",
    "                if len(d['sites'])==0: continue\n",
    "                nbr.fit(d['pos']); idx=nbr.kneighbors(d['sites'],return_distance=False)\n",
    "                self.data.append((torch.from_numpy(d['z'][idx]),\n",
    "                                  torch.from_numpy(d['pos'][idx]),\n",
    "                                  torch.from_numpy(d['pks'])))\n",
    "                self.ids.append(os.path.splitext(os.path.basename(p))[0])\n",
    "            except Exception as e: print(\"skip\",p,e)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        z,p,y=self.data[i]; return z,p,y,self.ids[i]\n",
    "\n",
    "def pad(batch,k,device,ret_ids):\n",
    "    ids=[b[3] for b in batch] if ret_ids else None\n",
    "    B=len(batch); S=max(b[0].shape[0] for b in batch)\n",
    "    zt=torch.zeros(B,S,k,dtype=torch.int32,device=device)\n",
    "    pt=torch.zeros(B,S,k,3,dtype=torch.float32,device=device)\n",
    "    yt=torch.full((B,S),float('nan'),device=device); mt=torch.zeros(B,S,dtype=torch.bool,device=device)\n",
    "    for b,(z,p,y,_) in enumerate(batch):\n",
    "        s=z.shape[0]; zt[b,:s]=z; pt[b,:s]=p; yt[b,:s]=y; mt[b,:s]=True\n",
    "    return (zt,pt,yt,mt,ids) if ret_ids else (zt,pt,yt,mt)\n",
    "\n",
    "def split(paths):\n",
    "    if cfg.num_paths: paths=paths[:cfg.num_paths]\n",
    "    rng=np.random.RandomState(cfg.split_seed)\n",
    "    idx=rng.permutation(len(paths)); cut=int(len(paths)*cfg.split_ratio)\n",
    "    return [paths[i] for i in idx[:cut]], [paths[i] for i in idx[cut:]]\n",
    "\n",
    "# ================================================================\n",
    "# 3) model\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn\n",
    "# ================================================================\n",
    "# 3)  fully‑tunable Model\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.c = cfg                    # keep a local handle\n",
    "\n",
    "        # ── residue‑level EGNN backbone\n",
    "        self.egnn = StackedEGNN(cfg.dim, cfg.depth, cfg.hidden_dim, cfg.dropout,\n",
    "                                cfg.hood_k, 98, cfg.num_neighbors,\n",
    "                                cfg.get('norm_coors', True)\n",
    "                               ).to(cfg.device)\n",
    "\n",
    "        # ── optional blocks\n",
    "        self.rbf  = TunableBlock(LearnableRBF(cfg.basis, 10.).to(cfg.device),\n",
    "                                 cfg.use_rbf)\n",
    "\n",
    "        self.attn = TunableBlock(AttentionBlock(cfg.dim+cfg.basis,\n",
    "                                                cfg.dim+cfg.basis,\n",
    "                                                cfg.hidden_dim).to(cfg.device),\n",
    "                                 cfg.use_attn)\n",
    "\n",
    "        # ── neighbours → scalar aggregator\n",
    "        if cfg.aggregator.startswith('nconv'):\n",
    "            self.nconv = nn.Conv1d(cfg.hood_k, 1,\n",
    "                                   kernel_size=cfg.dim+cfg.basis,\n",
    "                                   padding=0).to(cfg.device)\n",
    "            agg_out = 1\n",
    "        else:\n",
    "            self.nconv = None\n",
    "            agg_out    = cfg.dim + cfg.basis\n",
    "\n",
    "        if cfg.use_pred_head:\n",
    "            self.head = nn.Linear(agg_out, 1).to(cfg.device)\n",
    "        else:\n",
    "            self.head = nn.Identity()\n",
    "\n",
    "        # ── protein‑level geometry & optional 1‑D conv\n",
    "        self.use_prot = cfg.get('use_prot_egnn', True)\n",
    "        self.prot = EGNN(dim=1, update_coors=True,\n",
    "                         num_nearest_neighbors=3).to(cfg.device) \\\n",
    "                         if self.use_prot else nn.Identity()\n",
    "\n",
    "        self.use_conv = cfg.get('use_conv', False)\n",
    "        if self.use_conv:\n",
    "            k = cfg.get('conv_kernel', 7)\n",
    "            self.conv = nn.Conv1d(1, 1, k, padding=k//2).to(cfg.device)\n",
    "        else:\n",
    "            self.conv = nn.Identity()\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    def forward(self, z, x):                       # z:(R,N)  x:(R,N,3)\n",
    "        h, coord = self.egnn(z, x); h = h[0]       # h:(R,N,dim)\n",
    "\n",
    "        cent = coord.mean(1, keepdim=True)         # (R,1,3)\n",
    "        if self.c.use_rbf:\n",
    "            r = self.rbf(cent, coord).transpose(1, 2)   # (R, basis, N)\n",
    "        else:\n",
    "            r = h.new_zeros(h.size(0), self.c.basis, self.c.hood_k)\n",
    "\n",
    "        tok = torch.cat((r, h.transpose(1, 2)), 1)      # (R, C, N)\n",
    "\n",
    "        # ---- attention (handles tuple vs tensor automatically)\n",
    "        attn_out = self.attn(tok.permute(2, 0, 1))\n",
    "        tok = attn_out[0] if isinstance(attn_out, (tuple, list)) else attn_out\n",
    "        tok = tok.permute(1, 0, 2)                      # (R, N, C)\n",
    "\n",
    "        # ---- aggregator paths\n",
    "        if self.nconv is not None:                      # nconv or nconv+linear\n",
    "            tok = self.nconv(tok).squeeze(-1)           # (R, 1)\n",
    "        elif self.c.aggregator == 'pool':               # max‑pool\n",
    "            tok = tok.max(1).values                     # (R, C)\n",
    "        else:                                           # linear\n",
    "            tok = tok.max(1).values                     # (R, C)\n",
    "\n",
    "        preds = self.head(tok)                          # (R, 1) or unchanged\n",
    "\n",
    "        # ---- protein‑level EGNN (optional)\n",
    "        if self.use_prot:\n",
    "            preds = self.prot(preds.unsqueeze(0),\n",
    "                              cent.permute(1, 0, 2))[0].squeeze(0)\n",
    "\n",
    "        # ---- final 1‑D conv over residues (optional)\n",
    "        if self.use_conv:\n",
    "            preds = self.conv(preds.T.unsqueeze(0)).squeeze(0).T  # (R,1)\n",
    "\n",
    "        return preds\n",
    "\n",
    "print(\"params:\",sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# ================================================================\n",
    "# 4) loaders\n",
    "# ================================================================\n",
    "allp=glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "tr,val=split(allp)\n",
    "train_ds=HoodDS(tr,cfg.hood_k); val_ds=HoodDS(val,cfg.hood_k)\n",
    "coll=lambda b: pad(b,cfg.hood_k,cfg.device,cfg.analysis_mode)\n",
    "tr_loader=DataLoader(train_ds,batch_size=cfg.batch_size,shuffle=True ,collate_fn=coll)\n",
    "va_loader=DataLoader(val_ds,batch_size=cfg.batch_size,shuffle=False,collate_fn=coll)\n",
    "\n",
    "# ================================================================\n",
    "# 5) training utils\n",
    "# ================================================================\n",
    "p_fn=nn.L1Loss() if cfg.loss_type=='mae' else nn.MSELoss()\n",
    "s_fn=nn.MSELoss() if cfg.study_metrics and cfg.loss_type=='mae' else \\\n",
    "     nn.L1Loss() if cfg.study_metrics else None\n",
    "pname='MAE' if cfg.loss_type=='mae' else 'MSE'; sname='MSE' if pname=='MAE' else 'MAE'\n",
    "opt=torch.optim.AdamW(model.parameters(),lr=cfg.lr)\n",
    "sch=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,'min',0.5,3)\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler=GradScaler(enabled=(cfg.device=='cuda'))\n",
    "\n",
    "def run(loader,train):\n",
    "    model.train() if train else model.eval(); P=S=0;n=0\n",
    "    for batch in loader:\n",
    "        z,x,y,m,*rest=batch        # rest = [ids] or []\n",
    "        v=m.view(-1); z=z.view(-1,z.size(2))[v].to(cfg.device)\n",
    "        x=x.view(-1,x.size(2),3)[v].to(cfg.device); y=y.view(-1)[v].to(cfg.device)\n",
    "        with autocast(enabled=(cfg.device=='cuda')):\n",
    "            pred=model(z,x).flatten(); loss=p_fn(pred,y); sec=s_fn(pred,y).item() if s_fn else 0.\n",
    "        if train:\n",
    "            opt.zero_grad(); scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        P+=loss.item(); S+=sec; n+=1\n",
    "    return P/n, (S/n if s_fn else None)\n",
    "\n",
    "# ================================================================\n",
    "# 6) train\n",
    "# ================================================================\n",
    "for e in range(cfg.epochs):\n",
    "    tr_p,tr_s=run(tr_loader,True)\n",
    "    va_p,va_s=run(va_loader,False); sch.step(va_p)\n",
    "    msg=f\"[{e+1}/{cfg.epochs}] train {pname}:{tr_p:.4f} | val {pname}:{va_p:.4f}\"\n",
    "    if s_fn: msg+=f\" || train {sname}:{tr_s:.4f} | val {sname}:{va_s:.4f}\"\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(cfg)\n",
    "cfg.update(dict(\n",
    "    use_rbf       = False,\n",
    "    use_attn      = False,\n",
    "    aggregator    = 'nconv',      # 'linear', 'nconv', 'pool'\n",
    "    use_boost     = False,        # pred_head2\n",
    "    use_prot_egnn = True,\n",
    "    use_conv      = False\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "import numpy as np\n",
    "from egnn_pytorch import EGNN\n",
    "from architecture import (StackedEGNN,\n",
    "                          LearnableRBF,\n",
    "                          AttentionBlock,\n",
    "                          TunableBlock)\n",
    "import time, datetime\n",
    "import glob\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch, torch.nn as nn\n",
    "import numpy as np\n",
    "from egnn_pytorch import EGNN\n",
    "from architecture import (StackedEGNN,\n",
    "                          LearnableRBF,\n",
    "                          AttentionBlock,\n",
    "                          TunableBlock)\n",
    "import time, datetime\n",
    "import glob\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run‑ID: 20250726_221357\n",
      "params: 17695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] train MAE:1.5816 | val MAE:1.2734 || train MSE:4.3669 | val MSE:2.8816\n",
      "[2/3] train MAE:1.4030 | val MAE:1.1154 || train MSE:3.7351 | val MSE:2.4087\n",
      "[3/3] train MAE:1.2910 | val MAE:1.0252 || train MSE:3.3240 | val MSE:2.1439\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 0) dashboard  – change anything here\n",
    "# ================================================================\n",
    "class Cfg(dict):\n",
    "    __getattr__ = dict.__getitem__; __setattr__ = dict.__setitem__\n",
    "cfg = Cfg(\n",
    "    # backbone\n",
    "    dim=12, basis=6, depth=2, hidden_dim=4, dropout=0.02,\n",
    "    num_neighbors=8, hood_k=100, norm_coors=True,\n",
    "    # blocks\n",
    "    aggregator='linear', use_rbf=False, use_attn=False,\n",
    "    use_nconv=True, use_pred_head=False,\n",
    "    # training\n",
    "    loss_type='mae', study_metrics=True, lr=5e-3, epochs=3, batch_size=1,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    # reproducibility & misc\n",
    "    seed=0, analysis_mode=False, save_attn=False,\n",
    "    num_paths=2,\n",
    "    split_ratio=0.8, split_seed=0,\n",
    "    runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    ")\n",
    "print(\"Run‑ID:\", cfg.runid)\n",
    "\n",
    "# ================================================================\n",
    "# 1) reproducibility\n",
    "# ================================================================\n",
    "import random, os, numpy as np, torch, glob, datetime\n",
    "random.seed(cfg.seed); np.random.seed(cfg.seed); torch.manual_seed(cfg.seed)\n",
    "torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# ================================================================\n",
    "# 2) dataset helpers\n",
    "# ================================================================\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class HoodDS(Dataset):\n",
    "    def __init__(self, paths, k):\n",
    "        self.data=[]; self.ids=[]\n",
    "        nbr=NearestNeighbors(k,algorithm='brute')\n",
    "        for p in paths:\n",
    "            try:\n",
    "                d=np.load(p,allow_pickle=True)\n",
    "                if len(d['sites'])==0: continue\n",
    "                nbr.fit(d['pos']); idx=nbr.kneighbors(d['sites'],return_distance=False)\n",
    "                self.data.append((torch.from_numpy(d['z'][idx]),\n",
    "                                  torch.from_numpy(d['pos'][idx]),\n",
    "                                  torch.from_numpy(d['pks'])))\n",
    "                self.ids.append(os.path.splitext(os.path.basename(p))[0])\n",
    "            except Exception as e: print(\"skip\",p,e)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        z,p,y=self.data[i]; return z,p,y,self.ids[i]\n",
    "\n",
    "def pad(batch,k,device,ret_ids):\n",
    "    ids=[b[3] for b in batch] if ret_ids else None\n",
    "    B=len(batch); S=max(b[0].shape[0] for b in batch)\n",
    "    zt=torch.zeros(B,S,k,dtype=torch.int32,device=device)\n",
    "    pt=torch.zeros(B,S,k,3,dtype=torch.float32,device=device)\n",
    "    yt=torch.full((B,S),float('nan'),device=device); mt=torch.zeros(B,S,dtype=torch.bool,device=device)\n",
    "    for b,(z,p,y,_) in enumerate(batch):\n",
    "        s=z.shape[0]; zt[b,:s]=z; pt[b,:s]=p; yt[b,:s]=y; mt[b,:s]=True\n",
    "    return (zt,pt,yt,mt,ids) if ret_ids else (zt,pt,yt,mt)\n",
    "\n",
    "def split(paths):\n",
    "    if cfg.num_paths: paths=paths[:cfg.num_paths]\n",
    "    rng=np.random.RandomState(cfg.split_seed)\n",
    "    idx=rng.permutation(len(paths)); cut=int(len(paths)*cfg.split_ratio)\n",
    "    return [paths[i] for i in idx[:cut]], [paths[i] for i in idx[cut:]]\n",
    "\n",
    "# ================================================================\n",
    "# 3) model\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn\n",
    "# ================================================================\n",
    "# 3)  fully‑tunable Model (drop‑in replacement)\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn, torch\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.c = cfg                          # keep a local copy\n",
    "\n",
    "        # ---------- residue‑level EGNN backbone -------------------\n",
    "        self.egnn = StackedEGNN(\n",
    "            cfg.dim, cfg.depth, cfg.hidden_dim, cfg.dropout,\n",
    "            cfg.hood_k, 98, cfg.num_neighbors, cfg.get('norm_coors', True)\n",
    "        ).to(cfg.device)\n",
    "\n",
    "        # ---------- optional blocks --------------------------------\n",
    "        self.rbf  = TunableBlock(LearnableRBF(cfg.basis, 10.).to(cfg.device),\n",
    "                                 cfg.use_rbf)\n",
    "        self.attn = TunableBlock(AttentionBlock(cfg.dim + cfg.basis,\n",
    "                                                cfg.dim + cfg.basis,\n",
    "                                                cfg.hidden_dim).to(cfg.device),\n",
    "                                 cfg.use_attn)\n",
    "\n",
    "        # ---------- neighbour → scalar aggregators -----------------\n",
    "        C = cfg.dim + cfg.basis                        # feature channels\n",
    "        if cfg.aggregator == 'linear':\n",
    "            self.agg = nn.Linear(C, 1).to(cfg.device)\n",
    "        elif cfg.aggregator == 'nconv':\n",
    "            # in‑channels = hood_k, kernel = C   (N,C) layout\n",
    "            self.agg = nn.Conv1d(cfg.hood_k, 1, kernel_size=C, padding=0).to(cfg.device)\n",
    "        elif cfg.aggregator == 'pool':                 # max‑pool *without* linear\n",
    "            self.agg = None\n",
    "        else:\n",
    "            raise ValueError(\"aggregator must be 'linear', 'nconv', or 'pool'\")\n",
    "\n",
    "        # ---------- optional boost  (pred_head2) -------------------\n",
    "        self.boost = nn.Linear(1, 1).to(cfg.device) if cfg.get('use_boost', False) else nn.Identity()\n",
    "\n",
    "        # ---------- protein‑level EGNN & final conv ----------------\n",
    "        self.use_prot = cfg.get('use_prot_egnn', True)\n",
    "        self.prot = (EGNN(dim=1, update_coors=True, num_nearest_neighbors=3)\n",
    "                     .to(cfg.device)) if self.use_prot else nn.Identity()\n",
    "\n",
    "        self.use_conv = cfg.get('use_conv', False)\n",
    "        if self.use_conv:\n",
    "            k = cfg.get('conv_kernel', 7)\n",
    "            self.conv = nn.Conv1d(1, 1, k, padding=k // 2).to(cfg.device)\n",
    "        else:\n",
    "            self.conv = nn.Identity()\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    def forward(self, z, x):                       # z:(R,N) , x:(R,N,3)\n",
    "        h, coord = self.egnn(z, x); h = h[0]       # (R,N,dim)\n",
    "\n",
    "        cent = coord.mean(1, keepdim=True)         # (R,1,3)\n",
    "        if self.c.use_rbf:\n",
    "            r = self.rbf(cent, coord).transpose(1, 2)          # (R,basis,N)\n",
    "        else:\n",
    "            r = h.new_zeros(h.size(0), self.c.basis, self.c.hood_k)\n",
    "\n",
    "        tok = torch.cat((r, h.transpose(1, 2)), 1)             # (R,C,N)\n",
    "\n",
    "        # ---- attention (tuple‑safe) ------------------------------\n",
    "        out = self.attn(tok.permute(2, 0, 1))\n",
    "        tok = out[0] if isinstance(out, (tuple, list)) else out\n",
    "        tok = tok.permute(1, 0, 2)                              # (R,N,C)\n",
    "\n",
    "        # ---- aggregation paths -----------------------------------\n",
    "        if self.c.aggregator == 'linear':\n",
    "            pooled = tok.max(1).values                          # (R,C)\n",
    "            preds  = self.agg(pooled)                           # (R,1)\n",
    "        elif self.c.aggregator == 'nconv':\n",
    "            preds  = self.agg(tok).squeeze(-1)                  # (R,1)\n",
    "        else:                                                   # 'pool'\n",
    "            preds  = tok.max(1).values.unsqueeze(-1)            # (R,1)\n",
    "\n",
    "        # optional boost\n",
    "        preds = self.boost(preds)\n",
    "\n",
    "        # protein‑level EGNN\n",
    "        if self.use_prot:\n",
    "            preds = self.prot(preds.unsqueeze(0),\n",
    "                              cent.permute(1, 0, 2))[0].squeeze(0)\n",
    "\n",
    "        # final conv (1×k across residues)\n",
    "        if self.use_conv:\n",
    "            preds = self.conv(preds.T.unsqueeze(0)).squeeze(0).T  # (R,1)\n",
    "\n",
    "        return preds\n",
    "cfg.update(dict(\n",
    "    use_rbf       = False,\n",
    "    use_attn      = False,\n",
    "    aggregator    = 'linear',   # ← decide before instantiating\n",
    "    use_boost     = False,\n",
    "    use_prot_egnn = True,\n",
    "    use_conv      = False,\n",
    "))\n",
    "\n",
    "model=Model(cfg)\n",
    "\n",
    "print(\"params:\",sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# ================================================================\n",
    "# 4) loaders\n",
    "# ================================================================\n",
    "allp=glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "tr,val=split(allp)\n",
    "train_ds=HoodDS(tr,cfg.hood_k); val_ds=HoodDS(val,cfg.hood_k)\n",
    "coll=lambda b: pad(b,cfg.hood_k,cfg.device,cfg.analysis_mode)\n",
    "tr_loader=DataLoader(train_ds,batch_size=cfg.batch_size,shuffle=True ,collate_fn=coll)\n",
    "va_loader=DataLoader(val_ds,batch_size=cfg.batch_size,shuffle=False,collate_fn=coll)\n",
    "\n",
    "# ================================================================\n",
    "# 5) training utils\n",
    "# ================================================================\n",
    "p_fn=nn.L1Loss() if cfg.loss_type=='mae' else nn.MSELoss()\n",
    "s_fn=nn.MSELoss() if cfg.study_metrics and cfg.loss_type=='mae' else \\\n",
    "     nn.L1Loss() if cfg.study_metrics else None\n",
    "pname='MAE' if cfg.loss_type=='mae' else 'MSE'; sname='MSE' if pname=='MAE' else 'MAE'\n",
    "opt=torch.optim.AdamW(model.parameters(),lr=cfg.lr)\n",
    "sch=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,'min',0.5,3)\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler=GradScaler(enabled=(cfg.device=='cuda'))\n",
    "\n",
    "def run(loader,train):\n",
    "    model.train() if train else model.eval(); P=S=0;n=0\n",
    "    for batch in loader:\n",
    "        z,x,y,m,*rest=batch        # rest = [ids] or []\n",
    "        v=m.view(-1); z=z.view(-1,z.size(2))[v].to(cfg.device)\n",
    "        x=x.view(-1,x.size(2),3)[v].to(cfg.device); y=y.view(-1)[v].to(cfg.device)\n",
    "        with autocast(enabled=(cfg.device=='cuda')):\n",
    "            pred=model(z,x).flatten(); loss=p_fn(pred,y); sec=s_fn(pred,y).item() if s_fn else 0.\n",
    "        if train:\n",
    "            opt.zero_grad(); scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        P+=loss.item(); S+=sec; n+=1\n",
    "    return P/n, (S/n if s_fn else None)\n",
    "\n",
    "# ================================================================\n",
    "# 6) train\n",
    "# ================================================================\n",
    "for e in range(cfg.epochs):\n",
    "    tr_p,tr_s=run(tr_loader,True)\n",
    "    va_p,va_s=run(va_loader,False); sch.step(va_p)\n",
    "    msg=f\"[{e+1}/{cfg.epochs}] train {pname}:{tr_p:.4f} | val {pname}:{va_p:.4f}\"\n",
    "    if s_fn: msg+=f\" || train {sname}:{tr_s:.4f} | val {sname}:{va_s:.4f}\"\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run‑ID: 20250726_221734\n",
      "params: 17695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] train MAE:1.5816 | val MAE:1.2734 || train MSE:4.3669 | val MSE:2.8816\n",
      "[2/3] train MAE:1.4030 | val MAE:1.1154 || train MSE:3.7351 | val MSE:2.4087\n",
      "[3/3] train MAE:1.2910 | val MAE:1.0252 || train MSE:3.3240 | val MSE:2.1439\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 0) dashboard  – change anything here\n",
    "# ================================================================\n",
    "class Cfg(dict):\n",
    "    __getattr__ = dict.__getitem__; __setattr__ = dict.__setitem__\n",
    "cfg = Cfg(\n",
    "    # backbone\n",
    "    dim=12, basis=6, depth=2, hidden_dim=4, dropout=0.02,\n",
    "    num_neighbors=8, hood_k=100, norm_coors=True,\n",
    "    # blocks\n",
    "    aggregator='pool', use_rbf=False, use_attn=False,\n",
    "    use_nconv=True, use_pred_head=False,\n",
    "    # training\n",
    "    loss_type='mae', study_metrics=True, lr=5e-3, epochs=3, batch_size=1,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    # reproducibility & misc\n",
    "    seed=0, analysis_mode=False, save_attn=False,\n",
    "    num_paths=2,\n",
    "    split_ratio=0.8, split_seed=0,\n",
    "    runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    ")\n",
    "print(\"Run‑ID:\", cfg.runid)\n",
    "\n",
    "# ================================================================\n",
    "# 1) reproducibility\n",
    "# ================================================================\n",
    "import random, os, numpy as np, torch, glob, datetime\n",
    "random.seed(cfg.seed); np.random.seed(cfg.seed); torch.manual_seed(cfg.seed)\n",
    "torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# ================================================================\n",
    "# 2) dataset helpers\n",
    "# ================================================================\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class HoodDS(Dataset):\n",
    "    def __init__(self, paths, k):\n",
    "        self.data=[]; self.ids=[]\n",
    "        nbr=NearestNeighbors(k,algorithm='brute')\n",
    "        for p in paths:\n",
    "            try:\n",
    "                d=np.load(p,allow_pickle=True)\n",
    "                if len(d['sites'])==0: continue\n",
    "                nbr.fit(d['pos']); idx=nbr.kneighbors(d['sites'],return_distance=False)\n",
    "                self.data.append((torch.from_numpy(d['z'][idx]),\n",
    "                                  torch.from_numpy(d['pos'][idx]),\n",
    "                                  torch.from_numpy(d['pks'])))\n",
    "                self.ids.append(os.path.splitext(os.path.basename(p))[0])\n",
    "            except Exception as e: print(\"skip\",p,e)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        z,p,y=self.data[i]; return z,p,y,self.ids[i]\n",
    "\n",
    "def pad(batch,k,device,ret_ids):\n",
    "    ids=[b[3] for b in batch] if ret_ids else None\n",
    "    B=len(batch); S=max(b[0].shape[0] for b in batch)\n",
    "    zt=torch.zeros(B,S,k,dtype=torch.int32,device=device)\n",
    "    pt=torch.zeros(B,S,k,3,dtype=torch.float32,device=device)\n",
    "    yt=torch.full((B,S),float('nan'),device=device); mt=torch.zeros(B,S,dtype=torch.bool,device=device)\n",
    "    for b,(z,p,y,_) in enumerate(batch):\n",
    "        s=z.shape[0]; zt[b,:s]=z; pt[b,:s]=p; yt[b,:s]=y; mt[b,:s]=True\n",
    "    return (zt,pt,yt,mt,ids) if ret_ids else (zt,pt,yt,mt)\n",
    "\n",
    "def split(paths):\n",
    "    if cfg.num_paths: paths=paths[:cfg.num_paths]\n",
    "    rng=np.random.RandomState(cfg.split_seed)\n",
    "    idx=rng.permutation(len(paths)); cut=int(len(paths)*cfg.split_ratio)\n",
    "    return [paths[i] for i in idx[:cut]], [paths[i] for i in idx[cut:]]\n",
    "\n",
    "# ================================================================\n",
    "# 3) model\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn\n",
    "# ================================================================\n",
    "# 3)  fully‑tunable Model (drop‑in replacement)\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn, torch\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.c = cfg                          # keep a local copy\n",
    "\n",
    "        # ---------- residue‑level EGNN backbone -------------------\n",
    "        self.egnn = StackedEGNN(\n",
    "            cfg.dim, cfg.depth, cfg.hidden_dim, cfg.dropout,\n",
    "            cfg.hood_k, 98, cfg.num_neighbors, cfg.get('norm_coors', True)\n",
    "        ).to(cfg.device)\n",
    "\n",
    "        # ---------- optional blocks --------------------------------\n",
    "        self.rbf  = TunableBlock(LearnableRBF(cfg.basis, 10.).to(cfg.device),\n",
    "                                 cfg.use_rbf)\n",
    "        self.attn = TunableBlock(AttentionBlock(cfg.dim + cfg.basis,\n",
    "                                                cfg.dim + cfg.basis,\n",
    "                                                cfg.hidden_dim).to(cfg.device),\n",
    "                                 cfg.use_attn)\n",
    "\n",
    "        # ---------- neighbour → scalar aggregators -----------------\n",
    "        C = cfg.dim + cfg.basis   \n",
    "        \n",
    "                             # feature channels\n",
    "        # ---- aggregation paths -----------------------------------------\n",
    "        if self.c.aggregator == 'linear':\n",
    "            # (R, C, N)  →  (R, N, C) so Linear sees last‑dim = C\n",
    "            per_neigh = self.agg(tok.permute(0, 2, 1))     # (R, N, 1)\n",
    "            preds     = per_neigh.max(1).values            # (R, 1)\n",
    "\n",
    "        elif self.c.aggregator == 'nconv':\n",
    "            # nconv expects (R, N, C) layout inside Conv1d\n",
    "            preds = self.agg(tok).squeeze(-1)              # (R, 1)\n",
    "\n",
    "        elif self.c.aggregator == 'pool':                  # ablation\n",
    "            preds = tok.max(1).values.unsqueeze(-1)        # (R, 1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"aggregator must be 'linear', 'nconv', or 'pool'\")\n",
    "\n",
    "        if cfg.aggregator == 'linear':\n",
    "            self.agg = nn.Linear(C, 1).to(cfg.device)\n",
    "        elif cfg.aggregator == 'nconv':\n",
    "            # in‑channels = hood_k, kernel = C   (N,C) layout\n",
    "            self.agg = nn.Conv1d(cfg.hood_k, 1, kernel_size=C, padding=0).to(cfg.device)\n",
    "        elif cfg.aggregator == 'pool':                 # max‑pool *without* linear\n",
    "            self.agg = None\n",
    "        else:\n",
    "            raise ValueError(\"aggregator must be 'linear', 'nconv', or 'pool'\")\n",
    "\n",
    "        # ---------- optional boost  (pred_head2) -------------------\n",
    "        self.boost = nn.Linear(1, 1).to(cfg.device) if cfg.get('use_boost', False) else nn.Identity()\n",
    "\n",
    "        # ---------- protein‑level EGNN & final conv ----------------\n",
    "        self.use_prot = cfg.get('use_prot_egnn', True)\n",
    "        self.prot = (EGNN(dim=1, update_coors=True, num_nearest_neighbors=3)\n",
    "                     .to(cfg.device)) if self.use_prot else nn.Identity()\n",
    "\n",
    "        self.use_conv = cfg.get('use_conv', False)\n",
    "        if self.use_conv:\n",
    "            k = cfg.get('conv_kernel', 7)\n",
    "            self.conv = nn.Conv1d(1, 1, k, padding=k // 2).to(cfg.device)\n",
    "        else:\n",
    "            self.conv = nn.Identity()\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    def forward(self, z, x):                       # z:(R,N) , x:(R,N,3)\n",
    "        h, coord = self.egnn(z, x); h = h[0]       # (R,N,dim)\n",
    "\n",
    "        cent = coord.mean(1, keepdim=True)         # (R,1,3)\n",
    "        if self.c.use_rbf:\n",
    "            r = self.rbf(cent, coord).transpose(1, 2)          # (R,basis,N)\n",
    "        else:\n",
    "            r = h.new_zeros(h.size(0), self.c.basis, self.c.hood_k)\n",
    "\n",
    "        tok = torch.cat((r, h.transpose(1, 2)), 1)             # (R,C,N)\n",
    "\n",
    "        # ---- attention (tuple‑safe) ------------------------------\n",
    "        out = self.attn(tok.permute(2, 0, 1))\n",
    "        tok = out[0] if isinstance(out, (tuple, list)) else out\n",
    "        tok = tok.permute(1, 0, 2)                              # (R,N,C)\n",
    "\n",
    "        # ---- aggregation paths -----------------------------------\n",
    "        if self.c.aggregator == 'linear':\n",
    "            pooled = tok.max(1).values                          # (R,C)\n",
    "            preds  = self.agg(pooled)                           # (R,1)\n",
    "        elif self.c.aggregator == 'nconv':\n",
    "            preds  = self.agg(tok).squeeze(-1)                  # (R,1)\n",
    "        else:                                                   # 'pool'\n",
    "            preds  = tok.max(1).values.unsqueeze(-1)            # (R,1)\n",
    "\n",
    "        # optional boost\n",
    "        preds = self.boost(preds)\n",
    "\n",
    "        # protein‑level EGNN\n",
    "        if self.use_prot:\n",
    "            preds = self.prot(preds.unsqueeze(0),\n",
    "                              cent.permute(1, 0, 2))[0].squeeze(0)\n",
    "\n",
    "        # final conv (1×k across residues)\n",
    "        if self.use_conv:\n",
    "            preds = self.conv(preds.T.unsqueeze(0)).squeeze(0).T  # (R,1)\n",
    "\n",
    "        return preds\n",
    "cfg.update(dict(\n",
    "    use_rbf       = False,\n",
    "    use_attn      = False,\n",
    "    aggregator    = 'linear',   # ← decide before instantiating\n",
    "    use_boost     = False,\n",
    "    use_prot_egnn = True,\n",
    "    use_conv      = False,\n",
    "))\n",
    "\n",
    "model=Model(cfg)\n",
    "\n",
    "print(\"params:\",sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# ================================================================\n",
    "# 4) loaders\n",
    "# ================================================================\n",
    "allp=glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "tr,val=split(allp)\n",
    "train_ds=HoodDS(tr,cfg.hood_k); val_ds=HoodDS(val,cfg.hood_k)\n",
    "coll=lambda b: pad(b,cfg.hood_k,cfg.device,cfg.analysis_mode)\n",
    "tr_loader=DataLoader(train_ds,batch_size=cfg.batch_size,shuffle=True ,collate_fn=coll)\n",
    "va_loader=DataLoader(val_ds,batch_size=cfg.batch_size,shuffle=False,collate_fn=coll)\n",
    "\n",
    "# ================================================================\n",
    "# 5) training utils\n",
    "# ================================================================\n",
    "p_fn=nn.L1Loss() if cfg.loss_type=='mae' else nn.MSELoss()\n",
    "s_fn=nn.MSELoss() if cfg.study_metrics and cfg.loss_type=='mae' else \\\n",
    "     nn.L1Loss() if cfg.study_metrics else None\n",
    "pname='MAE' if cfg.loss_type=='mae' else 'MSE'; sname='MSE' if pname=='MAE' else 'MAE'\n",
    "opt=torch.optim.AdamW(model.parameters(),lr=cfg.lr)\n",
    "sch=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,'min',0.5,3)\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler=GradScaler(enabled=(cfg.device=='cuda'))\n",
    "\n",
    "def run(loader,train):\n",
    "    model.train() if train else model.eval(); P=S=0;n=0\n",
    "    for batch in loader:\n",
    "        z,x,y,m,*rest=batch        # rest = [ids] or []\n",
    "        v=m.view(-1); z=z.view(-1,z.size(2))[v].to(cfg.device)\n",
    "        x=x.view(-1,x.size(2),3)[v].to(cfg.device); y=y.view(-1)[v].to(cfg.device)\n",
    "        with autocast(enabled=(cfg.device=='cuda')):\n",
    "            pred=model(z,x).flatten(); loss=p_fn(pred,y); sec=s_fn(pred,y).item() if s_fn else 0.\n",
    "        if train:\n",
    "            opt.zero_grad(); scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        P+=loss.item(); S+=sec; n+=1\n",
    "    return P/n, (S/n if s_fn else None)\n",
    "\n",
    "# ================================================================\n",
    "# 6) train\n",
    "# ================================================================\n",
    "for e in range(cfg.epochs):\n",
    "    tr_p,tr_s=run(tr_loader,True)\n",
    "    va_p,va_s=run(va_loader,False); sch.step(va_p)\n",
    "    msg=f\"[{e+1}/{cfg.epochs}] train {pname}:{tr_p:.4f} | val {pname}:{va_p:.4f}\"\n",
    "    if s_fn: msg+=f\" || train {sname}:{tr_s:.4f} | val {sname}:{va_s:.4f}\"\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run‑ID: 20250726_222332\n",
      "params: 17695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] train MAE:1.5971 | val MAE:1.2026 || train other:3.9319 | val other:2.4462\n",
      "[2/3] train MAE:1.4604 | val MAE:1.0831 || train other:3.5514 | val other:2.2081\n",
      "[3/3] train MAE:1.3527 | val MAE:1.0277 || train other:3.2811 | val other:2.0960\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 0) dashboard – flip flags here, nothing else\n",
    "# ================================================================\n",
    "class Cfg(dict):\n",
    "    __getattr__ = dict.__getitem__; __setattr__ = dict.__setitem__\n",
    "cfg = Cfg(\n",
    "    # backbone\n",
    "    dim=12, basis=6, depth=2, hidden_dim=4, dropout=0.02,\n",
    "    hood_k=100, num_neighbors=8, norm_coors=True,\n",
    "\n",
    "    # aggregation: 'linear' | 'nconv' | 'pool'\n",
    "    aggregator   ='linear',\n",
    "\n",
    "    # block switches\n",
    "    use_rbf      =False,\n",
    "    use_attn     =False,\n",
    "    use_boost    =False,      # Linear(1→1) after aggregator\n",
    "    use_prot     =True,       # protein‑level EGNN\n",
    "    use_conv     =False,      # 1‑D conv after prot EGNN\n",
    "    conv_kernel  =7,          # kernel size for the conv\n",
    "\n",
    "    # training\n",
    "    loss_type='mae', study_metrics=True,\n",
    "    lr=5e-3, epochs=3, batch_size=1,\n",
    "\n",
    "    # misc\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    seed=0, analysis_mode=False,\n",
    "    num_paths=2, split_ratio=0.8, split_seed=0,\n",
    "    runid=datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    ")\n",
    "print(\"Run‑ID:\", cfg.runid)\n",
    "\n",
    "# ================================================================\n",
    "# 1) reproducibility\n",
    "# ================================================================\n",
    "import random, os, numpy as np, torch, glob, datetime\n",
    "random.seed(cfg.seed); np.random.seed(cfg.seed); torch.manual_seed(cfg.seed)\n",
    "torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# ================================================================\n",
    "# 2) dataset helpers\n",
    "# ================================================================\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class HoodDS(Dataset):\n",
    "    def __init__(self, paths, k):\n",
    "        self.data=[]; self.ids=[]\n",
    "        nbr=NearestNeighbors(k,algorithm='brute')\n",
    "        for p in paths:\n",
    "            try:\n",
    "                d=np.load(p,allow_pickle=True)\n",
    "                if len(d['sites'])==0: continue\n",
    "                nbr.fit(d['pos']); idx=nbr.kneighbors(d['sites'],return_distance=False)\n",
    "                self.data.append((torch.from_numpy(d['z'][idx]),\n",
    "                                  torch.from_numpy(d['pos'][idx]),\n",
    "                                  torch.from_numpy(d['pks'])))\n",
    "                self.ids.append(os.path.splitext(os.path.basename(p))[0])\n",
    "            except Exception as e: print(\"skip\",p,e)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        z,p,y=self.data[i]; return z,p,y,self.ids[i]\n",
    "\n",
    "def pad(batch,k,device,ret_ids):\n",
    "    ids=[b[3] for b in batch] if ret_ids else None\n",
    "    B=len(batch); S=max(b[0].shape[0] for b in batch)\n",
    "    zt=torch.zeros(B,S,k,dtype=torch.int32,device=device)\n",
    "    pt=torch.zeros(B,S,k,3,dtype=torch.float32,device=device)\n",
    "    yt=torch.full((B,S),float('nan'),device=device); mt=torch.zeros(B,S,dtype=torch.bool,device=device)\n",
    "    for b,(z,p,y,_) in enumerate(batch):\n",
    "        s=z.shape[0]; zt[b,:s]=z; pt[b,:s]=p; yt[b,:s]=y; mt[b,:s]=True\n",
    "    return (zt,pt,yt,mt,ids) if ret_ids else (zt,pt,yt,mt)\n",
    "\n",
    "def split(paths):\n",
    "    if cfg.num_paths: paths=paths[:cfg.num_paths]\n",
    "    rng=np.random.RandomState(cfg.split_seed)\n",
    "    idx=rng.permutation(len(paths)); cut=int(len(paths)*cfg.split_ratio)\n",
    "    return [paths[i] for i in idx[:cut]], [paths[i] for i in idx[cut:]]\n",
    "\n",
    "# ================================================================\n",
    "# 3) model\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,c):\n",
    "        super().__init__(); self.c=c\n",
    "        C = c.dim + c.basis                       # per‑atom channel count\n",
    "\n",
    "        self.egnn = StackedEGNN(c.dim,c.depth,c.hidden_dim,c.dropout,\n",
    "                                c.hood_k,98,c.num_neighbors,c.norm_coors).to(c.device)\n",
    "\n",
    "        self.rbf  = TunableBlock(LearnableRBF(c.basis,10.).to(c.device), c.use_rbf)\n",
    "        self.attn = TunableBlock(AttentionBlock(C,C,c.hidden_dim).to(c.device), c.use_attn)\n",
    "\n",
    "        if c.aggregator=='linear':\n",
    "            self.agg = nn.Linear(C,1).to(c.device)\n",
    "        elif c.aggregator=='nconv':\n",
    "            self.agg = nn.Conv1d(c.hood_k,1,kernel_size=C,padding=0).to(c.device)\n",
    "        elif c.aggregator=='pool':\n",
    "            self.agg = None\n",
    "        else: raise ValueError(\"aggregator must be 'linear' | 'nconv' | 'pool'\")\n",
    "\n",
    "        self.boost = nn.Linear(1,1).to(c.device) if c.use_boost else nn.Identity()\n",
    "        self.prot  = EGNN(dim=1,update_coors=True,num_nearest_neighbors=3).to(c.device) \\\n",
    "                     if c.use_prot else nn.Identity()\n",
    "        self.conv  = (nn.Conv1d(1,1,c.conv_kernel,padding=c.conv_kernel//2).to(c.device)\n",
    "                      if c.use_conv else nn.Identity())\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    def forward(self,z,x):                      # z:(R,N)  x:(R,N,3)\n",
    "        h,coord=self.egnn(z,x); h=h[0]          # h:(R,N,dim)\n",
    "        cent=coord.mean(1,keepdim=True)         # (R,1,3)\n",
    "\n",
    "        if self.c.use_rbf:\n",
    "            r=self.rbf(cent,coord).transpose(1,2)            # (R,basis,N)\n",
    "        else:\n",
    "            r=h.new_zeros(h.size(0),self.c.basis,self.c.hood_k)\n",
    "\n",
    "        tok=torch.cat((r,h.transpose(1,2)),1)                # (R,C,N)\n",
    "\n",
    "        attn_out=self.attn(tok.permute(2,0,1))\n",
    "        tok     = attn_out[0] if isinstance(attn_out,(list,tuple)) else attn_out\n",
    "        tok     = tok.permute(1,0,2)                         # (R,N,C)\n",
    "\n",
    "        # --- aggregation --------------------------------------\n",
    "        if self.c.aggregator=='linear':\n",
    "            per_neigh=self.agg(tok)                          # (R,N,1)\n",
    "            preds    = per_neigh.max(1).values               # (R,1)\n",
    "        elif self.c.aggregator=='nconv':\n",
    "            preds=self.agg(tok.transpose(1,2)).squeeze(-1)   # (R,1)\n",
    "        else:  # 'pool'\n",
    "            preds=tok.max(1).values.unsqueeze(-1)            # (R,1)\n",
    "\n",
    "        preds=self.boost(preds)                              # optional boost\n",
    "\n",
    "        if self.c.use_prot:\n",
    "            preds=self.prot(preds.unsqueeze(0),\n",
    "                            cent.permute(1,0,2))[0].squeeze(0)\n",
    "\n",
    "        if self.c.use_conv:\n",
    "            preds=self.conv(preds.T.unsqueeze(0)).squeeze(0).T\n",
    "\n",
    "        return preds\n",
    "model=Model(cfg); print(\"params:\",sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# ================================================================\n",
    "# 4) loaders\n",
    "# ================================================================\n",
    "allp=glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "tr,val=split(allp)\n",
    "train_ds=HoodDS(tr,cfg.hood_k); val_ds=HoodDS(val,cfg.hood_k)\n",
    "coll=lambda b: pad(b,cfg.hood_k,cfg.device,cfg.analysis_mode)\n",
    "tr_loader=DataLoader(train_ds,batch_size=cfg.batch_size,shuffle=True ,collate_fn=coll)\n",
    "va_loader=DataLoader(val_ds,batch_size=cfg.batch_size,shuffle=False,collate_fn=coll)\n",
    "\n",
    "# ================================================================\n",
    "# 5) training utils\n",
    "# ================================================================\n",
    "p_fn=nn.L1Loss() if cfg.loss_type=='mae' else nn.MSELoss()\n",
    "s_fn=nn.MSELoss() if cfg.study_metrics and cfg.loss_type=='mae' else \\\n",
    "     nn.L1Loss() if cfg.study_metrics else None\n",
    "opt=torch.optim.AdamW(model.parameters(),lr=cfg.lr)\n",
    "sch=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,'min',0.5,3)\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler=GradScaler(enabled=(cfg.device=='cuda'))\n",
    "\n",
    "def run(loader,train):\n",
    "    model.train() if train else model.eval(); P=S=0;n=0\n",
    "    for batch in loader:\n",
    "        z,x,y,m,*_ = batch\n",
    "        v=m.view(-1); z=z.view(-1,z.size(2))[v].to(cfg.device)\n",
    "        x=x.view(-1,x.size(2),3)[v].to(cfg.device); y=y.view(-1)[v].to(cfg.device)\n",
    "        with autocast(enabled=(cfg.device=='cuda')):\n",
    "            pred=model(z,x).flatten(); loss=p_fn(pred,y)\n",
    "            sec=s_fn(pred,y).item() if s_fn else 0.\n",
    "        if train:\n",
    "            opt.zero_grad(); scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        P+=loss.item(); S+=sec; n+=1\n",
    "    return P/n, (S/n if s_fn else None)\n",
    "\n",
    "# ================================================================\n",
    "# 6) train\n",
    "# ================================================================\n",
    "for e in range(cfg.epochs):\n",
    "    tr_p,tr_s=run(tr_loader,True)\n",
    "    va_p,va_s=run(va_loader,False); sch.step(va_p)\n",
    "    msg=f\"[{e+1}/{cfg.epochs}] train {cfg.loss_type.upper()}:{tr_p:.4f} | \" \\\n",
    "        f\"val {cfg.loss_type.upper()}:{va_p:.4f}\"\n",
    "    if s_fn: msg+=f\" || train other:{tr_s:.4f} | val other:{va_s:.4f}\"\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linear'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] train MAE:1.2685 | val MAE:1.0217 || train other:3.1997 | val other:2.0759\n",
      "[2/3] train MAE:1.2685 | val MAE:1.0217 || train other:3.1997 | val other:2.0759\n",
      "[3/3] train MAE:1.2685 | val MAE:1.0217 || train other:3.1997 | val other:2.0759\n"
     ]
    }
   ],
   "source": [
    "# n‑conv without RBF / Attn\n",
    "cfg.aggregator = 'linear'\n",
    "cfg.use_rbf = cfg.use_attn = False\n",
    "cfg.use_boost = False\n",
    "# re‑instantiate:\n",
    "model = Model(cfg)\n",
    "\n",
    "\n",
    "for e in range(cfg.epochs):\n",
    "    tr_p,tr_s=run(tr_loader,True)\n",
    "    va_p,va_s=run(va_loader,False); sch.step(va_p)\n",
    "    msg=f\"[{e+1}/{cfg.epochs}] train {cfg.loss_type.upper()}:{tr_p:.4f} | \" \\\n",
    "        f\"val {cfg.loss_type.upper()}:{va_p:.4f}\"\n",
    "    if s_fn: msg+=f\" || train other:{tr_s:.4f} | val other:{va_s:.4f}\"\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] train MAE:1.2776 | val MAE:1.0904 || train other:3.3217 | val other:2.3500\n",
      "[2/3] train MAE:1.2782 | val MAE:1.0904 || train other:3.3261 | val other:2.3500\n",
      "[3/3] train MAE:1.2790 | val MAE:1.0904 || train other:3.3255 | val other:2.3500\n"
     ]
    }
   ],
   "source": [
    "# n‑conv without RBF / Attn\n",
    "cfg.aggregator = 'linear'\n",
    "cfg.use_rbf = cfg.use_attn = True\n",
    "cfg.use_boost = True\n",
    "# re‑instantiate:\n",
    "model = Model(cfg)\n",
    "\n",
    "\n",
    "for e in range(cfg.epochs):\n",
    "    tr_p,tr_s=run(tr_loader,True)\n",
    "    va_p,va_s=run(va_loader,False); sch.step(va_p)\n",
    "    msg=f\"[{e+1}/{cfg.epochs}] train {cfg.loss_type.upper()}:{tr_p:.4f} | \" \\\n",
    "        f\"val {cfg.loss_type.upper()}:{va_p:.4f}\"\n",
    "    if s_fn: msg+=f\" || train other:{tr_s:.4f} | val other:{va_s:.4f}\"\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run‑ID: 20250726_222839\n",
      "params: 17695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3]  train 1.5971 | val 1.2026\n",
      "[2/3]  train 1.4604 | val 1.0831\n",
      "[3/3]  train 1.3527 | val 1.0277\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 0) dashboard – flip anything here\n",
    "# ================================================================\n",
    "class Cfg(dict):\n",
    "    __getattr__ = dict.__getitem__; __setattr__ = dict.__setitem__\n",
    "cfg = Cfg(\n",
    "    # backbone\n",
    "    dim=12, basis=6, depth=2, hidden_dim=4, dropout=0.02,\n",
    "    hood_k=100, num_neighbors=8, norm_coors=True,\n",
    "\n",
    "    # aggregation: 'linear' | 'nconv' | 'pool'\n",
    "    aggregator   ='linear',\n",
    "\n",
    "    # block switches\n",
    "    use_rbf      =False,\n",
    "    use_attn     =False,\n",
    "    use_boost    =False,     # Linear(1→1) after aggregator\n",
    "    use_prot     =True,      # protein‑level EGNN\n",
    "    use_conv     =False,     # 1‑D conv after prot EGNN\n",
    "    conv_kernel  =7,\n",
    "\n",
    "    # training\n",
    "    loss_type='mae', study_metrics=False,\n",
    "    lr=5e-3, epochs=3, batch_size=1,\n",
    "\n",
    "    # misc\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    seed=0, analysis_mode=False,\n",
    "    num_paths=2, split_ratio=0.8, split_seed=0,\n",
    "    runid=datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    ")\n",
    "print(\"Run‑ID:\", cfg.runid)\n",
    "\n",
    "# ================================================================\n",
    "# 1) reproducibility\n",
    "# ================================================================\n",
    "import random, os, numpy as np, torch, glob, datetime\n",
    "random.seed(cfg.seed); np.random.seed(cfg.seed); torch.manual_seed(cfg.seed)\n",
    "torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# ================================================================\n",
    "# 2) dataset helpers\n",
    "# ================================================================\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class HoodDS(Dataset):\n",
    "    def __init__(self, paths, k):\n",
    "        self.data=[]; self.ids=[]\n",
    "        nbr=NearestNeighbors(k,algorithm='brute')\n",
    "        for p in paths:\n",
    "            try:\n",
    "                d=np.load(p,allow_pickle=True)\n",
    "                if len(d['sites'])==0: continue\n",
    "                nbr.fit(d['pos']); idx=nbr.kneighbors(d['sites'],return_distance=False)\n",
    "                self.data.append((torch.from_numpy(d['z'][idx]),\n",
    "                                  torch.from_numpy(d['pos'][idx]),\n",
    "                                  torch.from_numpy(d['pks'])))\n",
    "                self.ids.append(os.path.splitext(os.path.basename(p))[0])\n",
    "            except Exception as e: print(\"skip\",p,e)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i):\n",
    "        z,p,y=self.data[i]; return z,p,y,self.ids[i]\n",
    "\n",
    "def pad(batch,k,device,ret_ids):\n",
    "    ids=[b[3] for b in batch] if ret_ids else None\n",
    "    B=len(batch); S=max(b[0].shape[0] for b in batch)\n",
    "    zt=torch.zeros(B,S,k,dtype=torch.int32,device=device)\n",
    "    pt=torch.zeros(B,S,k,3,dtype=torch.float32,device=device)\n",
    "    yt=torch.full((B,S),float('nan'),device=device); mt=torch.zeros(B,S,dtype=torch.bool,device=device)\n",
    "    for b,(z,p,y,_) in enumerate(batch):\n",
    "        s=z.shape[0]; zt[b,:s]=z; pt[b,:s]=p; yt[b,:s]=y; mt[b,:s]=True\n",
    "    return (zt,pt,yt,mt,ids) if ret_ids else (zt,pt,yt,mt)\n",
    "\n",
    "def split(paths):\n",
    "    if cfg.num_paths: paths=paths[:cfg.num_paths]\n",
    "    rng=np.random.RandomState(cfg.split_seed)\n",
    "    idx=rng.permutation(len(paths)); cut=int(len(paths)*cfg.split_ratio)\n",
    "    return [paths[i] for i in idx[:cut]], [paths[i] for i in idx[cut:]]\n",
    "\n",
    "# ================================================================\n",
    "# 3) model\n",
    "# ================================================================\n",
    "from architecture import StackedEGNN, LearnableRBF, AttentionBlock, TunableBlock\n",
    "from egnn_pytorch import EGNN\n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,c):\n",
    "        super().__init__(); self.c=c\n",
    "        C = c.dim + c.basis\n",
    "\n",
    "        self.egnn = StackedEGNN(c.dim,c.depth,c.hidden_dim,c.dropout,\n",
    "                                c.hood_k,98,c.num_neighbors,c.norm_coors).to(c.device)\n",
    "\n",
    "        self.rbf  = TunableBlock(LearnableRBF(c.basis,10.).to(c.device), c.use_rbf)\n",
    "        self.attn = TunableBlock(AttentionBlock(C,C,c.hidden_dim).to(c.device), c.use_attn)\n",
    "\n",
    "        if c.aggregator=='linear':\n",
    "            self.agg = nn.Linear(C,1).to(c.device)\n",
    "        elif c.aggregator=='nconv':\n",
    "            self.agg = nn.Conv1d(c.hood_k,1,kernel_size=C,padding=0).to(c.device)\n",
    "        elif c.aggregator=='pool':\n",
    "            self.agg = None\n",
    "        else: raise ValueError(\"aggregator must be 'linear' | 'nconv' | 'pool'\")\n",
    "\n",
    "        self.boost = nn.Linear(1,1).to(c.device) if c.use_boost else nn.Identity()\n",
    "        self.prot  = EGNN(dim=1,update_coors=True,num_nearest_neighbors=3).to(c.device) \\\n",
    "                     if c.use_prot else nn.Identity()\n",
    "        self.conv  = nn.Conv1d(1,1,c.conv_kernel,padding=c.conv_kernel//2).to(c.device) \\\n",
    "                     if c.use_conv else nn.Identity()\n",
    "\n",
    "    def forward(self,z,x):\n",
    "        h,coord=self.egnn(z,x); h=h[0]                # (R,N,dim)\n",
    "        cent=coord.mean(1,keepdim=True)               # (R,1,3)\n",
    "\n",
    "        # --- build token ----------------------------------------------------------------\n",
    "        r = self.rbf(cent,coord).transpose(1,2) if self.c.use_rbf else \\\n",
    "            h.new_zeros(h.size(0),self.c.basis,self.c.hood_k)\n",
    "        tok = torch.cat((r,h.transpose(1,2)),1)       # (R,C,N)\n",
    "\n",
    "        att = self.attn(tok.permute(2,0,1))\n",
    "        tok = att[0] if isinstance(att,(tuple,list)) else att\n",
    "        tok = tok.permute(1,0,2)                      # (R,N,C)\n",
    "\n",
    "        # --- aggregation ----------------------------------------------------------------\n",
    "        if self.c.aggregator=='linear':\n",
    "            preds = self.agg(tok) .max(1).values                # (R,1)\n",
    "        elif self.c.aggregator=='nconv':\n",
    "            preds = self.agg(tok).squeeze(-1)                   # (R,1)\n",
    "        else:   # pool\n",
    "            preds = tok.max(1).values.mean(1,keepdim=True)      # (R,1)\n",
    "\n",
    "        preds = self.boost(preds)\n",
    "\n",
    "        if self.c.use_prot:\n",
    "            preds = self.prot(preds.unsqueeze(0),\n",
    "                              cent.permute(1,0,2))[0].squeeze(0)\n",
    "\n",
    "        if self.c.use_conv:\n",
    "            preds = self.conv(preds.T.unsqueeze(0)).squeeze(0).T\n",
    "\n",
    "        return preds\n",
    "model=Model(cfg); print(\"params:\",sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# ================================================================\n",
    "# 4) loaders\n",
    "# ================================================================\n",
    "allp=glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "tr,val=split(allp)\n",
    "train_ds=HoodDS(tr,cfg.hood_k); val_ds=HoodDS(val,cfg.hood_k)\n",
    "coll=lambda b: pad(b,cfg.hood_k,cfg.device,cfg.analysis_mode)\n",
    "tr_loader=DataLoader(train_ds,batch_size=cfg.batch_size,shuffle=True ,collate_fn=coll)\n",
    "va_loader=DataLoader(val_ds,batch_size=cfg.batch_size,shuffle=False,collate_fn=coll)\n",
    "\n",
    "# ================================================================\n",
    "# 5) training utils\n",
    "# ================================================================\n",
    "p_fn = nn.L1Loss() if cfg.loss_type=='mae' else nn.MSELoss()\n",
    "opt  = torch.optim.AdamW(model.parameters(),lr=cfg.lr)\n",
    "sch  = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,'min',0.5,3)\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler=GradScaler(enabled=(cfg.device=='cuda'))\n",
    "\n",
    "def run(loader,train):\n",
    "    model.train() if train else model.eval(); loss_sum=0;n=0\n",
    "    for z,x,y,m,*_ in loader:\n",
    "        v=m.view(-1); z=z.view(-1,z.size(2))[v].to(cfg.device)\n",
    "        x=x.view(-1,x.size(2),3)[v].to(cfg.device); y=y.view(-1)[v].to(cfg.device)\n",
    "        with autocast(enabled=(cfg.device=='cuda')):\n",
    "            pred=model(z,x).flatten(); loss=p_fn(pred,y)\n",
    "        if train:\n",
    "            opt.zero_grad(); scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        loss_sum+=loss.item(); n+=1\n",
    "    return loss_sum/n\n",
    "\n",
    "# ================================================================\n",
    "# 6) train\n",
    "# ================================================================\n",
    "for e in range(cfg.epochs):\n",
    "    tr=run(tr_loader,True)\n",
    "    va=run(va_loader,False); sch.step(va)\n",
    "    print(f\"[{e+1}/{cfg.epochs}]  train {tr:.4f} | val {va:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
