{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ccbb5dced957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0megnn_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEGNN_Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"WANDB_MODE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"offline\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"
     ]
    }
   ],
   "source": [
    "#2020\n",
    "#f3d86a6de7f8cf4262f3b272206e26a9275cd1d8\n",
    "from architecture import *\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import wandb\n",
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "print(\"NPZ in\",len(train_ds), len(val_ds), (time.time() - to) / 60, \"min\")\n",
    "def collate_graphs(batch):\n",
    "    return batch\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=0, pin_memory=True, collate_fn=collate_graphs\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=0, pin_memory=True, collate_fn=collate_graphs\n",
    ")\n",
    "print(\"pinned and reaady\",len(train_loader), len(val_loader), (time.time() - to) / 60, \"min\")\n",
    "# 2) model pieces\n",
    "\n",
    "# --- EGNN + FFN + residual block ---\n",
    "# --- EGNN + FFN + residual block ---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3) instantiate everything\n",
    "dim, basis = 10, 64 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=256\n",
    "num_global_tokens=256\n",
    "dropout=0.02\n",
    "cutoff=20.0\n",
    "epochs=150\n",
    "num_neighbors=2\n",
    "net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "A     = PositionalEncoding(dim+basis).to(device)\n",
    "mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "model = TinyRegressor(in_channels=basis+dim,hidden_dim=dim+basis).to(device)\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "#8)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": net.parameters(),   \"lr\":5e-3},\n",
    "    {\"params\": mha.parameters(),   \"lr\":5e-3},\n",
    "    {\"params\": model.parameters(), \"lr\":5e-3},\n",
    "    {\"params\": RBF.parameters(),   \"lr\":5e-3}])\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.1)\n",
    "print(\"scheduler 5e-3. num nearest neiighbors 2 cutoff 9 num heads = in_dim.\")#\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=.99, patience=0, cooldown=0, min_lr=1e-8, verbose=False)\n",
    "# 4) training + validation\n",
    "train_hist, val_hist = [], []\n",
    "print(\"runid:\",runid)\n",
    "print(\"dim = num heads embeded dim:\", dim)\n",
    "print(\"depth\",depth)\n",
    "print(\"hidden_dim:\",hidden_dim)\n",
    "print(\"basis\", basis)\n",
    "print(f\"hidden dim 8. lower optimizer and inc batch size to 25 from 5. changed mha to act on all and more thx to mam and chat anon and more\")#rbf cut 4 same as real cutouts, only .01 dropout regularization, batch size 250. full val, {len(train_loader)} train\")\n",
    "print(\"\")\n",
    "#print(optimizer.state_dict())\n",
    "print(\"FIX SCHEDULER Max schedular cool 0 wait 0 min 1e-8 patience zero cooldown zero\")\n",
    "print(criterion)\n",
    "\"\"\"out1 N, dim\n",
    "attn out N, N, 2\n",
    "pairwise Ds 1,1,N\n",
    "rbf 1 1 N n_rbf\n",
    "rbf N basis\n",
    "model input N 3 3\n",
    "gnode N 1\n",
    "gemb 1 nasis+1 n \n",
    "pooled 1 1 1\n",
    "\"\"\"\n",
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"Biomodeling\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"Overfit PKEGNN on num_atoms = 500\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\"runid\": runid,\n",
    "        \"learning_rate\": [op[\"lr\"] for op in optimizer.param_groups], #net mha model rbf\n",
    "        \"dataset\": f\"inputs3 (num neighbors = 500) {len(paths) + len(tpaths)}\",\n",
    "        \"batch size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"dim\": dim,\n",
    "        \"depth\": depth,\n",
    "        \"basis\": basis,\n",
    "        \"num edge and global tokens\": [num_edge_tokens,num_global_tokens],\n",
    "        \"dropout\": [dropout, 0.03], #egnn p.enc. \n",
    "        \"rbf cutoff\": cutoff,\n",
    "        \"scheduler\": [scheduler.min_lrs,scheduler.cooldown,scheduler.factor,\"updates per epoch\"],\n",
    "        \"loss\": criterion,\n",
    "        \"architecture\": b\"EGNN (1 blocks) --> coords thru rbf --> concat rbf_out + egnn_out[0] ==> MHA --> model.linear --> pool > all protein's outputs thru model.linear2\"})\n",
    "vl,tl=[],[]\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    net.train(); mha.train(); model.train(); RBF.train()\n",
    "    epoch_train_losses = []\n",
    "\n",
    "    # training\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        for zs, xs, ys in batch:\n",
    "            outs = []\n",
    "            for z_t, x_t in zip(zs, xs):\n",
    "                z_t = z_t.to(device).unsqueeze(0)\n",
    "                x_t = x_t.to(device).unsqueeze(0)\n",
    "                with autocast():\n",
    "                    out1, coords = net(z_t, x_t)\n",
    "\n",
    "                    #dmat = pairwise_distances(coords)\n",
    "                    rbf  = RBF(pairwise_distances(coords))\n",
    "                    b=torch.concat((rbf[:,0].T,out1[0].T.unsqueeze(2)))\n",
    "                    en = A(b.permute(1,2,0)) #encoding\n",
    "                    c=model.lin(mha(en)[0])\n",
    "\n",
    "                    pooled = model.scalar_pool(c)[0][0] \n",
    "\n",
    "                outs.append(pooled)\n",
    "            \n",
    "            preds  = torch.stack(outs).to(device)\n",
    "            #print(preds.shape,\"preds\")\n",
    "            \n",
    "            target = torch.hstack(ys).to(device).flatten()\n",
    "            with autocast():\n",
    "                #preds2=model.conv5(preds.unsqueeze(1)).to(device).flatten()\n",
    "                pred3=model.lin2(preds).flatten().to(device)\n",
    "            #pred3=model.relu(preds)\n",
    "            #pred3=model.rel(preds)\n",
    "            loss = criterion(pred3, target)\n",
    "            #print(loss)\n",
    "            #print(pred3)\n",
    "            if use_amp:\n",
    "                #with autocast():\n",
    "                scaler.scale(loss).backward()\n",
    "                #scheduler.step(loss)\n",
    "                \n",
    "            else:\n",
    "                loss.backward()\n",
    "            epoch_train_losses.append(loss.item())\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            optimizer.step()\n",
    "\n",
    "    #train_hist.append(np.mean(epoch_train_losses))\n",
    "    \n",
    "\n",
    "    # validation\n",
    "    print(loss)\n",
    "    net.eval(); mha.eval(); model.eval(); RBF.eval()\n",
    "    epoch_val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            for zs, xs, ys in batch:\n",
    "                outs = []\n",
    "                for z_t, x_t in zip(zs, xs):\n",
    "                    z_t = z_t.to(device).unsqueeze(0)\n",
    "                    x_t = x_t.to(device).unsqueeze(0)\n",
    "                    with autocast():\n",
    "                        out1, coords = net(z_t, x_t)\n",
    "                        rbf  = RBF(pairwise_distances(coords))\n",
    "                        b=torch.concat((rbf[:,0].T,out1[0].T.unsqueeze(2)))\n",
    "                        en = A(b.permute(1,2,0)) #encoding\n",
    "                        c=model.lin(mha(en)[0])\n",
    "\n",
    "                    pooled = model.scalar_pool(c)[0][0] \n",
    "                    outs.append(pooled)\n",
    "                \n",
    "                preds  = torch.stack(outs).to(device)\n",
    "                #print(preds.shape,\"preds\")\n",
    "                \n",
    "                target = torch.hstack(ys).to(device).flatten()\n",
    "                \n",
    "                with autocast():\n",
    "                    #preds2=model.conv5(preds.unsqueeze(1)).to(device).flatten()\n",
    "                    pred3=model.lin2(preds).flatten().to(device)\n",
    "                loss = criterion(pred3, target)\n",
    "                epoch_val_losses.append(loss)\n",
    "                #loss = torch.mean(epoch_val_losses)\n",
    "                #scheduler.step(loss)  # val_loss = your average validation loss\n",
    "                #scheduler.step(loss) \n",
    "            #e\n",
    "            #print(val_loss.item())\n",
    "\n",
    "                    # 5) save a single timestamped checkpoint\n",
    "    \n",
    "    loss=torch.mean(torch.tensor(epoch_val_losses))\n",
    "    scheduler.step(loss) \n",
    "    tl.append(epoch_train_losses)\n",
    "    vl.append(epoch_val_losses)\n",
    "    elapsed_min = (time.time() - t0) / 60\n",
    "    \n",
    "\n",
    "\n",
    "    #print(torch.mean(torch.tensor(epoch_train_losses)),loss)\n",
    "    \n",
    "# 5) save a single timestamped checkpoint\n",
    "    elapsed_min = (time.time() - t0) / 60\n",
    "    print(\"pooled\",pooled, pred3[-1],target[-1])\n",
    "    print(elapsed_min,\"min\")\n",
    "                #print(val_loss.item())\n",
    "\n",
    "                    # 5) save a single timestamped checkpoint\n",
    "    \n",
    "    #loss=torch.mean(torch.tensor(epoch_val_losses))\n",
    "    #scheduler.step(loss) \n",
    "    vloss,tloss=loss.item(),torch.mean(torch.tensor(epoch_train_losses)).item()\n",
    "    #log\n",
    "    run.log({\"tloss\": tloss, \"vloss\": vloss, \"elapsed_time\": elapsed_min})\n",
    "    #elapsed_min = (time.time() - t0) / 60\n",
    "    #print(len(epoch_train_losses),len(epoch_val_losses))\n",
    "    #timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    checkpoint = {\n",
    "        \"epoch\":         epoch+1,\n",
    "        \"elapsed_min\":   elapsed_min,\n",
    "    #    \"net\":           net.state_dict(),\n",
    "    #    \"mha\":           mha.state_dict(),\n",
    "    #    \"model\":         model.state_dict(),\n",
    "    #    \"rbf\":           RBF.state_dict(),\n",
    "    #    \"optimizer\":     optimizer.state_dict(),\n",
    "        \"train_history\": tl,\n",
    "        \"val_history\":   vl}\n",
    "    #}\n",
    "    torch.save(checkpoint, f\"./{runid}-checkpoint.pt\")\n",
    "    #print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\")\n",
    "\n",
    "    #val_hist.append(loss.item())\n",
    "    print(f\" → avg train loss: {tloss:.4f}\")\n",
    "    print(f\" → avg   val loss: {vloss:.4f}\")\n",
    "run.finish()\n",
    "\n",
    "# 5) save a single timestamped checkpoint\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "timestamp   = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint = {\n",
    "    \"epoch\":         epoch+1,\n",
    "    \"elapsed_min\":   elapsed_min,\n",
    "    \"net\":           net.state_dict(),\n",
    "    \"mha\":           mha.state_dict(),\n",
    "    \"model\":         model.state_dict(),\n",
    "    \"rbf\":           RBF.state_dict(),\n",
    "    \"optimizer\":     optimizer.state_dict(),\n",
    "    \"scheduler\":     scheduler.state_dict(),\n",
    "    \"train_history\": tl,\n",
    "    \"val_history\":   vl,\n",
    "}\n",
    "torch.save(checkpoint, f\"./{runid}-checkpoint_{timestamp}.pt\")\n",
    "print(f\"Saved checkpoint_{timestamp}.pt ({elapsed_min:.1f} min)\")\n",
    "#os.system(\"wandb sync --include-offline --sync-all wandb\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrhoernschemeyer/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from architecture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch OK, shapes: [torch.Size([5, 102, 20]), torch.Size([5, 102, 20, 3]), torch.Size([5, 102])] torch.Size([5, 102])\n"
     ]
    }
   ],
   "source": [
    "for batch in val_loader:\n",
    "    print(\"batch OK, shapes:\", [t.shape for t in batch[:3]], batch[3].shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'coords'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-73cc898fa9c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m#model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_residues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_res\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# (R, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-73cc898fa9c1>\u001b[0m in \u001b[0;36mforward_residues\u001b[0;34m(z_r, x_r)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;31m#d   = torch.cdist(x_r, x_r)            # (R, N, N)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mrbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbf_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m# (R, N, N, basis)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# ---------- concat & attention ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'coords'"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from egnn_pytorch import EGNN\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 15\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=256\n",
    "num_global_tokens=256\n",
    "dropout=0.02\n",
    "cutoff=10.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "all_paths = glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "epochs = 1  # or whatever you like\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    \n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,    coords,  coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids, coords = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        #preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids, coords = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            #preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss.item())\n",
    "\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.2329\n",
      "              |  val L1 = 1.2776\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from egnn_pytorch import EGNN\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 15\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=256\n",
    "num_global_tokens=256\n",
    "dropout=0.02\n",
    "cutoff=10.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "all_paths = glob.glob(\"../../../data/pkegnn_INS/inputs/*.npz\")\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "epochs = 1  # or whatever you like\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    centroids=coords.mean(dim=0)\n",
    "    rbf = rbf_layer(centroids,coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf.transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,    centroids                              # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        #preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            #preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss.item())\n",
    "\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([121, 15, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([121, 15, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([121, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.mean(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 121, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(coords.mean(dim=1) - coords).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids=coords.mean(dim=1)\n",
    "dist = torch.norm(centroids - coords, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 121, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([121])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords[0].mean(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.2356\n",
      "              |  val L1 = 1.1295\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 15\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=256\n",
    "num_global_tokens=256\n",
    "dropout=0.02\n",
    "cutoff=10.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "all_paths = glob.glob(\"../inputs/*.npz\")\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "epochs = 1  # or whatever you like\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss.item())\n",
    "\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.1770\n",
      "              |  val L1 = 1.0956\n",
      "Epoch   1 | train L1 = 1.1575\n",
      "              |  val L1 = 1.0465\n",
      "Epoch   2 | train L1 = 1.1255\n",
      "              |  val L1 = 1.0123\n",
      "Epoch   3 | train L1 = 1.1085\n",
      "              |  val L1 = 1.0101\n",
      "Epoch   4 | train L1 = 1.1098\n",
      "              |  val L1 = 0.9833\n",
      "Epoch   5 | train L1 = 1.1022\n",
      "              |  val L1 = 0.9626\n",
      "Epoch   6 | train L1 = 1.0896\n",
      "              |  val L1 = 0.9661\n",
      "Epoch   7 | train L1 = 1.0964\n",
      "              |  val L1 = 0.9841\n",
      "Epoch   8 | train L1 = 1.0933\n",
      "              |  val L1 = 1.0415\n",
      "Epoch   9 | train L1 = 1.1144\n",
      "              |  val L1 = 1.0438\n",
      "Epoch  10 | train L1 = 1.1100\n",
      "              |  val L1 = 0.9604\n",
      "Epoch  11 | train L1 = 1.0953\n",
      "              |  val L1 = 0.9550\n",
      "Epoch  12 | train L1 = 1.0857\n",
      "              |  val L1 = 0.9498\n",
      "Epoch  13 | train L1 = 1.0760\n",
      "              |  val L1 = 0.9426\n",
      "Epoch  14 | train L1 = 1.0604\n",
      "              |  val L1 = 0.9507\n",
      "Epoch  15 | train L1 = 1.0770\n",
      "              |  val L1 = 0.9310\n",
      "Epoch  16 | train L1 = 1.0464\n",
      "              |  val L1 = 0.9230\n",
      "Epoch  17 | train L1 = 1.0294\n",
      "              |  val L1 = 0.9169\n",
      "Epoch  18 | train L1 = 1.0303\n",
      "              |  val L1 = 0.9143\n",
      "Epoch  19 | train L1 = 1.0200\n",
      "              |  val L1 = 0.9008\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss.item())\n",
    "\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without hierachel scalar head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.2519\n",
      "              |  val L1 = 1.1477\n",
      "Epoch   1 | train L1 = 1.1990\n",
      "              |  val L1 = 1.1280\n",
      "Epoch   2 | train L1 = 1.1771\n",
      "              |  val L1 = 1.0822\n",
      "Epoch   3 | train L1 = 1.1462\n",
      "              |  val L1 = 1.0380\n",
      "Epoch   4 | train L1 = 1.1211\n",
      "              |  val L1 = 1.0375\n",
      "Epoch   5 | train L1 = 1.1137\n",
      "              |  val L1 = 0.9962\n",
      "Epoch   6 | train L1 = 1.1062\n",
      "              |  val L1 = 0.9722\n",
      "Epoch   7 | train L1 = 1.0921\n",
      "              |  val L1 = 0.9721\n",
      "Epoch   8 | train L1 = 1.1130\n",
      "              |  val L1 = 1.0192\n",
      "Epoch   9 | train L1 = 1.1127\n",
      "              |  val L1 = 1.0457\n",
      "Epoch  10 | train L1 = 1.1440\n",
      "              |  val L1 = 1.0814\n",
      "Epoch  11 | train L1 = 1.1231\n",
      "              |  val L1 = 1.0645\n",
      "Epoch  12 | train L1 = 1.1170\n",
      "              |  val L1 = 1.0472\n",
      "Epoch  13 | train L1 = 1.1218\n",
      "              |  val L1 = 0.9962\n",
      "Epoch  14 | train L1 = 1.0872\n",
      "              |  val L1 = 0.9940\n",
      "Epoch  15 | train L1 = 1.0818\n",
      "              |  val L1 = 0.9883\n",
      "Epoch  16 | train L1 = 1.0901\n",
      "              |  val L1 = 0.9926\n",
      "Epoch  17 | train L1 = 1.0509\n",
      "              |  val L1 = 0.9817\n",
      "Epoch  18 | train L1 = 1.0387\n",
      "              |  val L1 = 0.9998\n",
      "Epoch  19 | train L1 = 1.0585\n",
      "              |  val L1 = 0.9905\n",
      "Epoch  20 | train L1 = 1.0595\n",
      "              |  val L1 = 0.9648\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 15\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=256\n",
    "num_global_tokens=256\n",
    "dropout=0.02\n",
    "cutoff=10.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "all_paths = glob.glob(\"../inputs/*.npz\")\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "epochs = 21  # or whatever you like\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1)       # (R, dim+basis, N)\n",
    "\n",
    "    tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        #preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            #preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss.item())\n",
    "\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin2=nn.Linear(1,1)\n",
    "lin2(preds)[99].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 15])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dim = num neighbors\n",
    "protein_egnn=EGNN(dim=15,update_coors=False,num_nearest_neighbors=8)\n",
    "protein_egnn(preds.permute(2,0,1),centroids)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without mha (didnt adjust optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | train L1 = 1.2283\n",
      "              |  val L1 = 1.1830\n",
      "Epoch   1 | train L1 = 1.2138\n",
      "              |  val L1 = 1.1819\n",
      "Epoch   2 | train L1 = 1.2122\n",
      "              |  val L1 = 1.1786\n",
      "Epoch   3 | train L1 = 1.2105\n",
      "              |  val L1 = 1.1794\n",
      "Epoch   4 | train L1 = 1.2093\n",
      "              |  val L1 = 1.1796\n",
      "Epoch   5 | train L1 = 1.2098\n",
      "              |  val L1 = 1.1783\n",
      "Epoch   6 | train L1 = 1.2084\n",
      "              |  val L1 = 1.1809\n",
      "Epoch   7 | train L1 = 1.2054\n",
      "              |  val L1 = 1.1781\n",
      "Epoch   8 | train L1 = 1.2051\n",
      "              |  val L1 = 1.1759\n",
      "Epoch   9 | train L1 = 1.2057\n",
      "              |  val L1 = 1.1783\n",
      "Epoch  10 | train L1 = 1.2049\n",
      "              |  val L1 = 1.1760\n",
      "Epoch  11 | train L1 = 1.2064\n",
      "              |  val L1 = 1.1768\n",
      "Epoch  12 | train L1 = 1.2023\n",
      "              |  val L1 = 1.1829\n",
      "Epoch  13 | train L1 = 1.2012\n",
      "              |  val L1 = 1.1749\n",
      "Epoch  14 | train L1 = 1.2035\n",
      "              |  val L1 = 1.1781\n",
      "Epoch  15 | train L1 = 1.1996\n",
      "              |  val L1 = 1.1752\n",
      "Epoch  16 | train L1 = 1.1990\n",
      "              |  val L1 = 1.1802\n",
      "Epoch  17 | train L1 = 1.1999\n",
      "              |  val L1 = 1.1833\n",
      "Epoch  18 | train L1 = 1.1958\n",
      "              |  val L1 = 1.1807\n",
      "Epoch  19 | train L1 = 1.2019\n",
      "              |  val L1 = 1.1791\n",
      "Epoch  20 | train L1 = 1.1970\n",
      "              |  val L1 = 1.1781\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "from architecture import *\n",
    "import torch\n",
    "import glob, math, time, datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from egnn_pytorch import EGNN_Network\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "# 0) start timer\n",
    "t0 = time.time()\n",
    "N_NEIGHBORS = 15\n",
    "BATCH_SIZE  =  1           # now safe to increase\n",
    "PIN_MEMORY  = torch.cuda.is_available()\n",
    "# reproducibility + device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# decide AMP only on GP0\n",
    "use_amp = (device.type == \"cuda\")\n",
    "if use_amp:\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    class DummyCM:\n",
    "        def __enter__(self): pass\n",
    "        def __exit__(self, *args): pass\n",
    "    autocast = DummyCM\n",
    "    scaler   = None\n",
    "\n",
    "def init_model(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout):\n",
    "    \n",
    "    def build_egnn(dim,depth,hidden_dim,num_neighbors, num_edge_tokens,num_global_tokens,dropout):\n",
    "        return StackedEGNN(\n",
    "            dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            num_positions=1000, num_tokens=118,\n",
    "            num_nearest_neighbors=num_neighbors,\n",
    "            norm_coors=True,\n",
    "            num_edge_tokens=num_edge_tokens,\n",
    "            num_global_tokens=num_global_tokens\n",
    "        )\n",
    "    net   = build_egnn(dim,depth,hidden_dim,num_neighbors,num_edge_tokens,num_global_tokens,dropout).to(device)\n",
    "    mha   = AttentionBlock(embed_dim=dim+basis, num_heads=num_heads, hidden_dim=hidden_dim).to(device)\n",
    "    RBF   = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device) \n",
    "    return net, mha, RBF\n",
    "#net,mha,RBF=init_model\n",
    "# 3) instantiate everything\n",
    "dim, basis = 2, 8 #scale to 3,16 at least # dim must be divisible by 2\n",
    "depth=2 #scale to 2, at least\n",
    "hidden_dim=3\n",
    "num_heads=dim + basis \n",
    "num_edge_tokens=256\n",
    "num_global_tokens=256\n",
    "dropout=0.02\n",
    "cutoff=10.0\n",
    "num_neighbors=2\n",
    "\n",
    "\n",
    "runid=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, torch, glob\n",
    "\n",
    "class InMemoryHoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads *.npz files, constructs fixed-size neighbourhoods around each\n",
    "    site (anchor) and stores the result entirely in RAM.\n",
    "\n",
    "    For a protein with S sites the shapes are\n",
    "        z   : (S, N_NEIGHBORS)      int32\n",
    "        pos : (S, N_NEIGHBORS, 3)   float32\n",
    "        y   : (S,)                  float32\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, n_neighbors=N_NEIGHBORS, pin_memory=PIN_MEMORY):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"brute\")\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                dat = np.load(p, allow_pickle=True)\n",
    "                z_all   = dat[\"z\"].astype(np.int32)        # (N,)\n",
    "                pos_all = dat[\"pos\"].astype(np.float32)    # (N,3)\n",
    "                sites   = dat[\"sites\"].astype(np.float32)  # (S,3)\n",
    "                y       = dat[\"pks\"].astype(np.float32)    # (S,)\n",
    "\n",
    "                if len(sites) == 0:\n",
    "                    continue  # skip empty entries\n",
    "\n",
    "                nbrs.fit(pos_all)\n",
    "                idx = nbrs.kneighbors(sites, return_distance=False)   # (S, N_NEIGHBORS)\n",
    "\n",
    "                z_hood   = torch.from_numpy(z_all[idx])            # (S,N_NEIGHBORS)\n",
    "                pos_hood = torch.from_numpy(pos_all[idx])          # (S,N_NEIGHBORS,3)\n",
    "                y        = torch.from_numpy(y)                     # (S,)\n",
    "\n",
    "                if pin_memory:\n",
    "                    z_hood   = z_hood.pin_memory()\n",
    "                    pos_hood = pos_hood.pin_memory()\n",
    "                    y        = y.pin_memory()\n",
    "\n",
    "                self.data.append((z_hood, pos_hood, y))\n",
    "            except Exception as e:\n",
    "                print(f\"skipping {p}: {e}\")\n",
    "\n",
    "    def __len__(self):             return len(self.data)\n",
    "    def __getitem__(self, idx):    return self.data[idx]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) collate function  -------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads the variable-length site dimension so the batch can be stacked\n",
    "    into one tensor.  A boolean mask keeps track of which elements are\n",
    "    real data (True) vs. padding (False).\n",
    "    \"\"\"\n",
    "    # batch = list[(z,pos,y), ...]         len = B\n",
    "    B               = len(batch)\n",
    "    S_max           = max(item[0].shape[0] for item in batch)   # longest protein\n",
    "    device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    zs   = torch.zeros (B, S_max, N_NEIGHBORS ,   dtype=torch.int32 , device=device)\n",
    "    pos  = torch.zeros (B, S_max, N_NEIGHBORS ,3, dtype=torch.float32, device=device)\n",
    "    ys   = torch.full  ((B, S_max),  float(\"nan\"), dtype=torch.float32, device=device)\n",
    "    #ys   = torch.full  (B, S_max,               float(\"nan\"),        dtype=torch.float32, device=device)\n",
    "    mask = torch.zeros (B, S_max,                                   dtype=torch.bool,     device=device)\n",
    "\n",
    "    for b,(z,pos_b,y) in enumerate(batch):\n",
    "        S = z.shape[0]\n",
    "        zs  [b, :S] = z.to(device)\n",
    "        pos [b, :S] = pos_b.to(device)\n",
    "        ys  [b, :S] = y.to(device)\n",
    "        mask[b, :S] = True\n",
    "\n",
    "    return zs, pos, ys, mask             # shapes – see above\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 0) parameters you might want to expose at the top of the script\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 3) data loaders ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "all_paths = glob.glob(\"../inputs/*.npz\")\n",
    "np.random.shuffle(all_paths)\n",
    "train_paths, val_paths = all_paths[:20], all_paths[20:30]\n",
    "\n",
    "train_ds = InMemoryHoodDataset(train_paths)\n",
    "val_ds   = InMemoryHoodDataset(val_paths)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds  , batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=pad_collate,\n",
    "                          num_workers=0, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) model pieces ------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "egnn_net = StackedEGNN(dim=dim, depth=depth, hidden_dim=hidden_dim,\n",
    "                       dropout=dropout, num_positions=1000, num_tokens=118,\n",
    "                       num_nearest_neighbors=num_neighbors,\n",
    "                       norm_coors=True,\n",
    "                       num_edge_tokens=num_edge_tokens,\n",
    "                       num_global_tokens=num_global_tokens).to(device)\n",
    "\n",
    "rbf_layer = LearnableRBF(num_basis=basis, cutoff=cutoff).to(device)\n",
    "mha_layer = AttentionBlock(embed_dim=dim + basis,\n",
    "                           num_heads=num_heads,\n",
    "                           hidden_dim=hidden_dim).to(device)\n",
    "pred_head = nn.Linear(dim + basis, 1).to(device)\n",
    "\n",
    "protein_egnn=EGNN(dim=1,update_coors=False,num_nearest_neighbors=8)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(egnn_net.parameters()) +\n",
    "    list(rbf_layer.parameters()) +\n",
    "    list(mha_layer.parameters()) +\n",
    "    list(pred_head.parameters()) +\n",
    "    list(protein_egnn.parameters()),\n",
    "    lr=5e-3\n",
    ")\n",
    "\n",
    "epochs = 21  # or whatever you like\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) forward for a *compressed* batch (R residues, N neighbours)\n",
    "# ---------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) single-path forward – no shape guessing, no branching\n",
    "# ---------------------------------------------------------------------\n",
    "def forward_residues(z_r, x_r):\n",
    "    \"\"\"\n",
    "    z_r : (R, N)       int32   – atomic numbers for R residues\n",
    "    x_r : (R, N, 3)    float32 – coordinates\n",
    "    returns (R, dim + basis)   – per-residue embeddings\n",
    "    \"\"\"\n",
    "    # ---------- EGNN ----------\n",
    "    h_out, coords = egnn_net(z_r, x_r)          # h_out is [tensor] or tensor\n",
    "    h = h_out[0] if isinstance(h_out, (list, tuple)) else h_out   # (R, N, dim)\n",
    "\n",
    "    # ---------- RBF on *input* coords (already (R,N,3)) ----------\n",
    "    #d   = torch.cdist(x_r, x_r)            # (R, N, N)\n",
    "    rbf = rbf_layer(coords)                     # (R, N, N, basis)\n",
    "\n",
    "    # ---------- concat & attention ----------\n",
    "    h0  = h.transpose(1, 2)                # (R, dim,   N)\n",
    "    r0  = rbf[:, 0].transpose(1, 2)        # (R, basis, N)\n",
    "    tok = torch.cat((r0, h0), dim=1).permute(2,0,1)      # (R, dim+basis, N)\n",
    "\n",
    "    #tok, _ = mha_layer(tok.permute(2, 0, 1))   # (N, R, C) → attn(+PE)\n",
    "    tok    = tok.permute(1, 0, 2).max(dim=1).values   # (R, C) max over neighbours\n",
    "    return tok,     coords.mean(dim=1).unsqueeze(0)                               # (R, dim + basis)\n",
    "                                         # (R, dim+basis)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) training / validation loop ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "for epoch in range(epochs):\n",
    "    # ======== TRAIN ========\n",
    "    egnn_net.train(); rbf_layer.train(); mha_layer.train(); pred_head.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    for z, x, y, mask in train_loader:                 # z:(B,S,N)  mask:(B,S)\n",
    "        # compress away padding →  (R, N), (R, N, 3), (R,)\n",
    "        valid      = mask.view(-1)\n",
    "        z_res      = z.view(-1, z.size(2))[valid].to(device)\n",
    "        x_res      = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "        y_res      = y.view(-1)[valid].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model\n",
    "        feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "        \n",
    "        preds = pred_head(feats)       \n",
    "        t=preds.unsqueeze(0)\n",
    "        preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "        loss  = criterion(preds.flatten(), y_res)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train L1 = {np.mean(tr_losses):.4f}\")\n",
    "\n",
    "    \n",
    "    # ======== VALID ========\n",
    "    egnn_net.eval(); rbf_layer.eval(); mha_layer.eval(); pred_head.eval()\n",
    "    vl_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for z, x, y, mask in val_loader:\n",
    "            valid   = mask.view(-1)\n",
    "            z_res   = z.view(-1, z.size(2))[valid].to(device)\n",
    "            x_res   = x.view(-1, x.size(2), 3)[valid].to(device)\n",
    "            y_res   = y.view(-1)[valid].to(device)\n",
    "\n",
    "                #model\n",
    "            feats, centroids = forward_residues(z_res, x_res)         # (R, C)\n",
    "            \n",
    "            preds = pred_head(feats)       \n",
    "            t=preds.unsqueeze(0)\n",
    "            preds=protein_egnn(t,centroids)[0]\n",
    "\n",
    "            loss  = criterion(preds.flatten(), y_res)\n",
    "            vl_losses.append(loss.item())\n",
    "\n",
    "    print(f\"              |  val L1 = {np.mean(vl_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
