
Short answer:
DeepKa still carries the most “street-cred” among academic pK<sub>a</sub> specialists because it was the first ML model to beat PROPKA and its architecture is fully published and audited. pKAI+ is the workhorse many pharma groups deploy for rapid, large-scale scans because it is tiny (~80 k parameters) and has a one-line CLI. pKALM is gathering attention for showing that sequence-only PLMs can reach structure-based accuracy, but it has not yet been stress-tested in a blind challenge. AEV/ANI is respected in the quantum-chemistry community for its rigorous featurisation, yet it sees less day-to-day use in classical protein-pH pipelines.
How to choose

    Need raw speed across hundreds of proteins? → pKAI+ (milliseconds, CPU).

    Want a peer-reviewed method with the best track-record on buried sites? → DeepKa.

    Working in sequence space (no coordinates) or on low-resolution models? → keep an eye on pKALM.

    Coupling with QM/ANI workflows or per-atom property prediction? → AEV/ANI.

If you’d like a deeper dive into any of these (e.g., training data provenance, licensing, GPU memory footprints), just let me know.

Physics-heavy CpH-MD is now the accuracy leader on carefully chosen systems, but it is compute-intensive and its edge narrows on bigger, flexible proteins.

Modern ML models (DeepKa, pKAI+, pKALM, AEV/ANI) run orders-of-magnitude faster and already sit around 0.45 – 0.55 MAE on broad, public test sets—roughly matching continuum electrostatics while handling thousands of residues in seconds.

Minimal “bulletproof” workflow (practical recipe)

Step 0 – Curate sites. Collapse duplicate experimental pKₐ entries for the same residue/protein state; keep metadata (pH method, mutants).
arXiv
Nature

Step 1 – Sequence clustering. Cluster all protein chains at a conservative global identity cutoff (e.g., 25–30%) using an alignment- or sketch-based tool (SpanSeq, MMseqs family). Assign cluster IDs.
arXiv
PubMed

Step 2 – Structure clustering (optional but stronger). Use Foldseek (fast 3D alphabet alignment) to merge clusters that are structurally homologous despite low sequence identity.
Nature
arXiv

Step 3 – Merge metadata families. Union clusters for engineered variants, ligand-bound vs. apo forms, and multi-pH structures so no related environment leaks across folds. Guidance on central-node removal helps when everything connects.
OpenReview
Nature

Step 4 – Partition whole clusters to folds (train/val/test) using load-balancing optimization (DataSAIL) so residue counts and class balance remain reasonable.
Nature
arXiv

Step 5 – Publish similarity diagnostics (max identity train↔test; distribution plots) and stick to them; Kramer et al. demonstrated dramatic metric drops when moving from random to leave-cluster-out validation—proof this matters.
PubMed

Putting it together for pKₐ projects

A practical compromise many groups use:

    Cluster by ≤25% seq ID (ProteinNet precedent) to limit easy homology transfer.
    GitHub
    PubMed

    Manually merge known homologs missed by the cutoff using a rapid structure search (Foldseek).
    Nature

    Assign all titratable residues from a protein (and its close variants) to the same fold. Prevents site-level leakage where the model just memorizes that protein’s environment. Empirically recommended in leakage-avoidance studies (DataSAIL, SpanSeq).
    Nature
    arXiv

    Hold out an entire structural class (e.g., all β-propellers) if you want an extreme OOD challenge; removing central nodes first can make such splits feasible.
    OpenReview
    Nature

If you need numbers for a “Methods” table

When you report runtime, give something like:

    Runtime benchmark. All timings on 1×NVIDIA A100 + 8 CPU cores. Average wall time (n=50 proteins, median 275 residues):

        Feature build: 1.8 ± 0.3 s/protein

        Model inference: 0.02 s/protein

        Total: 1.82 s/protein

This style mirrors how fast ML pKₐ tools (DeepKa lineage; PROPKA) are described (“seconds per protein”) and how server papers report size-dependent timings (H++; PypKa).
PMC
newbiophysics.cs.vt.edu
PMC
Want help designing your split or timing harness?

If you share: (a) dataset size (#proteins, #titratable sites), (b) whether you have structures, (c) hardware, I can draft a script + recommended thresholds. Let me know!

Sources
(ordered roughly by topic relevance)

    Huang et al. “Protein pKa Prediction with Machine Learning” (DeepKa vs. PROPKA; seconds per protein).
    PMC

    H++ FAQ with size-dependent runtimes (~18 s / 12 sites; ~5 min / 111 sites).
    newbiophysics.cs.vt.edu

    Shen et al. GPU Continuous CpHMD in Amber (rapid 2-ns single-pH sims for pKₐ prediction; illustrates heavier compute class).
    PMC

    Joeres et al. DataSAIL (leakage-reduced biological data splitting; optimization to balance folds).
    Nature

    Florensa et al. SpanSeq (similarity-based partitioning to avoid leakage in biological sequence ML).
    arXiv

    Kramer & Gedeck “Leave-cluster-out cross-validation…” (showing inflated metrics without cluster-aware splits).
    PubMed

    Rochereau et al. “Disconnecting The Dots” (remove central nodes to enable extreme OOD leakage-free protein splits).
    OpenReview

    Foldseek (fast structure comparison for redundancy removal / clustering).
    Nature

    PROPKA GitHub (lightweight empirical predictor; typical interactive speeds).
    GitHub

    PypKa server (physics + ML, scalable to larger systems; supports batch and feature reuse).
    PMC

!oldseek easy-cluster pdbs/ out tmp --max-seq-id 0.3 --cov-mode 1 -c 0.8
import pandas as pd, random, pathlib

df = pd.read_csv('clusters.tsv', sep='\t', names=['rep', 'member'])
cluster_of = dict(zip(df.member, df.rep))

members = list(cluster_of.keys())
random.shuffle(members)

folds = {0: [], 1: [], 2: []}   # 3-way split
for m in members:
    folds[len(cluster_of[m]) % 3].append(m)   # trivial balance

# now folds[0], folds[1], folds[2] are leakage-free lists
