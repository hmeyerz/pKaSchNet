{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "def read_database(path):\n",
    "    \"\"\"csv --> dask df\"\"\"\n",
    "    #make the dask data frame from the PYPKA csv\n",
    "    dk=dd.read_csv(path, delimiter=';', na_filter=False, dtype={'idcode':'category', \n",
    "                                                                    'residue_number':'uint8',\n",
    "                                                                    'pk': 'float32',\n",
    "                                                                    'residue_name':'category',\n",
    "                                                                    'chain': 'category'\n",
    "                                                                    })\n",
    "                                                            \n",
    "    dk=dk.rename(columns={'idcode': 'PDB ID', 'residue_number': 'Res ID', 'residue_name': 'Res Name', 'residue_number': 'Res ID', 'pk': 'pKa', 'chain' : 'Chain'}) #rename columns to match df from pkad \n",
    "    dk=dk.sort_values(['PDB ID', 'Res ID'], ascending=[True, True]) \n",
    "    dk=dk.compute() \n",
    "    #dff = dk.reset_index() \n",
    "\n",
    "    return dk.reset_index()\n",
    "\n",
    "dask_df = read_database(\"/Users/jessihoernschemeyer/pKaSchNet/pkas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_df = dask_df[dask_df.iloc[:, 1] == '199l'].drop(columns = [\"PDB ID\"])\n",
    "pdb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
