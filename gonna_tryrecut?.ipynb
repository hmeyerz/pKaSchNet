{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"\"\"\n",
    "   _____      __    _   __     __  .____ \n",
    "  / ___/_____/ /_  / | / /__  / /_./ __ \\/ /__   ____ \n",
    "  \\__ \\/ ___/ __ \\/  |/ / _ \\/ __./ /_/ / //_/ / __  / \n",
    " ___/ / /__/ / / / /|  /  __/ /_./ ____/  <   | /_/  \\\n",
    "/____/\\___/_/ /_/_/ |_/\\___/\\__./_/   /_/|_|  \\__,_/\\_\\   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problems: put TER first / last. when changing the names of things to titrate\n",
    "\n",
    "to do: disordered flag in file save\n",
    "\n",
    "are you even using residue names and coordA/B. Also fix how im using centers\n",
    "\n",
    "\n",
    "can feed the resnumber straight instead of whole residue object\n",
    "\n",
    "todo integrate pKa value\n",
    "\n",
    "todo \n",
    "-HIS \n",
    "-indicate atom of disordered atom\n",
    "-get the coordinate info for terminus.. N?\n",
    "    -get the coord from pypka i guess, in the whole pdb\n",
    "    -{pypka res number / chain : coord}\n",
    "    -{coord : amber res number}\n",
    "    look for coords in pdb... \n",
    "    -{0: (amber residue numbers), 1: (amber residue numbers)} #ntr\n",
    "\n",
    "reconsider not allowing TER-TER cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure exists: 'PDB/pdb199l.ent' \n",
      "{'199lA1': <Residue MET het=  resseq=1 icode= >, '199lA5': <Residue GLU het=  resseq=5 icode= >, '199lA10': <Residue ASP het=  resseq=10 icode= >, '199lA11': <Residue GLU het=  resseq=11 icode= >, '199lA16': <Residue LYS het=  resseq=16 icode= >, '199lA18': <Residue TYR het=  resseq=18 icode= >, '199lA19': <Residue LYS het=  resseq=19 icode= >, '199lA20': <Residue ASP het=  resseq=20 icode= >, '199lA22': <Residue GLU het=  resseq=22 icode= >, '199lA24': <Residue TYR het=  resseq=24 icode= >, '199lA25': <Residue TYR het=  resseq=25 icode= >, '199lA31': <Residue HIS het=  resseq=31 icode= >, '199lA35': <Residue LYS het=  resseq=35 icode= >, '199lA43': <Residue LYS het=  resseq=43 icode= >, '199lA45': <Residue GLU het=  resseq=45 icode= >, '199lA47': <Residue ASP het=  resseq=47 icode= >, '199lA48': <Residue LYS het=  resseq=48 icode= >, '199lA60': <Residue LYS het=  resseq=60 icode= >, '199lA61': <Residue ASP het=  resseq=61 icode= >, '199lA62': <Residue GLU het=  resseq=62 icode= >, '199lA64': <Residue GLU het=  resseq=64 icode= >, '199lA65': <Residue LYS het=  resseq=65 icode= >, '199lA70': <Residue ASP het=  resseq=70 icode= >, '199lA72': <Residue ASP het=  resseq=72 icode= >, '199lA83': <Residue LYS het=  resseq=83 icode= >, '199lA85': <Residue LYS het=  resseq=85 icode= >, '199lA88': <Residue TYR het=  resseq=88 icode= >, '199lA89': <Residue ASP het=  resseq=89 icode= >, '199lA92': <Residue ASP het=  resseq=92 icode= >, '199lA108': <Residue GLU het=  resseq=108 icode= >, '199lA124': <Residue LYS het=  resseq=124 icode= >, '199lA127': <Residue ASP het=  resseq=127 icode= >, '199lA128': <Residue GLU het=  resseq=128 icode= >, '199lA135': <Residue LYS het=  resseq=135 icode= >, '199lA139': <Residue TYR het=  resseq=139 icode= >, '199lA147': <Residue LYS het=  resseq=147 icode= >, '199lA159': <Residue ASP het=  resseq=159 icode= >, '199lA161': <Residue TYR het=  resseq=161 icode= >, '199lA162': <Residue LYS het=  resseq=162 icode= >}\n",
      "1 1\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 ter\n",
      "NMET resname\n",
      "5 5\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "5 5\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 1\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 ter\n",
      "NMET resname\n",
      "5 5\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "5 5\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 1\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 ter\n",
      "NMET resname\n",
      "1 1\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 ter\n",
      "NMET resname\n",
      "5 5\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 1\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 ter\n",
      "NMET resname\n",
      "1 1\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 ter\n",
      "NMET resname\n",
      "1 1\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 ter\n",
      "NMET resname\n",
      "1 1\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "1 ter\n",
      "NMET resname\n",
      "5 5\n",
      "A ['A', 'A'] [1, 5]\n",
      "1 IF ter\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/prep to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd to search path.\n",
      "-s: Ignoring all leaprc startup files.\n",
      "-f: Source /Users/jessihoernschemeyer/pKaSchNet/ascript.py.\n",
      "\n",
      "Welcome to LEaP!\n",
      "Sourcing: /Users/jessihoernschemeyer/pKaSchNet/ascript.py\n",
      "----- Source: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.protein.ff14SB\n",
      "----- Source of /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.protein.ff14SB done\n",
      "Log file: ./leap.log\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/parm10.dat\n",
      "Reading title:\n",
      "PARM99 + frcmod.ff99SB + frcmod.parmbsc0 + OL3 for RNA\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ff14SB\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "ff14SB protein backbone and sidechain parameters\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino12.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/aminoct12.lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jl/8mbcps0x1jv9616svy8_9vy80000gn/T/ipykernel_13825/2995027828.py:283: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  closest_cutout_i = int(np.where((distances[int(index), :])==a_residues_distance_array[0])[0])\n",
      "/var/folders/jl/8mbcps0x1jv9616svy8_9vy80000gn/T/ipykernel_13825/2995027828.py:290: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  closest_cutout_i = int(np.where((distances[int(index), :])==a_residues_distance_array[1])[0]) #next closest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/aminont12.lib\n",
      "----- Source: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.water.tip3p\n",
      "----- Source of /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.water.tip3p done\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/atomic_ions.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/solvents.lib\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "This is the additional/replacement parameter set for TIP3P water\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ions1lm_126_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Li/Merz ion parameters of monovalent ions for TIP3P water model (12-6 normal usage set)\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ionsjc_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Monovalent ion parameters for Ewald and TIP3P water from Joung & Cheatham JPCB (2008)\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ions234lm_126_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Li/Merz ion parameters of divalent to tetravalent ions for TIP3P water model (12-6 normal usage set)\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\n",
      "Loading PDB file: /Users/jessihoernschemeyer/pKaSchNet/cuts/199lA1_N0-MET_199lA5_G1_NG-N44.195.pdb\n",
      " (starting new molecule for chain A)\n",
      "Created a new atom named: SD within residue: .R<NME 0>\n",
      "Created a new atom named: O within residue: .R<NME 0>\n",
      "Created a new atom named: CG within residue: .R<NME 0>\n",
      "Created a new atom named: CA within residue: .R<NME 0>\n",
      "Created a new atom named: CB within residue: .R<NME 0>\n",
      "Created a new atom named: CE within residue: .R<NME 0>\n",
      "  Added missing heavy atom: .R<NASN 1>.A<CB 7>\n",
      "  Added missing heavy atom: .R<NASN 1>.A<C 15>\n",
      "  Added missing heavy atom: .R<NASN 1>.A<O 16>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<N 1>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<CA 3>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<CB 5>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<C 23>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<CG 8>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<O 24>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<CD2 22>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<CE2 13>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<CE3 20>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<CZ2 14>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<CZ3 18>\n",
      "  Added missing heavy atom: .R<TRP 2>.A<CH2 16>\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      "One sided connection. Residue (TP3) missing connect0 atom.\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      "One sided connection. Residue (default_name) missing connect1 atom.\n",
      "  Added missing heavy atom: .R<GLU 4>.A<N 1>\n",
      "  Added missing heavy atom: .R<GLU 4>.A<C 14>\n",
      "  Added missing heavy atom: .R<GLU 4>.A<O 15>\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      "One sided connection. Residue (TP3) missing connect0 atom.\n",
      "  total atoms in file: 25\n",
      "  Leap added 54 missing atoms according to residue templates:\n",
      "       18 Heavy\n",
      "       36 H / lone pairs\n",
      "  The file contained 6 atoms not in residue templates\n",
      "Writing pdb file: /Users/jessihoernschemeyer/pKaSchNet/prot/199lA1_N0-MET_199lA5_G1_NG-N44.195\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      " Converting N-terminal residue name to PDB format: NASN -> ASN\n",
      "\tQuit\n",
      "\n",
      "Exiting LEaP: Errors = 0; Warnings = 4; Notes = 0.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'recut_deprotonate_save_ter_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 749\u001b[0m\n\u001b[1;32m    744\u001b[0m                 deprot_save_solo_ter(info, center, distance_cutoff)  \u001b[39m#TODO\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39m#dask_df = read_database(pkPDB_CSV)\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39m#pdbs = list(OrderedSet(list(dask_df[\"PDB ID\"])))\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m fs, cs, rs \u001b[39m=\u001b[39m get_cutout(dask_df, \u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[40], line 455\u001b[0m, in \u001b[0;36mget_cutout\u001b[0;34m(dask_df, distance_cutoff)\u001b[0m\n\u001b[1;32m    452\u001b[0m         atoms_to_structure(cut[\u001b[39m0\u001b[39m], key, Fname, site_dict[friend_f\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]])\n\u001b[1;32m    454\u001b[0m     \u001b[39m#info = ((f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)) #coords of CA ##?\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     save_amber_chainify_recut_deprotonate(Fname, (site_dict[f[\u001b[39m0\u001b[39;49m]][\u001b[39m'\u001b[39;49m\u001b[39mCA\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mget_coord() \u001b[39mfor\u001b[39;49;00m f \u001b[39min\u001b[39;49;00m (f1, f2)), cut[\u001b[39m2\u001b[39;49m], key, \u001b[39m0\u001b[39;49m, distance_cutoff)\n\u001b[1;32m    456\u001b[0m     \u001b[39m#save_amber_chainify_recut_deprotonate([(f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)], cut[2], key, 0, distance_cutoff)\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \n\u001b[1;32m    458\u001b[0m \n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m#solo, noemal\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39m#centers_apdb.append(cut[1])\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     newfnames\u001b[39m.\u001b[39mappend(fname)\n",
      "Cell \u001b[0;32mIn[40], line 734\u001b[0m, in \u001b[0;36msave_amber_chainify_recut_deprotonate\u001b[0;34m(f, coords, center, key, flag, distance_cutoff)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39m#ter merged\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[39melif\u001b[39;00m flag\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m--> 734\u001b[0m     recut_deprotonate_save_ter_merged(info, center, distance_cutoff)\n\u001b[1;32m    737\u001b[0m \u001b[39m#solo\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39m#none flag\u001b[39;00m\n\u001b[1;32m    740\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m: \u001b[39m#solo, noemal\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recut_deprotonate_save_ter_merged' is not defined"
     ]
    }
   ],
   "source": [
    "from Bio.PDB import *\n",
    "from Bio import PDB\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from ase import Atoms, Atom\n",
    "import dask.dataframe as dd\n",
    "from ordered_set import OrderedSet\n",
    "import os\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import chain, product\n",
    "import sys\n",
    "import string\n",
    "\n",
    "char_list = (string.ascii_uppercase)\n",
    "protonatable_sites2 = {\"G\":\"GLH\", \n",
    "                      \"C\":\"CYS\", \n",
    "                      \"L\":\"LYS\", \n",
    "                      \"A\":\"ASH\",\n",
    "                      \"H\": \"HIP\",\n",
    "                      \"T\": \"TYR\",\n",
    "                      \"X\": \"CTR\",\n",
    "                      \"N\": \"NTR\"}\n",
    "protonatable_Hsites = {\"G\":\"HE2\", \n",
    "                      \"C\":\"HG\", \n",
    "                      \"L\":\"HZ1\", \n",
    "                      \"A\":\"HD2\",\n",
    "                      \"H\": (\"HD1\",\"HE2\"), #this needs to be fixed \n",
    "                      \"T\": \"HH\"}\n",
    "\n",
    "protonatable_sites = {\"G\":(\"OE1\",\"OE2\"), \"A\":(\"OD1\",\"OD2\"), \"C\":\"SG\", \"L\":\"NZ\", \"H\":(\"NE2\", \"ND1\"), \"T\":\"OH\"}\n",
    "\n",
    "protonatable_sites3 = {\"GLU\":\"GLH\", \n",
    "                      \"ASP\":\"ASH\",\n",
    "                      \"HIS\": \"HIP\"}\n",
    "#pdb_parser=PDB.PDBParser()\n",
    "local_folder=\"/Users/jessihoernschemeyer/pKaSchNet\"\n",
    "pkPDB_CSV = f\"{local_folder}/pkas.csv\"\n",
    "\n",
    "def read_database(path):\n",
    "    \"\"\"csv --> dask df\"\"\"\n",
    "    #make the dask data frame from the PYPKA csv\n",
    "    dk=dd.read_csv(path, delimiter=';', na_filter=False, dtype={'idcode':'category', \n",
    "                                                                    'residue_number':'uint8',\n",
    "                                                                    'pk': 'float32',\n",
    "                                                                    'residue_name':'category',\n",
    "                                                                    'chain': 'category'\n",
    "                                                                    })\n",
    "                                                            \n",
    "    dk=dk.rename(columns={'idcode': 'PDB ID', 'residue_number': 'Res ID', 'residue_name': 'Res Name', 'residue_number': 'Res ID', 'pk': 'pKa', 'chain' : 'Chain'}) #rename columns to match df from pkad \n",
    "    dk=dk.sort_values(['PDB ID', 'Res ID'], ascending=[True, True]) \n",
    "    dk=dk.compute() \n",
    "    #dff = dk.reset_index() \n",
    "\n",
    "    return dk.reset_index()\n",
    "\n",
    "def check_atoms_protein(structure, struc_atoms): \n",
    "    \"\"\"checks every atom in the entire protein for metals, undesirables\"\"\"\n",
    "    pdb_residues=[]\n",
    "    for atom in struc_atoms: \n",
    "        papa = atom.get_parent()\n",
    "        resname, atomid=papa.get_resname(), atom.get_full_id()[2:]\n",
    "        element=atomid[2][0]\n",
    "\n",
    "        if element in [\"MG\", \"MN\", \"FE\", \"CO\", \"NI\", \"CU\", \"ZN\"]:\n",
    "            return None\n",
    "        \n",
    "        elif atomid[1][0] not in [' ']:\n",
    "            if element == 'S': #hetero sulfur\n",
    "                return None #skip pdb\n",
    "            \n",
    "            if element in ['CA', 'CL', 'K', 'NA']: #other salt\n",
    "                for res in structure.get_residues():\n",
    "                    if resname in [\"GLU\", \"HIS\", \"ASP\", \"ARG\", \"TYR\", \"CYS\", \"LYS\"]: \n",
    "                        if np.linalg.norm(res.center_of_mass(geometric=True) - atom.get_coord()) < 3:\n",
    "                            atom.get_parent().detach_child(atom.get_id())   #delete if <3Ã¥ from geometric center\n",
    "    \n",
    "    return structure\n",
    "\n",
    "def atoms_to_structure(cutout, key, filename, residue): \n",
    "    \"\"\"input: cutout [<atom>, <atom>]: list of biopython atom objects\n",
    "    first save, after merging and before protonation\n",
    "    \n",
    "    T_IDn = [108, 109]\"\"\"\n",
    "    #file name has the fname, which hs the resnumber and 199lA108_G29\n",
    "    tit_res_names, resname = None, None\n",
    "    chain_dict, res_dict = {}, {}\n",
    "\n",
    "    Tresid =filename.split(\"_\")\n",
    "    f1=Tresid[0][4:] #A108\n",
    "    T_IDn,T_IDc = [int(f1[1:])], [f1[0]] #108, A\n",
    "\n",
    "    if len(Tresid) > 3: #merged \n",
    "        f2 = Tresid[2][4:]\n",
    "        T_IDn.append(int(f2[1:]))\n",
    "        T_IDc.append(f2[0])\n",
    "\n",
    "    if residue != None: #TER\n",
    "        ter_res_id = residue.get_id()[1]\n",
    "        #print(\"TER\", TER)\n",
    "        #ter_res_id = TER[1][1]\n",
    "\n",
    "    \n",
    "    structure = Structure.Structure(\"\")\n",
    "    model = Model.Model(0)\n",
    "    structure.add(model)\n",
    "\n",
    "    for atom in cutout:\n",
    "        resname=None\n",
    "        res = atom.get_parent()\n",
    "        id = res.get_full_id()\n",
    "        res_id, chain_id = id[3], id[2]\n",
    "        resnumber = res_id[1]\n",
    "        #for chain, resnum in zip(Cter, Nter):\n",
    "        \n",
    "        if resnumber in T_IDn: #acidify #if 107 in [108, 109]\n",
    "            print(resnumber, resnumber)\n",
    "            if chain_id in T_IDc: #if A in [A,A]\n",
    "                print(chain_id, T_IDc, T_IDn)\n",
    "                if ter_res_id: #TER\n",
    "                    print(ter_res_id, \"IF ter\")\n",
    "                    if ter_res_id == resnumber:\n",
    "                        print(ter_res_id, \"ter\")\n",
    "                        if \"X\" in key:\n",
    "                            resname = \"X\" + res.get_resname()\n",
    "                            print(resname, \"resname\")\n",
    "                        else:\n",
    "                            resname = \"N\" + res.get_resname()\n",
    "                            print(resname, \"resname\")\n",
    "                \n",
    "                else: #ASP GLU or HIP\n",
    "                    resname = protonatable_sites3.get(res.get_resname())\n",
    "\n",
    "        if not resname: #bc ter etc arent in dic\n",
    "            resname = res.get_resname()\n",
    "       \n",
    "#make/retrieve chain\n",
    "        if chain_id not in chain_dict:\n",
    "            chain = Chain.Chain(chain_id) #make new chain\n",
    "            chain_dict[chain_id] = chain\n",
    "            model.add(chain) #add it\n",
    "\n",
    "        else:\n",
    "            chain = chain_dict[chain_id]\n",
    "        \n",
    "#make/retrieve residue\n",
    "        if res_id not in res_dict:\n",
    "            residue = Residue.Residue(res_id, resname, '')\n",
    "            res_dict[res_id] = residue\n",
    "            chain.add(residue) #add it\n",
    "        else:\n",
    "            residue = res_dict[res_id]\n",
    "\n",
    "        residue.add(atom)\n",
    "#save\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(f\"cuts/{filename}.pdb\")\n",
    "\n",
    "def _get_cut_AspGlu(residue, resname, counter, distance_cutoff, ns):\n",
    "    cuts=[]\n",
    "    sites=protonatable_sites[resname]\n",
    "    atom1,atom2=residue[sites[0]],residue[sites[1]]\n",
    "    if atom1.is_disordered(): \n",
    "        center, resname = atom1.get_coord(), resname + \",\"\n",
    "    elif atom2.is_disordered():\n",
    "        center, resname = atom2.get_coord(), resname + \",\"\n",
    "    else:\n",
    "        center=(atom1.get_coord() + atom2.get_coord()) / 2.0\n",
    "    cut = ns.search(center, distance_cutoff, \"A\") #put ns search i n below? todo\n",
    "    cuts.append((counter, center, resname, cut)) \n",
    "    return cuts\n",
    "\n",
    "def _get_cut_normal(residue, resname, counter, distance_cutoff, ns):\n",
    "    cuts=[]\n",
    "    site=residue[protonatable_sites[resname]]\n",
    "    if site.is_disordered(): \n",
    "        resname = resname + \",\"\n",
    "    center = site.get_coord()\n",
    "    cut = ns.search(center, distance_cutoff, \"A\")\n",
    "    cuts.append((counter, center, resname, cut))\n",
    "    return cuts\n",
    "   \n",
    "def generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter, resname):\n",
    "    \"\"\"Residue wise resolurion. ns is neighbor search set up for the entire protein, residue is the single data point / 1 of several residues in a pdb & in pypka.\n",
    "    input is one residue. output is the cutout around its titratable site, both of which can be plural e.g. his, mb asp and glu.\n",
    "    residue (biopython Residue object): a single protonable residue \"\"\"\n",
    "    protonatable_sites = {\"G\":(\"OE1\",\"OE2\"), \"A\":(\"OD1\",\"OD2\"), \"C\":\"SG\", \"L\":\"NZ\", \"H\":(\"NE2\", \"ND1\"), \"T\":\"OH\"} #TODO\n",
    "    cuts = []\n",
    "\n",
    "    if resname==0: #NTR\n",
    "        center = residue['N'].get_coord()\n",
    "        cut = ns.search(center, distance_cutoff, \"A\")\n",
    "        cuts.append((counter, center, 'N', (cut, residue))) \n",
    "        return cuts\n",
    "    \n",
    "    elif resname==1: #CTR\n",
    "        try:\n",
    "            center = residue['OXT'].get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, 'X', (cut, residue)))\n",
    "        except:\n",
    "            center = residue['C'].get_coord()\n",
    "        cut = ns.search(center, distance_cutoff, \"A\")\n",
    "        cuts.append((counter, center, 'X', (cut, residue)))\n",
    "        return cuts\n",
    "    \n",
    "    else:\n",
    "        if resname==\"G\": \n",
    "            return _get_cut_AspGlu(residue, resname, counter, distance_cutoff, ns)\n",
    "        if resname==\"A\": \n",
    "            return _get_cut_AspGlu(residue, resname, counter, distance_cutoff, ns)\n",
    "        if resname==\"C\": \n",
    "            return _get_cut_normal(residue, resname, counter, distance_cutoff, ns)\n",
    "        if resname==\"L\": \n",
    "            return _get_cut_normal(residue, resname, counter, distance_cutoff, ns)\n",
    "        if resname==\"T\":\n",
    "            return _get_cut_normal(residue, resname, counter, distance_cutoff, ns)\n",
    "        if resname==\"H\":\n",
    "            sites=protonatable_sites[resname]\n",
    "            atom1,atom2=residue[sites[0]],residue[sites[1]]            \n",
    "            if atom1.is_disordered(): \n",
    "                resname = resname + \",\"\n",
    "            if atom2.is_disordered():\n",
    "                resname = resname + \",\"\n",
    "            center1,center2=atom1.get_coord(), atom2.get_coord()\n",
    "            cut1, cut2 = ns.search(center1, distance_cutoff, \"A\"), ns.search(center2, distance_cutoff, \"A\")\n",
    "            cuts.append([(counter+.1, center1, resname, cut1),(counter+.2, center2, resname, cut2)])\n",
    "\n",
    "    return cuts #plural because of sites with multiple sites.\n",
    "\n",
    "def _get_merged_F(greaterN_pair_i, fname, fnames, site_dict, key):\n",
    "    \"returns Fname, alpha carbon coords\"\n",
    "    friend_f = fnames[greaterN_pair_i[0]]\n",
    "    f1, f2 = fname.split(\"_\"), friend_f.split(\"_\")\n",
    "    f1_0, f2_0 = f1[0], f2[0]\n",
    "    if f1_0==f2_0:\n",
    "        #double His\n",
    "        if f1_0==\"~\":\n",
    "            #doublehis\n",
    "        if f2_0==\"~\":\n",
    "\n",
    "    else:\n",
    "        if f1_0==\"~\":\n",
    "            HISMerged(key.strip(\"H\"))\n",
    "        elif f2_0==\"~\":\n",
    "            HISMerged(key.strip(\"H\"))\n",
    "\n",
    "    return \"\".join([fname,'_',friend_f,\"_\",key.strip(\",\")]), (site_dict[f[0]]['CA'].get_coord() for f in (f1, f2))\n",
    "    #Fname=\"\".join([fname,'_',friend_f,\"_\",cut[1].strip(\",\"),\"-\",a.get_name(), str(round(a.get_coord()[0],3))])\n",
    "\n",
    "def _find_terminus_residue(f, Tcoord):\n",
    "    \"\"\"\n",
    "    Extract residues from a PDB file, returning a list of tuples\n",
    "    with (residue name, original residue number).\n",
    "    \"\"\"\n",
    "    residues = []\n",
    "    with open(f, \"r\") as file:\n",
    "        for line in file:\n",
    "            if Tcoord in line:\n",
    "                return int(line[22:26].strip())\n",
    "\n",
    "def _ns(f):\n",
    "    \"\"\"per residue. \"\"\"\n",
    "    #f=info[0]\n",
    "    #pdbatoms = list(pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{f}').get_atoms())\n",
    "    return PDB.NeighborSearch(list(pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{f}').get_atoms()))\n",
    "\n",
    "    ns = PDB.NeighborSearch(list(pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{f}').get_atoms())) #set up ns , entire protein\n",
    "    #cut = ns.search(centerA[0], distance_cutoff, \"A\"), ns.search(centerB[1], distance_cutoff, \"A\")\n",
    "    return PDB.NeighborSearch(list(pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{f}').get_atoms()))\n",
    "    return f, info[1], info[2], ns #ns.search(centerA[0], distance_cutoff, \"A\"), ns.search(centerB[1], distance_cutoff, \"A\")\n",
    "    \n",
    "def amber(fname):\n",
    "    \"not TER. disables terminus patches, treating pdb as a fragment\"\n",
    "    #string = '{ { \"NMET\" \"NMET\" } }'\n",
    "    skript = f\"\"\"source leaprc.protein.ff14SB\n",
    "    source leaprc.water.tip3p\n",
    "    loadOff \"/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\"\n",
    "    mol = loadpdb \"/Users/jessihoernschemeyer/pKaSchNet/cuts/{fname}.pdb\"\n",
    "    set mol.1 connect0 none\n",
    "    last_residue_number = length(mol)\n",
    "    set mol.last_residue_number connect1 none\n",
    "    savepdb mol \"/Users/jessihoernschemeyer/pKaSchNet/prot/{fname}\"\n",
    "\n",
    "    quit\"\"\"\n",
    "    with open(\"ascript.py\",\"w\") as file: \n",
    "        file.writelines(skript)\n",
    "\n",
    "    !tleap -s -f /Users/jessihoernschemeyer/pKaSchNet/ascript.py\n",
    "\n",
    "\n",
    "def amber_terminus(fname, resnumber, flag): #TODO flag\n",
    "    if flag==0: #N terminus\n",
    "        skript = f\"\"\"source leaprc.protein.ff14SB\n",
    "        source leaprc.water.tip3p\n",
    "        loadOff \"/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\"\n",
    "        mol = loadpdb \"/Users/jessihoernschemeyer/pKaSchNet/cuts/{fname}.pdb\"\n",
    "        set mol.0.{resnumber} patch ACE\n",
    "        last_residue_number = length(mol)\n",
    "        set mol.last_residue_number connect1 none\n",
    "        savepdb mol \"/Users/jessihoernschemeyer/pKaSchNet/prot/{fname}\"\n",
    "\n",
    "        quit\"\"\"\n",
    "\n",
    "    if flag==1: #C terminus\n",
    "        skript = f\"\"\"source leaprc.protein.ff14SB\n",
    "        source leaprc.water.tip3p\n",
    "        loadOff \"/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\"\n",
    "        mol = loadpdb \"/Users/jessihoernschemeyer/pKaSchNet/cuts/{fname}.pdb\"\n",
    "        set mol.1 connect0 none\n",
    "        last_residue_number = length(mol)\n",
    "        set mol.last_residue_number connect1 none\n",
    "        set mol.0.{resnumber} patch NME \n",
    "        savepdb mol \"/Users/jessihoernschemeyer/pKaSchNet/prot/{fname}\"\n",
    "\n",
    "        quit\"\"\"\n",
    "\n",
    "    with open(\"ascript.py\",\"w\") as file: \n",
    "        file.writelines(skript)\n",
    "\n",
    "    !tleap -s -f /Users/jessihoernschemeyer/pKaSchNet/ascript.py\n",
    "\n",
    "    \n",
    "def add_chains(file):\n",
    "    \"add chains to the amber protonated pdbs\"\n",
    "    chain=\"A\"\n",
    "    counter=0\n",
    "    with open(local_folder + f'/prot/{file}', 'r') as f, open(local_folder + f'/prot/chained/{file}', 'w') as out:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ATOM\"):\n",
    "                # Extract the fields based on PDB format fixed columns\n",
    "                serial = line[6:11].strip()\n",
    "                atom_name = line[12:16].strip()\n",
    "                residue_name = line[17:20].strip()\n",
    "                res_seq = line[22:26].strip()\n",
    "                x = line[30:38].strip()\n",
    "                y = line[38:46].strip()\n",
    "                z = line[46:54].strip()\n",
    "                out.write(f\"ATOM  {int(serial):5d}  {atom_name:<4}{residue_name:>3} {chain:1}{int(res_seq):4d}    {float(x):8.3f}{float(y):8.3f}{float(z):8.3f}  1.00  0.00\\n\")\n",
    "\n",
    "            elif line.startswith(\"TER\"):\n",
    "                counter += 1\n",
    "                chain = char_list[counter]\n",
    "\n",
    "def _recut_deprot_save_solo_reg(f, coord, center, key, distance_cutoff): \n",
    "    \"not his!\"\n",
    "    \n",
    "    ns =  _ns(f)\n",
    "    \n",
    "    cut=ns.search(center, distance_cutoff, \"A\")\n",
    "    save(cut, f + \"P\")\n",
    "\n",
    "    for i in range(len(cut)):\n",
    "        a=cut[i]\n",
    "        target_atom = protonatable_sites[key]\n",
    "        if a.get_name() == target_atom:\n",
    "            papa = a.get_parent()\n",
    "            if coord == papa['CA'].get_coord():#ctrl\n",
    "                break\n",
    "\n",
    "    del cut[i]\n",
    "    save(cut, f + \"d\")\n",
    "\n",
    "def _recut_deprot_save_merged(f, coords, center, key, distance_cutoff): \n",
    "    \"\"\"((info1), {info2)). f is the same for both! cant do his\n",
    "    it doesnt matter e.g. ASP ASP because the same HH will never come twice. thus itll always be the other coord\"\"\"\n",
    "    if f[0] == \"~\": #his\n",
    "        _HisMerged(f, center, coord, key)\n",
    "    else:\n",
    "        atoms_i=[]\n",
    "        #res1,res2=info[0],info[1] #tuple, tuple\n",
    "        ns = _ns(f)\n",
    "        cut1= ns.search(center[0], distance_cutoff, \"A\")\n",
    "        #f, coordA, ns = _ns_n_info(info[0])\n",
    "        #cut1 = ns.search(center[0], distance_cutoff, \"A\n",
    "        #f, coordB, ns = _ns_n_info(info[1])\n",
    "        cut2 = ns.search(center[1], distance_cutoff, \"A\")\n",
    "\n",
    "        #info_resdict={res1[2] : res1[1], res2[2] : res2[1]} #name of res, coord of res {ASP: alpha carbon 1, ASP:C2}\n",
    "        counter=0\n",
    "        #cut1, cut2 = ns.search(centerA[0], distance_cutoff, \"A\"), ns.search(centerB[1], distance_cutoff, \"A\")\n",
    "\n",
    "        #recut\n",
    "        merged = set(cut1 + cut2) \n",
    "\n",
    "        #DEPROTONATE\n",
    "\n",
    "        #acquire atoms to delete\n",
    "        atoms = (protonatable_sites[k] for k in key) #Hs names\n",
    "\n",
    "        for i in range(len(merged)): #iterate thru atoms\n",
    "            a=merged[i]#atom in merged\n",
    "            if a.get_name() in atoms: #if atomname == hydrogen atom of res name\n",
    "                papa = a.get_parent()\n",
    "                resname=papa.get_resname()\n",
    "                if papa['CA'].get_coord() in coords:\n",
    "                    atoms_i.append({i:resname[0]}) #{3 : 'A', 12 : 'A'} will be deleted\n",
    "                    counter+=1\n",
    "                    if counter == 2: #if it found 2 site,leave #his wouldnt work here\n",
    "                        break\n",
    "    Bd, A, B = merged.copy(), atoms_i[0], atoms_i[1]\n",
    "    \n",
    "    #ApBp\n",
    "    save(merged, f + \"P\")\n",
    "\n",
    "    #deprotonate A\n",
    "    #A=atoms_i[0] #first atom's index\n",
    "    del merged[A] #delete first atom from ApBp\n",
    "    save(merged, f + A.value() + 'd' + 'Bp') #AdBp\n",
    "\n",
    "    #deprotonate B          \n",
    "    #B=atoms_i[1]\n",
    "    del Bd[B]\n",
    "    save(Bd, f + B.value())\n",
    "\n",
    "    #AdBd\n",
    "    save(list({merged} ^ + {Bd}), f + \"D\") #symmetrical difference = AdBd\n",
    "\n",
    "    return\n",
    "\n",
    "def _recut_deprot_save_solo_ter(f, coord, center, distance_cutoff):   \n",
    "    cut=_ns(f).search(center, distance_cutoff, \"A\")\n",
    "    save(cut, f + \"P\")\n",
    "\n",
    "    return\n",
    "\n",
    "    f.split(\"_\")[1][0]\n",
    "    res = info[2]\n",
    "\n",
    "    for i in range(len(cut)):\n",
    "            a=cut[i]\n",
    "            papa = a.get_parent()\n",
    "            resname = papa.get_resname()\n",
    "            if resname == res: \n",
    "                \n",
    "                if coord == papa['CA'].get_coord():#ctrl\n",
    "                    if key==\"X\":\n",
    "                        if papa.has_id('OXT'):\n",
    "                            #atom = papa[\"OXT\"]\n",
    "                            i = cut.index(papa[\"OXT\"])\n",
    "                            break\n",
    "                        else:\n",
    "                            i = cut.index(papa[\"C\"])\n",
    "                            break  \n",
    "                    else:\n",
    "                        i = cut.index(papa[\"N\"])\n",
    "                        break\n",
    "\n",
    "            del cut[i]\n",
    "            save(cut, f + \"d\")\n",
    "        \n",
    "            return\n",
    "\n",
    "def _recut_deprot_save_merged_ter(f, coord, center, key, distance_cutoff): #todo key\n",
    "    \"BROKEN wdym delete oxt and N.cant do AA! or his\"\n",
    "    \"\"\"this is now just solo deprot cuz terminus has no combos.\n",
    "    todo KEY\"\"\"\n",
    "    ns = _ns(f)\n",
    "    #cut1, cut2= ns.search(center[0], distance_cutoff, \"A\"), ns.search(center[1], distance_cutoff, \"A\")\n",
    "    merged = set(ns.search(center[0], distance_cutoff, \"A\") + ns.search(center[1], distance_cutoff, \"A\")) \n",
    "    for i in range(len(merged)): #basically solo\n",
    "        a=merged[i]\n",
    "        target_atom = protonatable_sites[key]\n",
    "        if a.get_name() == target_atom:\n",
    "            papa = a.get_parent()\n",
    "            if coord == papa['CA'].get_coord():#ctrl\n",
    "                break\n",
    "    \n",
    "    del cut[i]\n",
    "    save(cut, f + \"d\")\n",
    "    return\n",
    "    \n",
    "\n",
    "    atoms_i, counter =[],0\n",
    "    print(\"merged ter\")\n",
    "    res1,res2=info[0],info[1] #tuple, tuple ((f, coord, resname),\n",
    "    info_resdict={res1[2] : res1[1], res2[2] : res2[1]}\n",
    "\n",
    "    f, coordA, _, ns = _ns_n_info(info[0])\n",
    "    cut1 = ns.search(center[0], distance_cutoff, \"A\")\n",
    "\n",
    "    f, coordB, _, ns = _ns_n_info(info[1])\n",
    "    cut2 = ns.search(center[1], distance_cutoff, \"A\")\n",
    "\n",
    "    #f_split=f.split(\"_\")\n",
    "    #resA, resB = f_split[1].split(\"-\"), f_split[3].split(\"-\") #N0-MET, G1 --> [N0, MET], [G1]\n",
    "    \n",
    "    #recut\n",
    "    merged = set(cut1 + cut2) \n",
    "    save(merged, f + \"P\")\n",
    "\n",
    "\n",
    "    for i in range(len(merged)):\n",
    "        a=cut[i]\n",
    "        target_atom = protonatable_sites.get(key)\n",
    "        if a.get_name() == target_atom:\n",
    "            papa = a.get_parent()\n",
    "            if coord == papa['CA'].get_coord():#ctrl\n",
    "                break\n",
    "\n",
    "    del cut[i]\n",
    "    save(cut, f + \"d\")\n",
    "    if len(resA) > 1: #res A is TER [N0, MET]\n",
    "        ter_res = resA[1] #MET\n",
    "        reg_res_key = resB[0]\n",
    "        reg_res = protonatable_sites2[reg_res_key] #GLU #G=resB[0]\n",
    "\n",
    "    if len(resB) > 1: #res B is TER\n",
    "        ter_res = resB[1]#, resB[0][0]\n",
    "        reg_res_key = resA[0]\n",
    "        reg_res =protonatable_sites2[reg_res_key]\n",
    " \n",
    "   \n",
    "    for i in range(len(merged)):\n",
    "        a=merged[i]\n",
    "        papa = a.get_parent()\n",
    "        resname = papa.get_resname()\n",
    "        if resname == ter_res: \n",
    "            if info_resdict[resname] == papa['CA'].get_coord():\n",
    "                if \"X\" in key:\n",
    "                    if papa.has_id('OXT'):\n",
    "                        atom = papa[\"OXT\"]\n",
    "                        atoms_i.append({merged.index(atom):ter_res})\n",
    "\n",
    "                        counter+=1\n",
    "                        if counter == 2:\n",
    "                            break      \n",
    "\n",
    "                    else: \n",
    "                        atom = papa[\"C\"]\n",
    "                        atoms_i.append({merged.index(atom):ter_res})\n",
    "                        #atoms_to_delete.append({papa: \"C\"})\n",
    "                        counter+=1\n",
    "                        if counter == 2:\n",
    "                            break      \n",
    "                else: #N\n",
    "                    atom = papa[\"N\"]\n",
    "                    atoms_i.append({merged.index(atom):ter_res})\n",
    "                    #atoms_to_delete.append({papa: \"C\"})\n",
    "                    counter+=1\n",
    "                    if counter == 2:\n",
    "                        break    \n",
    "\n",
    "        elif resname == reg_res:\n",
    "            if info_resdict[resname] == papa['CA'].get_coord():\n",
    "                atom = papa[protonatable_sites[reg_res_key]]\n",
    "                atoms_i.append({merged.index(atom):reg_res})\n",
    "                #atoms_to_delete.append({papa: protonatable_sites[reg_res_key]})\n",
    "                counter+=1\n",
    "                if counter == 2:\n",
    "                    break      \n",
    "\n",
    "    Bd, A, B = merged.copy(), atoms_i[0], atoms_i[1]\n",
    "    #ApBp\n",
    "    save(merged, f + \"P\")\n",
    "\n",
    "    #deprotonate A\n",
    "    del merged[A] #delete first atom from ApBp\n",
    "    save(merged, f + A.value()) #ApBp\n",
    "\n",
    "    #deprotonate B          \n",
    "    del Bd[B]\n",
    "    save(Bd, f + B.value())\n",
    "\n",
    "    #AdBd\n",
    "    save(list({merged} ^ + {Bd}), f + \"D\") #symmetrical difference = AdBd\n",
    "\n",
    "    return\n",
    "\n",
    "#def save_amber_chainify_recut_deprotonate(info, center, key, flag, distance_cutoff):\n",
    "def save_amber_chainify_recut_deprotonate(f, coords, center, key, flag, distance_cutoff):\n",
    "        \"\"\"info (tuple or tuple of tuples): ((f, alpha carbon of the titratable residue, resname, cut))\n",
    "        #TODO: fix error in SAVE! order matters for set ends to none then set to ter after\n",
    "        flag 0 = ter merged, 1 = merged, none = solo normal 2 = solo TER.\n",
    "\n",
    "        applies terminus patches manually because biopython doesnt do that.\n",
    "\n",
    "        terminus will not be subject to combinatorics. CTER = negative, NTER = +, as is standard in amber. \n",
    "        the reason i am skipping that is because i would have to specify in amber script to not neutralize termini if she is \n",
    "        \"\"\"\n",
    "\n",
    "        amber(f)\n",
    "\n",
    "        #add chains to protonated pdb\n",
    "        add_chains(f)\n",
    "        if flag:\n",
    "            if flag==1:  #merged\n",
    "                terminus=_find_terminus_residue(f, Tcoord)\n",
    "                if terminus:\n",
    "                    amber_terminus(f, terminus)\n",
    "                    add_chains(f)\n",
    "                else:\n",
    "                    amber(f) \n",
    "                    add_chains(f)\n",
    "                _recut_deprot_save_merged(f, center, coords, key, distance_cutoff) #deals with HIS here\n",
    "            \n",
    "            elif flag==2: #solo, ter\n",
    "                amber_terminus(f, _find_terminus_residue(f, Tcoord))\n",
    "                add_chains(f)\n",
    "                _recut_deprot_save_solo_ter(f, center, distance_cutoff)  #TODO\n",
    "\n",
    "            else: #ter merged #0 #TODO change 0 ti 2 etc for efficiency\n",
    "                amber_terminus(f, _find_terminus_residue(f, Tcoord)) #terminus will be ({0: (NTRres#1, NTRres#2), 1:(ctr..)})\n",
    "                add_chains(f)\n",
    "                _recut_deprot_save_merged_ter(f, center, coords, key.strip([\"X\", \"N\"]), distance_cutoff) #TODO\n",
    "\n",
    "        #solo\n",
    "        else: #none flag #solo normal \n",
    "            if terminus:\n",
    "                amber_terminus(f, terminus)\n",
    "                add_chains(f)\n",
    "            else:\n",
    "                amber(f)\n",
    "                add_chains(f)\n",
    "            \n",
    "            if f[0]=!\"~\":\n",
    "                _recut_deprot_save_solo_reg(f, center, key, distance_cutoff) #TODO\n",
    "            else:\n",
    "                dp_soloHIS(f, center)\n",
    "\n",
    "\n",
    "\n",
    "def dp_soloHIS(fname, center):\n",
    "    cut=ns.search(center[0], distance_cutoff, \"A\")\n",
    "\n",
    "    save(cut, fname + '~HIP')\n",
    "\n",
    "    HIE = dp_HIS(\"HD1\", cut.copy())\n",
    "    save(HIE, fname + '~HIE') #A, eps prot with B prot\n",
    "\n",
    "    HID = dp_HIS(\"HE2\", cut)\n",
    "    save(HID, fname + '~HID') #A, delta protonated\n",
    "\n",
    "    HIS = dp_HIS(\"HD1\", HID)\n",
    "    save(HIS, fname + '~HIS') #A fully deprotonated\n",
    "\n",
    "def _dp_HIS_merged(atom, cut): #\n",
    "    \"only doing one. takes an atom, deletes it\"\n",
    "    #merged=cut #todo\n",
    "    for Atom in cut:\n",
    "        residue=Atom.get_parent()\n",
    "        if residue.get_resname() == \"HIP\":\n",
    "                residue.detach_child(atom) \n",
    "    return cut\n",
    "\n",
    "def _dp_notHIS_merged(atom, coord, cut): #for working in hismerged\n",
    "    for i in range(len(cut)):\n",
    "        a=cut[i]\n",
    "        #target_atom = protonatable_sites[key]\n",
    "        if a.get_name() == atom:\n",
    "            papa = a.get_parent()\n",
    "            if coord == papa['CA'].get_coord():#ctrl\n",
    "                break\n",
    "\n",
    "    del cut[i]\n",
    "    #save(cut, f + \"d\") \n",
    "\n",
    "    return cut  \n",
    "\n",
    "def _HisMerged(fname, centers, coord, cut, key): #key H stripped\n",
    "    \"\"\"doesnt do double H, or TER-H.\"\"\"\n",
    "    #recut/merged\n",
    "    ns = _ns(fname)\n",
    "    cut = {{ns.search(centers[0], distance_cutoff, \"A\")} | {ns.search(centers[1], distance_cutoff, \"A\")}}\n",
    "    #HIP = cut.copy()\n",
    "    save(cut, fname + '~HIP')\n",
    "\n",
    "    otherDP = _dp_notHIS_merged(protonatable_Hsites[key], coord, cut.copy())\n",
    "\n",
    "    HIE = set(_dp_HIS_merged(\"HD1\", cut.copy()))\n",
    "    save(HIE, fname + '~HIE') #A, eps prot with B prot\n",
    "    Ad_HIE = otherDP | HIE\n",
    "    save(Ad_HIE, fname + f'{key}d~HIE')\n",
    "\n",
    "    HID = set(_dp_HIS_merged(\"HE2\", cut))\n",
    "    save(HID, fname + '~HID') #A, delta protonated\n",
    "\n",
    "    Ad_HID = otherDP | HID\n",
    "    save(Ad_HID, fname + f'.{key}d~HID')\n",
    "    #save(HID, fname + '~HID') #A, delta protonated\n",
    "\n",
    "    HIS = set(_dp_HIS_merged(\"HD1\", HID))\n",
    "    save(HIS, fname + '~HIS') #A fully deprotonated\n",
    "    Ad_HIS = otherDP | HIS #combined both sets\n",
    "    save(Ad_HIS, fname + f'.{key}d+HIS')\n",
    "\n",
    "def merge_or_not_cutouts(cutouts_apdb, distance_cutoff, fnames, site_dict): #TODO: reduce dtypes #PDB WISE!\n",
    "    \"\"\"\n",
    "    in: all of the cutouts from the pdb. returns  [the merged or solo cutout for each input residue of cutouts_apdb]. len in = len out\"\"\"\n",
    "    #protein wise ..\n",
    "    dp_ids,centers,cuts, Ds_lite, cutouts, resnames,redunant_merged_is, done_pairs, other_site =[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "    for site in cutouts_apdb:\n",
    "        if type(site)==tuple: #all but his\n",
    "            dp_ids.append(site[0])\n",
    "            centers.append(site[1]) \n",
    "            resnames.append(site[2])\n",
    "            cuts.append(site[3])\n",
    "            other_site.append(None) #other_site is for his. N/A\n",
    "\n",
    "        else: #his is list\n",
    "            dp_ids.append(site[0][0]) \n",
    "            dp_ids.append(site[1][0])\n",
    "\n",
    "            centers.append(site[0][1]) \n",
    "            centers.append(site[1][1]) \n",
    "\n",
    "            resnames.append(site[0][2])\n",
    "            resnames.append(site[1][2]) \n",
    "\n",
    "            cuts.append(site[0][3])\n",
    "            cuts.append(site[1][3])\n",
    "\n",
    "            other_site.append(site[1][1]) #to not include own his\n",
    "            other_site.append(site[0][1]) #\"\"\n",
    "\n",
    "\n",
    "    num_residues=len(centers)\n",
    "    distances = np.zeros((num_residues, num_residues))\n",
    "    \n",
    "    for i in range(num_residues):\n",
    "        for j in range(i + 1, num_residues):\n",
    "            distance = np.linalg.norm(centers[i] - centers[j]).astype(np.float32)\n",
    "            if distance < distance_cutoff:\n",
    "                distances[i, j] = distance.astype(np.float32)\n",
    "                distances[j, i] = distance.astype(np.float32)\n",
    "\n",
    "    Ds_lite = [distances[i][distances[i] != 0] for i in range(num_residues)] #nonzero entries\n",
    "\n",
    "    #residuewise...\n",
    "    for i in range(len(Ds_lite)): #=len IDs \n",
    "        a_residues_distance_array=Ds_lite[i]\n",
    "        a_residues_distance_array.sort() #debug dont forget i messed around in here #TODO\n",
    "\n",
    "        if a_residues_distance_array.any(): #merged\n",
    "            index=i\n",
    "            closest_cutout_i = int(np.where((distances[int(index), :])==a_residues_distance_array[0])[0])\n",
    "            cut1,cut2=cuts[i], cuts[closest_cutout_i]\n",
    "            \n",
    "            #exclude own his\n",
    "            if resnames[i] == 'H' and resnames[closest_cutout_i] == 'H':\n",
    "                if other_site[i].any() and other_site[closest_cutout_i].any(): \n",
    "                    if len(a_residues_distance_array) > 1:\n",
    "                        closest_cutout_i = int(np.where((distances[int(index), :])==a_residues_distance_array[1])[0]) #next closest\n",
    "                    else:\n",
    "                        pass #to solo cutouts\n",
    "\n",
    "            pair_i = frozenset((index,dp_ids[closest_cutout_i]))#key #frozen set is immutable thus can be used as a dict key #also order doesnt matter, 2-1=1-2\n",
    "            \n",
    "            if not done_pairs: #if there are any yet merged\n",
    "                cut1,cut2=cuts[i], cuts[closest_cutout_i]\n",
    "                \n",
    "                if type(cut1) == tuple: #TER\n",
    "                    cutout = (list(set(cut1[0] + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]), cut1[1]) #cut1[0] is ter cut, cut2 is normal\n",
    "                elif type(cut2) == tuple: #safe bc no combined terminus #TER\n",
    "                    cutout = (list(set(cut1 + cut2[0])),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]), cut2[1])\n",
    "                else: #Merged\n",
    "                    cutout = (list(set(cut1 + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]))\n",
    "\n",
    "                done_pairs.append(pair_i)\n",
    "                redunant_merged_is.append(closest_cutout_i)\n",
    "\n",
    "            else: #if there are already some generated\n",
    "                if pair_i not in done_pairs: #if that mergedcut hasnt yet been made\n",
    "                    if type(cut1) == tuple: #TER\n",
    "                        cutout = (list(set(cut1[0] + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]), cut1[1])\n",
    "                        done_pairs.append(pair_i)\n",
    "                        redunant_merged_is.append(closest_cutout_i)\n",
    "                    elif type(cut2) == tuple: #TER\n",
    "                        cutout = (list(set(cut1 + cut2[0])),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]), cut2[1])\n",
    "                        done_pairs.append(pair_i)\n",
    "                        redunant_merged_is.append(closest_cutout_i)\n",
    "                    else: #Merged\n",
    "                        cutout = (list(set(cut1 + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]))\n",
    "                        done_pairs.append(pair_i)\n",
    "                        redunant_merged_is.append(closest_cutout_i)\n",
    "\n",
    "                else: #null\n",
    "                    cutout = None\n",
    "\n",
    "        else: #SOLO\n",
    "            cut=cuts[i]\n",
    "            if type(cut)==tuple: #TER\n",
    "                cutout = (cut[0], centers[i], cut[1])\n",
    "            else: #normal\n",
    "                cutout = (cut, centers[i])\n",
    "\n",
    "        cutouts.append(cutout)\n",
    "    \n",
    "    _save_merged_or_not(fnames, cutout, redunant_merged_is, distance_cutoff, site_dict)\n",
    "    return \n",
    "    return cutouts,redunant_merged_is #merged or solo\n",
    "\n",
    "def _save_merged_or_not(fnames, all_cuts, greaterN_pair_i, distance_cutoff, site_dict):\n",
    "    newfnames=[]\n",
    "    for cut, fname in zip(all_cuts, fnames):\n",
    "        L=len(cut)\n",
    "        if L==3: \n",
    "            third = cut[2] #tuple or residue object\n",
    "            if type(third) != tuple: #TER solo (resobj)\n",
    "                id, residue =fname.split(\"_\")[1], site_dict[fname] #X38 #res obj #TODO double res obj why?\n",
    "                #key, ter_res = id[0], id.split(\"-\")[1] #X, LYS\n",
    "                key=id[0]\n",
    "                atoms_to_structure(cut[0], key, fname, residue) \n",
    "                newfnames.append(fname)\n",
    "                save_amber_chainify_recut_deprotonate((fname, residue['CA'].get_coord(), id.split(\"-\")[1]), cut[1],  key, 2, distance_cutoff) #SOLO TER\n",
    "                \n",
    "            else: #merged normal  #done #cutout = (list(set(cut1 + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]))\n",
    "                key=cut[1]\n",
    "                Fname, CAcoords = _get_merged_F(greaterN_pair_i, fname, fnames, key)\n",
    "                #centers_apdb.append(third)\n",
    "                del greaterN_pair_i[0]\n",
    "                #(fname(site_dict[fname.split(\"_\")[0]]['CA']\n",
    "                atoms_to_structure(cut[0], key, Fname, None) #save as pdb) #cut #TODO!!!!!!!!! need to change resnames of\n",
    "                newfnames.append(Fname)\n",
    "                #save_amber_chainify_recut_deprotonate(((Fname, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)), third, key.strip(\",\"), 1, distance_cutoff)\n",
    "                save_amber_chainify_recut_deprotonate(Fname, CAcoords, third, key.strip(\",\"), 1, distance_cutoff)\n",
    "                #save_amber_chainify_recut_deprotonate(Fname, CAcoords, cut[2], key.strip(\",\"), 0, distance_cutoff)\n",
    "        elif L==4: #merged, ter  (counter, center, resname, (cut, residue))\n",
    "            key=cut[1].strip(\",\")\n",
    "            for a in cut[3].get_atoms():  #TODO delete probably\n",
    "                Fname, CAcoords = _get_merged_F(greaterN_pair_i, fname, fnames, key)\n",
    "                newfnames.append(Fname)\n",
    "                break\n",
    "            del greaterN_pair_i[0]\n",
    "            friend_f = fnames[greaterN_pair_i[0]]\n",
    "            f1, f2 = fname.split(\"_\"), friend_f.split(\"_\")\n",
    "            Fname = \"\".join([fname,'_',friend_f,\"_\",key.strip(\",\")])\n",
    "            newfnames.append(fname)\n",
    "\n",
    "            if \"-\" in fname: #TEMPORARY SOLUTION #TODO\n",
    "                atoms_to_structure(cut[0], key, Fname, site_dict[fname.split(\"_\")[0]]) #TODO\n",
    "            if \"-\" in friend_f:\n",
    "                atoms_to_structure(cut[0], key, Fname, site_dict[friend_f.split(\"_\")[0]]) #TODO\n",
    "\n",
    "            #info = ((f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)) #coords of CA ##?\n",
    "            save_amber_chainify_recut_deprotonate(Fname, site_dict[friend_f[0]]['CA'].get_coord(), cut[2], key, 0, distance_cutoff) #only have f coord cuz \n",
    "            #save_amber_chainify_recut_deprotonate([(f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)], cut[2], key, 0, distance_cutoff)\n",
    "\n",
    "\n",
    "        else:  #solo, noemal\n",
    "            #centers_apdb.append(cut[1])\n",
    "            newfnames.append(fname)\n",
    "            atoms_to_structure(key, fname)  \n",
    "            #info = ((f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]])) #coords of CA \n",
    "            save_amber_chainify_recut_deprotonate(((f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]])), cut[1], cut[0], None, distance_cutoff) #info, center, key\n",
    "\n",
    "def get_cutout(dask_df, distance_cutoff): #\"PARENT\" FUNCTION\n",
    "    \"\"\"for each protein in dask_df (the entire PYPKA database), it iterates residue wise through the 121,294 proteins in PYPKA database and downloads\n",
    "    the structure from RCSB with biopython. Then, it checks and skips the structure if metals & hetero sulfurs are present, and deletes non-sulfur\n",
    "    salts from titratable residues.\n",
    "    Then, for each structure residue represented in PYPKA, generates a cutout for each residue, appends the structure to cutouts_apdb\"\"\"\n",
    "    all_fnames, all_cuts, all_centers = [],[],[]\n",
    "     #---PROTEINWISE RESOLUION  \n",
    "    for i in range(19,20): #will equal len of set of pdbs in pypka, == 121294 \n",
    "        cutouts_apdb, fnames, cutouts_1_datapoint, counter, pdbname, newfnames, centers_apdb = [],[], [],0, pdbs[i],[],[]\n",
    "        residues, site_dict=[],{}\n",
    "        \n",
    "        Structure = pdb_parser.get_structure(\"\",  PDBList().retrieve_pdb_file(str.lower(pdbname),obsolete=False, pdir='PDB',file_format = 'pdb'))\n",
    "        structure = check_atoms_protein(Structure, Structure.get_atoms()) #returns nothing if undesirables\n",
    "\n",
    "        if not structure: #skip entire pdb and all its entries in pypka db if there are undesirables in pdb\n",
    "            continue\n",
    "\n",
    "        ns = PDB.NeighborSearch(list(structure.get_atoms())) #set up ns , entire protein\n",
    "        pdb_df = dask_df[dask_df.iloc[:, 1] == pdbname].drop(columns = [\"PDB ID\", \"pKa\"]) #make a subdf containing only residue entries which are in PYPKA (dask_df) \n",
    "        #Cter, Nter = pdb_df[pdb_df.iloc[:, 2] == \"CTR\"][[pdb_df.columns[0],pdb_df.columns[2]]].compute().tolist(), pdb_df[pdb_df.iloc[:, 2] == \"NTR\"][0].compute().tolist()\n",
    "\n",
    "        #---DATAPOINT RESOLUTION \n",
    "        for j in range(len(pdb_df)):  #go through each residue in a pdb #each j is a datapoint!\n",
    "            NTRresname, CTRresname=None,None\n",
    "            chain, res_id =pdb_df.iloc[j]['Chain'], int(pdb_df.iloc[j]['Res ID'])\n",
    "            try: \n",
    "                residue=structure[0][chain][res_id] #a datapoint # will error here if pypka error \n",
    "                pypka_resname, PDBresname = pdb_df.iloc[j]['Res Name'], residue.get_resname() #pypka error\n",
    "\n",
    "                if pypka_resname=='NTR':\n",
    "                    resname, pypka_resname, NTRresname=0, \"N\", PDBresname\n",
    "\n",
    "                elif pypka_resname=='CTR':\n",
    "                    resname,pypka_resname, CTRresname =1,\"X\", PDBresname #carboxyl\n",
    "\n",
    "                elif pypka_resname==PDBresname: \n",
    "                    resname=pypka_resname[0] #A,T,G...\n",
    "\n",
    "                else: \n",
    "                    continue #if pypka_resname DNE PDB resname (pypka error #1)\n",
    "                \n",
    "                #---CUTOUT + FNAME#1 GENERATION----#\n",
    "                cutouts_1_datapoint=generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter, resname) ##############can be multiple #returns empty if disordered\n",
    "                residues.append(residue)\n",
    "                cutouts_apdb.append(*cutouts_1_datapoint) \n",
    "                id = f\"{pdbname}{chain}{res_id}\"\n",
    "                site_dict.update({id: residue})\n",
    "\n",
    "                if resname==\"H\": \n",
    "                    fnames.append(f\"{id}_{resname}{counter + .1}\") \n",
    "                    fnames.append(f\"{id}_{resname}{counter + .2}\") \n",
    "                 \n",
    "                elif CTRresname:\n",
    "                    fnames.append(f\"{id}_{pypka_resname}{counter}-{CTRresname}\")\n",
    "                elif NTRresname:\n",
    "                    fnames.append(f\"{id}_{pypka_resname}{counter}-{NTRresname}\") \n",
    "\n",
    "                else: #normal\n",
    "                    fnames.append(f\"{id}_{resname}{counter}\") \n",
    "\n",
    "                counter+=1\n",
    "\n",
    "            except Exception as e: #TODO: remove this when done debugging\n",
    "                print(f\"Exception caught: {e}\")\n",
    "                raise  \n",
    "  \n",
    "        #os.remove(f\"{local_folder}/PDB/pdb{pdbname}.ent\")  #TODO\n",
    "            \n",
    "        #--PROTEIN WISE. MERGE OR NOT. then amber chainify recut deprot. \n",
    "        newfnames = merge_or_not_cutouts(cutouts_apdb, distance_cutoff, fnames, site_dict) #############\n",
    "        \n",
    "    return newfnames #, centers_apdb, residues\n",
    "\n",
    "#dask_df = read_database(pkPDB_CSV)\n",
    "#pdbs = list(OrderedSet(list(dask_df[\"PDB ID\"])))\n",
    "fs = get_cutout(dask_df, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATOM      1  N   NMET A   1      44.195  -3.177   8.871  1.00 25.75           N  \n",
      "ATOM      2  SD  NMET A   1      44.340   1.458   7.911  1.00 36.83           S  \n",
      "ATOM      3  O   NMET A   1      41.696  -3.002   9.526  1.00 20.10           O  \n",
      "ATOM      4  C   NMET A   1      42.288  -1.932   9.563  1.00 21.37           C  \n",
      "ATOM      5  CG  NMET A   1      43.128   0.189   7.549  1.00 38.99           C  \n",
      "ATOM      6  CA  NMET A   1      43.701  -1.841   8.993  1.00 20.86           C  \n",
      "ATOM      7  CB  NMET A   1      43.738  -1.184   7.605  1.00 14.28           C  \n",
      "ATOM      8  CE  NMET A   1      45.824   0.489   7.683  1.00 48.39           C  \n",
      "ATOM      9  ND2 ASN A   2      42.144  -1.730  13.663  1.00 17.58           N  \n",
      "ATOM     10  CG  ASN A   2      41.292  -0.863  13.128  1.00 23.61           C  \n",
      "ATOM     11  CA  ASN A   2      40.504  -0.672  10.716  1.00  9.86           C  \n",
      "ATOM     12  OD1 ASN A   2      41.258   0.327  13.471  1.00 18.45           O  \n",
      "ATOM     13  N   ASN A   2      41.817  -0.815  10.139  1.00 13.85           N  \n",
      "ATOM     14  CD1 TRP A 158      41.674  -2.776   4.699  1.00 15.97           C  \n",
      "ATOM     15  NE1 TRP A 158      40.608  -2.803   5.568  1.00 17.21           N  \n",
      "HETATM   16  O   HOH A 223      42.700  -4.565  12.706  1.00 28.87           O  \n",
      "ATOM     17  CD  GLU A   5      45.479  -0.096  12.221  1.00 42.21           C  \n",
      "ATOM     18  OE2 GLU A   5      45.655  -0.992  13.151  1.00 47.32           O  \n",
      "ATOM     19  CG  GLU A   5      44.861   1.177  12.774  1.00 20.84           C  \n",
      "ATOM     20  CA  GLU A   5      43.740   3.440  12.292  1.00 13.72           C  \n",
      "ATOM     21  CB  GLU A   5      44.371   2.183  11.710  1.00 19.12           C  \n",
      "ATOM     22  OE1 GLU A   5      45.853  -0.252  11.065  1.00 53.39           O  \n",
      "HETATM   23  O   HOH A 288      44.276  -1.067  15.536  1.00 53.44           O  \n",
      "HETATM   24  O   HOH A 335      47.605  -2.844  13.028  1.00 64.32           O  \n",
      "HETATM   25  O   HOH A 187      45.117  -3.582  11.676  1.00 40.70           O  \n",
      "TER      26      HOH A 187                                                       \n",
      "END   \n"
     ]
    }
   ],
   "source": [
    "!cat \"/Users/jessihoernschemeyer/pKaSchNet/cuts/199lA1_N0-MET_199lA5_G1_NG-N44.195.pdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'site_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [(f, site_dict[f[\u001b[39m0\u001b[39m]][\u001b[39m'\u001b[39m\u001b[39mCA\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget_coord(), protonatable_sites2[f[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m199lA1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m199lA5\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [(f, site_dict[f[\u001b[39m0\u001b[39m]][\u001b[39m'\u001b[39m\u001b[39mCA\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget_coord(), protonatable_sites2[f[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m199lA1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m199lA5\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'site_dict' is not defined"
     ]
    }
   ],
   "source": [
    "[(f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in ('199lA1','199lA5')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problems:\n",
    "center is not even an output and that is \"resname\" which isnt even being used, no use in fixing this bc i might not keep that bc  i might just make a new center from the Hs but probably not actually."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider putting cA in fname"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fix REDUNDANT MERGED IS!!! (still?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIS, change names of "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "                \n",
    "\n",
    "\"\"\"for f in fs:\n",
    "    amber(f)\n",
    "    #!tleap -s -f /Users/jessihoernschemeyer/pKaSchNet/ascript.py\n",
    "    add_chains(f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def deprotonate_singles(res, cut): #turn one acidic into all its others? #NOT HIS!!!\n",
    "    \"\"\"Binary Situation\n",
    "    this function takes a cutout that is not merged / a single cutout, and the file name of that cutout. It gets the residue string name, and from that a string of the atom name of the hydrogen ion\n",
    "    that should be deleted. \n",
    "    cut: Set(<atom1>, <atom2>)\n",
    "    ONE CCUT AT A TIME!\n",
    "    Then, found atoms is a list of all the atoms with that name e.g. \"OXT\" and the desired parent res (in the file name).\n",
    "    If the atom has the name and parent res name matching the file name information, then the atom is detached and then saved.\n",
    "    \n",
    "    This returns: ApBd or AdBp.\"\"\"\n",
    "#NORMAL CASE\n",
    "    atom_to_delete=None\n",
    "\n",
    "    atom_to_delete = protonatable_sites.get(res)\n",
    "    if atom_to_delete:\n",
    "        Res = protonatable_sites2[res] #careful here w same name\n",
    "\n",
    "        for atom in cut:\n",
    "            residue=atom.get_parent()\n",
    "            if residue.get_resname() == Res:\n",
    "                residue.detach_child(atom_to_delete)\n",
    "                return cut\n",
    "            \n",
    "    if not atom_to_delete: #his (atom), or TER\n",
    "        if res[0]==\"+\": #ter\n",
    "            for atom in cut:\n",
    "                residue=atom.get_parent()\n",
    "                if residue.get_resname() == \"HIP\":\n",
    "                    residue.detach_child(res) #res IS atom to delete for HIS!\n",
    "                    return cut\n",
    "        else: #his\n",
    "            for atom in cut:\n",
    "                residue=atom.get_parent()\n",
    "                if residue.get_resname() == \"HIP\":\n",
    "                    residue.detach_child(res) #res IS atom to delete for HIS\n",
    "\n",
    "            deprotonate_terminus_single(res, cut)\n",
    "\n",
    "def deprotonate_terminus_single(res, cut):\n",
    "    \"\"\"Input: XPHE, NARG..\n",
    "    returns a deprotonated NTR or CTR\"\"\"\n",
    "    ter, resi = res[0], res[1:]\n",
    "    for atom in cut:\n",
    "        residue=atom.get_parent()\n",
    "        if residue.get_resname() == resi: \n",
    "            if res==\"X\": #CTR\n",
    "                atoms = residue.get_atoms()\n",
    "                try: \n",
    "                    residue.detach_child(\"OXT\")\n",
    "                    return cut \n",
    "                except:\n",
    "                    residue.detach_child(\"C\")\n",
    "                    return cut\n",
    "            else: #NTR \n",
    "                residue.detach_child(\"N\")\n",
    "                return cut\n",
    "\n",
    "def dp_GleichRes2Mal(res, cut): #doesnt take HHH or ters\n",
    "    \"returns two cuts, deprotonated of them both.\"\n",
    "    \n",
    "    found_atoms, dp_cuts =[],[]\n",
    "    atom_to_delete = protonatable_sites[res]\n",
    "\n",
    "    if type(atom_to_delete) == tuple: #histidine\n",
    "        for atom in cut:\n",
    "            residue=atom.get_parent()\n",
    "            if residue.get_resname() == \"HIP\":\n",
    "                for atom in residue.get_atoms():   \n",
    "                    atomname = atom.get_name()        \n",
    "                    if atomname in atom_to_delete:\n",
    "                        found_atoms.append((atomname, residue))\n",
    "\n",
    "        \n",
    "        found_atoms.sort() #will sort by letter and number \n",
    "        resA_del, resB_del, resA_eps, resB_eps = found_atoms[0], found_atoms[1], found_atoms[2], found_atoms[3]\n",
    "        \n",
    "        hipAhipB = cut.copy() \n",
    "        dp_cuts.append(hipAhipB, \"HIPHIP\")\n",
    "        #modify resA\n",
    "        resA_del[1].detach_child(resA_del[0]) #makes HIE res A, res B HIP\n",
    "        hieAhipB = cut.copy()\n",
    "        dp_cuts.append(hieAhipB, \"HIEHIP\") #HIE+HIp\n",
    "\n",
    "        resA_eps[1].detach_child(resA_eps[0]) #makes HIS res A, res B HIP\n",
    "        hisAhipB = cut.copy()\n",
    "        dp_cuts.append(hisAhipB, \"HISHIP\") #HIS+HIp\n",
    "\n",
    "        hidAhipB = hisAhipB.union(hipAhipB-hieAhipB)\n",
    "        dp_cuts.append(hidAhipB, \"HIDHIP\")\n",
    "\n",
    "        #modify residue b \n",
    "        resB_del[1].detach_child(resB_del[0]) #makes HIE res A, res B HIP\n",
    "        hisAhieB = cut.copy()\n",
    "        dp_cuts.append(hisAhieB, \"HISHIE\")\n",
    "\n",
    "        resB_eps[1].detach_child(resB_eps[0])\n",
    "        hisAhisB = cut.copy()\n",
    "        dp_cuts.append(hisAhisB, \"HISHIE\")\n",
    "\n",
    "        hisAhidB = hisAhisB.union(hisAhipB-hisAhieB)\n",
    "        dp_cuts.append(hisAhisB, \"HISHID\")\n",
    "        \n",
    "        #now make the rest \n",
    "        hipA_atoms = hipAhipB - hisAhipB \n",
    "        HIPHIE = hisAhieB.union(hipA_atoms) #arg is the atoms which make hip seperate from his\n",
    "        dp_cuts.append(HIPHIE, \"HIPHIE\")\n",
    "        HIPHID = hisAhidB.union(hipA_atoms)\n",
    "        dp_cuts.append(HIPHID, \"HIPHID\")\n",
    "        HIPHIS = hisAhisB.union(hipA_atoms)\n",
    "        dp_cuts.append(HIPHIS, \"HIPHIS\")\n",
    "\n",
    "        dp_cuts.append(HIPHIE | hieAhipB, \"HIEHIE\")\n",
    "        dp_cuts.append(HIPHID | hieAhipB, \"HIEHID\")\n",
    "        dp_cuts.apprnf(HIPHIS | hieAhipB,  \"HIEHIS\")\n",
    "\n",
    "        dp_cuts.append(HIPHIE | hidAhipB, \"HIDHIE\") \n",
    "        dp_cuts.append(HIPHID | hidAhipB, \"HIDHID\")\n",
    "        dp_cuts.append(HIPHIS | hidAhipB, \"HIDHIS\")\n",
    "\n",
    "    elif len(atom_to_delete) == 2: #nor his\n",
    "        Res = protonatable_sites2[res]\n",
    "        for residue in cut.get_residues():\n",
    "            if residue.get_name() == Res:\n",
    "                for atom in residue.get_atoms():           \n",
    "                    if atom.get_name() == atom_to_delete:\n",
    "                        found_atoms.append((residue, atom_to_delete))\n",
    "\n",
    "        #for two found atoms\n",
    "        resA, resB = found_atoms[0], found_atoms[1]\n",
    "        resA[0].detach_child(resA[1])\n",
    "        Adp = cut.copy()\n",
    "        #deprotonate cut fully by removing the other second residue\n",
    "        resB[0].detach_child(resB[1])\n",
    "        Bdp = cut.copy()\n",
    "\n",
    "        return Adp, resB\n",
    "\n",
    "def recut_and_deprotonate(fnames_apdb, centers_apdb, distance_cutoff): #the centers come in #fnames after protonation\n",
    "    \"\"\"\n",
    "    fnames_apdb [list]: [fname_cut1, fname_cut2, fname_cut3] --> resA &/OR resB\n",
    "                    Ex: ['199lA11_GLU3', '199lA10_ASP2_199lA161_TYR37_AT', '199lA70_ASP22_199lA31_HIS11.2_AH'] \n",
    "\n",
    "    This function takes in all the file names for a single pdb, as well as the centers of their titratable site (OXT, N, NE2, NH...). Using the fname, it\n",
    "    makes a cutout again using that center which was found before. \n",
    "    \n",
    "    If the cutout is merged, then there will be a multiple centers. Then, the cutout becomes the set of both cutoute (a sphere of distance_cutoff from the \n",
    "    protonatable site.)\"\"\"\n",
    "    for fname, center in zip(fnames_apdb, centers_apdb):\n",
    "        struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{fname}')\n",
    "        pdbatoms = list(struct.get_atoms())\n",
    "        ns = PDB.NeighborSearch(pdbatoms) #set up ns , entire protein\n",
    "        print(\"all atoms\", len(list(struct.get_atoms())))\n",
    "        #############MERGEDD#####\n",
    "        if type(center)==tuple: \n",
    "            f=fname.split(\"_\")\n",
    "            print(f)\n",
    "            singles_res, key=f[1],f[4] #22X-PHE, AT, XASP\n",
    "            resA, resB = key[0],key[1] #A,T\n",
    "\n",
    "            #NTR/CTR (cannot combine NTR and CTR.) MERGED\n",
    "            if resA or resB in ('X', 'N'): #need to deal wih his in here???\n",
    "                cut = set(ns.search(center[0], distance_cutoff, \"A\")) | set(ns.search(center[1], distance_cutoff, \"A\")) #the merged cut\n",
    "                Save(cut, fname) #fully protonated\n",
    "                if resA in ('X', 'N'): \n",
    "                    #res1 = f[1].split(\"-\") #the real residue\n",
    "                    resAdp = deprotonate_singles(resA + f[1].split(\"-\")[1], cut) #xphe\n",
    "                    resBdp = deprotonate_singles(resB, cut) #xphe\n",
    "\n",
    "                elif resB in ('X', 'N'):\n",
    "                    res2 = f[3].split(\"-\")\n",
    "                    resBdp = deprotonate_singles(resB + res2[1], cut) #xphe\n",
    "                    resAdp = deprotonate_singles(resA)\n",
    "                    \n",
    "                deprotonated = OrderedSet(resAdp) | OrderedSet(resBdp)  #fully deprotonated #not making a new cut but combining what is done \n",
    "\n",
    "                Save(resAdp, fname + f'~{resA}d') #resA deprot, B prot\n",
    "                Save(resBdp, fname + f\"~{resB}d\") #A prot, resB deprot\n",
    "                Save(deprotonated, fname + \"~d\")\n",
    "\n",
    "\n",
    "\n",
    "            elif resA == resB: #no ntr and ctr will get here!\n",
    "                if resB == 'H' or resA=='H':  #double H\n",
    "                    his_cuts = dp_HH(\"H\", cut)\n",
    "                    for cut in his_cuts:\n",
    "                        Save(cut[0], fname + f'{cut[1]}')\n",
    "\n",
    "                else: #normal AA, GG..\n",
    "                  \n",
    "                    resAdp, resBdp = dp_GleichRes2Mal(cut, resA)   ##AA, GG... #res A is res B\n",
    "                    Save(resAdp, fname + f'~{resA}d') #resA deprot, B prot\n",
    "                    Save(resBdp, fname + f\"~{resB}d\") #A prot, resB deprot\n",
    "                    Save(OrderedSet(resBdp) | OrderedSet(resAdp), fname + '~d')\n",
    "                \n",
    "            elif resB == 'H' or resA=='H': #histidine \n",
    "                    if resA == 'H': #1 his #HA\n",
    "                        HIE = deprotonate_singles(\"HD1\", cut)\n",
    "                        Save(HIE, fname + '~HIE') #A, eps prot with B prot\n",
    "                        HID = deprotonate_singles(\"HE2\", cut)\n",
    "                        Save(HID, fname + '~HID') #A, delta protonated\n",
    "                        HIS = deprotonate_singles(\"HD1\", HID.copy()) \n",
    "                        Save(HIS, fname + '~HIS') #A fully deprotonated\n",
    "\n",
    "                        resBdp = deprotonate_singles(resB, cut.copy())\n",
    "\n",
    "                        #remaining combos with deprotonated other nonhis and nonter residue\n",
    "                        resBd_HIE = OrderedSet(resBdp) | OrderedSet(HIE) \n",
    "                        Save(resAd_HIE, fname + f'~{resB}d+HIE')\n",
    "                        resBd_HID = OrderedSet(resBdp) | OrderedSet(HID)\n",
    "                        Save(resAd_HID, fname + f'~{resB}d+HID')\n",
    "                        resBd_HIS = OrderedSet(resBdp) | OrderedSet(HIS)\n",
    "                        Save(resAd_HIS, fname + f'~{resB}d+HIS')\n",
    "                \n",
    "                    else: #ResB = H. then this means that the second res is the his. AH\n",
    "                        HIE = deprotonate_singles(\"HD1\", cut.copy())\n",
    "                        Save(HIE, fname + '~HIE') #HIE with A =HIP\n",
    "                        HID = deprotonate_singles(\"HE2\", cut.copy())\n",
    "                        Save(HID, fname + '~HID')\n",
    "                        HIS = deprotonate_singles(\"HD1\", HID.copy())\n",
    "                        Save(HID, fname + '~HIS') #fully deprotonated\n",
    "\n",
    "                        resAdp = deprotonate_singles(resA, cut.copy())\n",
    "\n",
    "                        #make combos with sets \n",
    "                        resAd_HIE = OrderedSet(resAdp) | OrderedSet(HIE) #after resA is already deprotonated\n",
    "                        Save(resAd_HIE, fname + f'~{resA}d+HIE')\n",
    "                        resAd_HID = OrderedSet(resAdp) | OrderedSet(HID)\n",
    "                        Save(resAd_HID, fname + f'~{resA}d+HID')\n",
    "                        resAd_HIS = OrderedSet(resAdp) | OrderedSet(HIS)\n",
    "                        Save(resAd_HIS, fname + f'~{resA}d+HIS')\n",
    "                        \n",
    "            else:  #normal merged\n",
    "                    cut = OrderedSet(ns.search(center[0], distance_cutoff, \"A\")) | OrderedSet(ns.search(center[1], distance_cutoff, \"A\")) #the merged cut\n",
    "                    print(len(cut))\n",
    "                    list(set(cut1[0] + cut2))\n",
    "                    Save(cut, fname) #fully protonated, both\n",
    "\n",
    "                    resAdp = deprotonate_singles(resA, cut) #resA = \"A\", \"G\". resAdp = a cut\n",
    "                    Save(resAdp, fname + f'~{resA}d') #resA deprot, B prot\n",
    "                    print(len(resAdp))\n",
    "\n",
    "                    resBdp = deprotonate_singles(resB, cut)\n",
    "                    Save(resBdp, fname + f\"~{resB}d\") #A prot, resB deprot\n",
    "\n",
    "                    deprotonated = OrderedSet(resAdp) | OrderedSet(resBdp)  #fully deprotonated #not making a new cut but combining what is done \n",
    "                    Save(deprotonated, fname + \"~d\")\n",
    "\n",
    "        else: #single\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            Save(cut, fname) #fully protonated\n",
    "\n",
    "            L = singles_res.split(\"-\")\n",
    "            if len(L)==2: #TER\n",
    "                 #debug\n",
    "                 for atom in cut.get_atoms():\n",
    "                     print(atom)\n",
    "                 deprotonated = deprotonate_singles(L[1], cut) #L[1] = \"PHE\"\n",
    "                 Save(deprotonated, fname + \"~D\")\n",
    "\n",
    "            else: \n",
    "                if len(L[0].split(\".\")) == 2: #HIS\n",
    "                    HIP=cut.copy()\n",
    "\n",
    "                    HIE = deprotonate_singles(\"OD1\", cut)\n",
    "                    Save(HIE, fname + \"HIE\")\n",
    "\n",
    "                    HIS = deprotonate_singles(\"OE2\", HIE.copy())\n",
    "                    Save(HIS, fname + \"HIS\")\n",
    "                    \n",
    "                    Save(HIS.union(HIP - HIE), fname + \"HID\")\n",
    "                    \n",
    "                else: #regular\n",
    "                    deprotonated = deprotonate_singles(fname.split(\"_\")[1][0], cut) #[A]SP22, [X]25PHE.. #not his\n",
    "                    Save(deprotonated, fname + \"~D\")\n",
    "\n",
    "def Save(cut, F):\n",
    "    if cut:\n",
    "        print(F, len(cut))\n",
    "    else:\n",
    "        print(F, cut)\n",
    "          \n",
    "recut_and_deprotonate(fs, cs, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m#save(cut, \"P\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#merged\u001b[39;00m\n\u001b[1;32m      6\u001b[0m atoms_del \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(cut)) \u001b[39mif\u001b[39;00m cut[i]\u001b[39m.\u001b[39mget_name() \u001b[39min\u001b[39;00m atoms_to_delete \u001b[39mand\u001b[39;00m cut[i]\u001b[39m.\u001b[39mget_parent()\u001b[39m.\u001b[39mget_resname() \u001b[39m==\u001b[39m res]\n\u001b[0;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(atoms_del, cut[atoms_del[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39mget_parent(), cut[atoms_del[\u001b[39m1\u001b[39m]]\u001b[39m.\u001b[39mget_parent(), cut[atoms_del[\u001b[39m2\u001b[39;49m]]\u001b[39m.\u001b[39mget_parent())\n\u001b[1;32m      8\u001b[0m Bd \u001b[39m=\u001b[39m cut\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     10\u001b[0m \u001b[39mdel\u001b[39;00m cut[atoms_del[\u001b[39m0\u001b[39m]]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cut1=ns.search(center[0], 5, \"A\")\n",
    "cut, resis=cut1,[\"ASH\"]\n",
    "atoms_to_delete=[\"OD1\", \"OD2\"]\n",
    "#save(cut, \"P\")\n",
    "#merged, normal\n",
    "for i in range(len(cut)):\n",
    "    a=cut[i]\n",
    "    if a.get_name() in atoms_to_delete:\n",
    "        if a.get_parent().get_resname() in resis:\n",
    "            \n",
    "\n",
    "atoms_del = [i for i in range(len(cut)) if cut[i].get_name() in atoms_to_delete and cut[i].get_parent().get_resname() == res]\n",
    "print(atoms_del, cut[atoms_del[0]].get_parent(), cut[atoms_del[1]].get_parent(), cut[atoms_del[2]].get_parent())\n",
    "Bd = cut.copy()\n",
    "\n",
    "del cut[atoms_del[0]]\n",
    "#save(cut, \"Ad\")\n",
    "del Bd[atoms_del[1]]\n",
    "#save(Bd, \"Bd\")\n",
    "#save(set(cut, Bd), \"D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cut = ns.search(center[0], distance_cutoff, \"R\") #list\n",
    "\n",
    "for r in res_cut:\n",
    "    if r.get_resname() == res:\n",
    "        r.detach_child(atom_to_delete)\n",
    "        break\n",
    "    return [tuple(residue.get_atoms()) for residue in res.get_cut] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 57 54 82 82\n",
      "150 57 54 82 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=N) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=H1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=H2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=H3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CA) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HA) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CB) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HB) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CG1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HG1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CG2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HG2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=C) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=O) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=H) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HB2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HB3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CG) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CD1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HD1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CE1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HE1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CZ) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=OH) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HH) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CE2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HE2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CD2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HD2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HG3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CD) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HD3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=NE) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HE) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=NH1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HH1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=NH2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HH2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'S' for Atom (name=SD) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CE) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HE3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=OD1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=OD2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=OG1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=ND2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n"
     ]
    }
   ],
   "source": [
    "merged=1\n",
    "center=cs[1]\n",
    "fname=fs[1]\n",
    "\n",
    "struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{fname}')\n",
    "pdbatoms = list(struct.get_atoms())\n",
    "ns = PDB.NeighborSearch(pdbatoms) #set up ns , entire protein\n",
    "\n",
    "if merged:\n",
    "    cut1=ns.search(center[0], 5, \"A\")\n",
    "    cut2=ns.search(center[1], 5, \"A\")\n",
    "print(len(list(struct.get_atoms())), len(cut1), len(cut2), len(set(cut1 + cut2)), len(set(cut1)  | set(cut2)))\n",
    "\n",
    "for a in cut1:\n",
    "    a.get_parent().detach_child('N')\n",
    "    break\n",
    "print(len(list(struct.get_atoms())), len(cut1), len(cut2), len(set(cut1 + cut2)), len(set(cut1)  | set(cut2)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: ascript.py: command not found\n"
     ]
    }
   ],
   "source": [
    "!ascript.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo disordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "local_folder=\"/Users/jessihoernschemeyer/pKaSchNet\"\n",
    "from Bio.PDB import *\n",
    "from Bio import PDB\n",
    "pdb_parser=PDB.PDBParser()\n",
    "cut = pdb_parser.get_structure(\"\",  local_folder + '/prot/chained/199lA161_T37_199lA10_A2_TA')\n",
    "\n",
    "for residue in cut.get_residues():\n",
    "    for a in residue.get_atoms():\n",
    "        info = f\"{a.get_name()}{round(a.get_coord()[0],3)}\"\n",
    "        \n",
    "\n",
    "cut = pdb_parser.get_structure(\"\",  local_folder + '/cuts/199lA161_T37_199lA10_A2_TA')\n",
    "\n",
    "for residue in cut.get_residues():\n",
    "    for a in residue.get_atoms():\n",
    "        info = f\"{a.get_name()}{round(a.get_coord()[0],3)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Residue TYR het=  resseq=161 icode= >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut[0]['A'][161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 0, 'C', (' ', 10, ' '), ('H2', ' '))\n"
     ]
    }
   ],
   "source": [
    "print(a.get_full_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fs\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fs' is not defined"
     ]
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
