{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"\"\"\n",
    "   _____      __    _   __     __  .____ \n",
    "  / ___/_____/ /_  / | / /__  / /_./ __ \\/ /__   ____ \n",
    "  \\__ \\/ ___/ __ \\/  |/ / _ \\/ __./ /_/ / //_/ / __  / \n",
    " ___/ / /__/ / / / /|  /  __/ /_./ ____/  <   | /_/  \\\n",
    "/____/\\___/_/ /_/_/ |_/\\___/\\__./_/   /_/|_|  \\__,_/\\_\\   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "from Bio import PDB\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from ase import Atoms, Atom\n",
    "import dask.dataframe as dd\n",
    "from ordered_set import OrderedSet\n",
    "import os\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import chain, product\n",
    "import sys\n",
    "import string\n",
    "char_list = (string.ascii_uppercase)\n",
    "protonatable_sites2 = {\"G\":\"GLH\", \n",
    "                      \"C\":\"CYS\", \n",
    "                      \"L\":\"LYS\", \n",
    "                      \"A\":\"ASH\",\n",
    "                      \"H\": \"HIP\",\n",
    "                      \"T\": \"TYR\",\n",
    "                      \"X\": \"CTR\",\n",
    "                      \"N\": \"NTR\"}\n",
    "protonatable_sites = {\"G\":\"HE2\", \n",
    "                      \"C\":\"HG\", \n",
    "                      \"L\":\"HZ1\", \n",
    "                      \"A\":\"HD2\",\n",
    "                      \"H\": (\"HD1\",\"HE2\"), #this needs to be fixed \n",
    "                      \"T\": \"HH\",\n",
    "                      \"X\": (\"OXT\", \"C\"),\n",
    "                      \"N\": \"N\"}\n",
    "protonatable_sites3 = {\"GLU\":\"GLH\", \n",
    "                      \"ASP\":\"ASH\",\n",
    "                      \"HIS\": \"HIP\"}\n",
    "\n",
    "\n",
    "def atoms_to_structure(cutout, filename): \n",
    "    \"\"\"input: cutout [<atom>, <atom>]: list of biopython atom objects\"\"\"\n",
    "    #file name has the fname, which hs the resnumber and 199lA108_G29\n",
    "    tit_res_names = None\n",
    "    resname=None\n",
    "    Tresid =filename.split(\"_\")\n",
    "    f1=Tresid[0][4:] #A108\n",
    "    T_IDn,T_IDc = [int(f1[1:])], [f1[0]] \n",
    "\n",
    "    if len(Tresid) > 3: #merged\n",
    "        f2 = Tresid[2][4:]\n",
    "        T_IDn.append(int(f2[1:]))\n",
    "        T_IDc.append(f2[0])\n",
    "\n",
    "    chain_dict, res_dict = {}, {}\n",
    "    structure = Structure.Structure(\"\")\n",
    "    model = Model.Model(0)\n",
    "    structure.add(model)\n",
    "\n",
    "    for atom in cutout:\n",
    "        resname=None\n",
    "        res = atom.get_parent()\n",
    "        id = res.get_full_id()\n",
    "        res_id, chain_id = id[3], id[2]\n",
    "\n",
    "        if res_id[1] in T_IDn: #acidify \n",
    "            if chain_id in T_IDc:\n",
    "                resname = protonatable_sites3.get(res.get_resname())\n",
    "                if not resname: #bc ter etc arent in dic\n",
    "                    resname = res.get_resname()\n",
    "            else:\n",
    "                resname = res.get_resname()\n",
    "\n",
    "        else:\n",
    "            resname = res.get_resname()\n",
    "       \n",
    "#make/retrieve chain\n",
    "        if chain_id not in chain_dict:\n",
    "            chain = Chain.Chain(chain_id) #make new chain\n",
    "            chain_dict[chain_id] = chain\n",
    "            model.add(chain) #add it\n",
    "\n",
    "        else:\n",
    "            chain = chain_dict[chain_id]\n",
    "        \n",
    "#make/retrieve residue\n",
    "        if res_id not in res_dict:\n",
    "            residue = Residue.Residue(res_id, resname, '')\n",
    "            res_dict[res_id] = residue\n",
    "            chain.add(residue) #add it\n",
    "        else:\n",
    "            residue = res_dict[res_id]\n",
    "\n",
    "        residue.add(atom)\n",
    "#save\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(f\"cuts/{filename}.pdb\")\n",
    "\n",
    "def _get_cut_AspGlu(residue, counter, distance_cutoff):\n",
    "    cuts=[]\n",
    "    sites=protonatable_sites[resname]\n",
    "    atom1,atom2=residue[sites[0]],residue[sites[1]]\n",
    "    if atom1.is_disordered(): \n",
    "        center, resname = atom1.get_coord(), resname + \",\"\n",
    "    elif atom2.is_disordered():\n",
    "        center, resname = atom2.get_coord(), resname + \",\"\n",
    "    else:\n",
    "        center=(atom1.get_coord() + atom2.get_coord()) / 2.0\n",
    "    cut = ns.search(center, distance_cutoff, \"A\") #put ns search i n below? todo\n",
    "    cuts.append((counter, center, resname, cut)) \n",
    "    return cuts\n",
    "\n",
    "def _get_cut_normal(residue, counter, distance_cutoff):\n",
    "    site=residue[protonatable_sites[resname]]\n",
    "    if site.is_disordered(): \n",
    "        resname = resname + \",\"\n",
    "    center = site.get_coord()\n",
    "    cut = ns.search(center, distance_cutoff, \"A\")\n",
    "    cuts.append((counter, center, resname, cut))\n",
    "    return cuts\n",
    "\n",
    "def generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter, resname):\n",
    "    \"\"\"Residue wise resolurion. ns is neighbor search set up for the entire protein, residue is the single data point / 1 of several residues in a pdb & in pypka.\n",
    "    input is one residue. output is the cutout around its titratable site, both of which can be plural e.g. his, mb asp and glu.\n",
    "    residue (biopython Residue object): a single protonable residue \"\"\"\n",
    "    protonatable_sites = {\"G\":(\"OE1\",\"OE2\"), \"A\":(\"OD1\",\"OD2\"), \"C\":\"SG\", \"L\":\"NZ\", \"H\":(\"NE2\", \"ND1\"), \"T\":\"OH\"} #TODO\n",
    "    cuts = []\n",
    "\n",
    "    if resname==0: #NTR\n",
    "        center = residue['N'].get_coord()\n",
    "        cut = ns.search(center, distance_cutoff, \"A\")\n",
    "        cuts.append((counter, center, 'N', (cut, residue))) \n",
    "        return cuts\n",
    "    \n",
    "    elif resname==1: #CTR\n",
    "        try:\n",
    "            center = residue['OXT'].get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, 'X', (cut, residue)))\n",
    "        except:\n",
    "            center = residue['C'].get_coord()\n",
    "        cut = ns.search(center, distance_cutoff, \"A\")\n",
    "        cuts.append((counter, center, 'X', (cut, residue)))\n",
    "        return cuts\n",
    "    \n",
    "    else:\n",
    "        if resname==\"G\": \n",
    "            return _get_cut_AspGlu(counter, distance_cutoff)\n",
    "        if resname==\"A\": \n",
    "            return _get_cut_AspGlu(counter, distance_cutoff)\n",
    "        if resname==\"C\": \n",
    "            return _get_cut_normal(residue, counter, distance_cutoff)\n",
    "        if resname==\"L\": \n",
    "            return _get_cut_normal(residue, counter, distance_cutoff)\n",
    "        if resname==\"T\":\n",
    "            return _get_cut_normal(residue, counter, distance_cutoff)\n",
    "        if resname==\"H\":\n",
    "            sites=protonatable_sites[resname]\n",
    "            atom1,atom2=residue[sites[0]],residue[sites[1]]            \n",
    "            if atom1.is_disordered(): \n",
    "                resname = resname + \",\"\n",
    "            if atom2.is_disordered():\n",
    "                resname = resname + \",\"\n",
    "            center1,center2=atom1.get_coord(), atom2.get_coord()\n",
    "            cut1, cut2 = ns.search(center1, distance_cutoff, \"A\"), ns.search(center2, distance_cutoff, \"A\")\n",
    "            cuts.append([(counter+.1, center1, resname, cut1),(counter+.2, center2, resname, cut2)])\n",
    "\n",
    "    return cuts #plural because of sites with multiple sites.\n",
    "\n",
    "\n",
    "def merge_or_not_cutouts(cutouts_apdb, distance_cutoff): #TODO: reduce dtypes #PDB WISE!\n",
    "    \"\"\"\n",
    "    in: all of the cutouts from the pdb. returns  [the merged or solo cutout for each input residue of cutouts_apdb]. len in = len out\"\"\"\n",
    "    #protein wise ..\n",
    "    dp_ids,centers,cuts, Ds_lite, cutouts, resnames,redunant_merged_is, done_pairs, other_site =[],[],[],[], [],[],[],[],[]\n",
    "\n",
    "    for site in cutouts_apdb:\n",
    "        if type(site)==tuple: \n",
    "            dp_ids.append(site[0])\n",
    "            centers.append(site[1]) \n",
    "            resnames.append(site[2])\n",
    "            cuts.append(site[3])\n",
    "            other_site.append(None) \n",
    "\n",
    "        else: #his is list\n",
    "            dp_ids.append(site[0][0]) \n",
    "            dp_ids.append(site[1][0])\n",
    "\n",
    "            centers.append(site[0][1]) \n",
    "            centers.append(site[1][1]) \n",
    "\n",
    "            resnames.append(site[0][2])\n",
    "            resnames.append(site[1][2]) \n",
    "\n",
    "            cuts.append(site[0][3])\n",
    "            cuts.append(site[1][3])\n",
    "\n",
    "            other_site.append(site[1][1]) #TODO\n",
    "            other_site.append(site[0][1])\n",
    "\n",
    "\n",
    "    num_residues=len(centers)\n",
    "    distances = np.zeros((num_residues, num_residues))\n",
    "    \n",
    "    for i in range(num_residues):\n",
    "        for j in range(i + 1, num_residues):\n",
    "            distance = np.linalg.norm(centers[i] - centers[j]).astype(np.float32)\n",
    "            if distance < distance_cutoff:\n",
    "                distances[i, j] = distance.astype(np.float32)\n",
    "                distances[j, i] = distance.astype(np.float32)\n",
    "\n",
    "    Ds_lite = [distances[i][distances[i] != 0] for i in range(num_residues)] #nonzero entries\n",
    "\n",
    "    #residuewise...\n",
    "    for i in range(len(Ds_lite)): #=len IDs \n",
    "        a_residues_distance_array=Ds_lite[i]\n",
    "        a_residues_distance_array.sort() #debug dont forget i messed around in here #TODO\n",
    "\n",
    "        if a_residues_distance_array.any(): #merged\n",
    "            index=i\n",
    "            closest_cutout_i = int(np.where((distances[int(index), :])==a_residues_distance_array[0])[0])\n",
    "            cut1,cut2=cuts[i], cuts[closest_cutout_i]\n",
    "            \n",
    "            #exclude own his\n",
    "            if resnames[i] == 'H' and resnames[closest_cutout_i] == 'H':\n",
    "                if other_site[i].any() and other_site[closest_cutout_i].any(): \n",
    "                    if len(a_residues_distance_array) > 1:\n",
    "                        closest_cutout_i = int(np.where((distances[int(index), :])==a_residues_distance_array[1])[0]) #next closest\n",
    "                    else:\n",
    "                        pass #to solo cutouts\n",
    "\n",
    "            pair_i = frozenset((index,dp_ids[closest_cutout_i]))#key #frozen set is immutable thus can be used as a dict key #also order doesnt matter, 2-1=1-2\n",
    "            \n",
    "            if not done_pairs: #if there are any yet merged\n",
    "                cut1,cut2=cuts[i], cuts[closest_cutout_i]\n",
    "                \n",
    "                if type(cut1) == tuple:\n",
    "                    cutout = (list(set(cut1[0] + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]), cut1[1])\n",
    "                elif type(cut2) == tuple: #safe bc no combined terminus\n",
    "                    cutout = (list(set(cut1 + cut2[0])),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]), cut2[1])\n",
    "                else:\n",
    "                    cutout = (list(set(cut1 + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]))\n",
    "\n",
    "                done_pairs.append(pair_i)\n",
    "                redunant_merged_is.append(closest_cutout_i)\n",
    "\n",
    "            else: #if there are already some generated\n",
    "                if pair_i not in done_pairs: #if that mergedcut hasnt yet been made\n",
    "                    if type(cut1) == tuple:\n",
    "                        cutout = (list(set(cut1[0] + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]), cut1[1])\n",
    "                        done_pairs.append(pair_i)\n",
    "                        redunant_merged_is.append(closest_cutout_i)\n",
    "                    elif type(cut2) == tuple:\n",
    "                        cutout = (list(set(cut1 + cut2[0])),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]), cut2[1])\n",
    "                        done_pairs.append(pair_i)\n",
    "                        redunant_merged_is.append(closest_cutout_i)\n",
    "                    else:\n",
    "                        cutout = (list(set(cut1 + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]))\n",
    "                        done_pairs.append(pair_i)\n",
    "                        redunant_merged_is.append(closest_cutout_i)\n",
    "\n",
    "                else: #null\n",
    "                    cutout = None\n",
    "\n",
    "        else: #solo cutout\n",
    "            cut=cuts[i]\n",
    "            if type(cut)==tuple:\n",
    "                cutout = (cut[0], centers[i], cut[1])\n",
    "            else:\n",
    "                cutout = (cut, centers[i])\n",
    "\n",
    "        cutouts.append(cutout)\n",
    "    \n",
    "    return cutouts,redunant_merged_is #merged or solo\n",
    "\n",
    "def get_cutout(dask_df, distance_cutoff): #\"PARENT\" FUNCTION\n",
    "    \"\"\"for each protein in dask_df (the entire PYPKA database), it iterates residue wise through the 121,294 proteins in PYPKA database and downloads\n",
    "    the structure from RCSB with biopython. Then, it checks and skips the structure if metals & hetero sulfurs are present, and deletes non-sulfur\n",
    "    salts from titratable residues.\n",
    "    Then, for each structure residue represented in PYPKA, generates a cutout for each residue, appends the structure to cutouts_apdb\"\"\"\n",
    "    all_fnames, all_cuts, all_centers = [],[],[]\n",
    "     #---PROTEINWISE RESOLUION  \n",
    "    for i in range(19,20): #will equal len of set of pdbs in pypka, == 121294 \n",
    "        cutouts_apdb, fnames, cutouts_1_datapoint, counter, pdbname, newfnames, centers_apdb = [],[], [],0, pdbs[i],[],[]\n",
    "        residues, site_dict=[],{}\n",
    "        \n",
    "        Structure = pdb_parser.get_structure(\"\",  PDBList().retrieve_pdb_file(str.lower(pdbname),obsolete=False, pdir='PDB',file_format = 'pdb'))\n",
    "        structure = check_atoms_protein(Structure, Structure.get_atoms()) #returns nothing if undesirables\n",
    "\n",
    "        if not structure: #skip entire pdb and all its entries in pypka db if there are undesirables in pdb\n",
    "            continue\n",
    "\n",
    "        ns = PDB.NeighborSearch(list(structure.get_atoms())) #set up ns , entire protein\n",
    "        pdb_df = dask_df[dask_df.iloc[:, 1] == pdbname].drop(columns = [\"PDB ID\", \"pKa\"]) #make a subdf containing only residue entries which are in PYPKA (dask_df) \n",
    "        \n",
    "        #---DATAPOINT RESOLUTION \n",
    "        for j in range(len(pdb_df)):  #go through each residue in a pdb #each j is a datapoint!\n",
    "            NTRresname, CTRresname=None,None\n",
    "            chain, res_id =pdb_df.iloc[j]['Chain'], int(pdb_df.iloc[j]['Res ID'])\n",
    "            try: \n",
    "                residue=structure[0][chain][res_id] #a datapoint # will error here if pypka error \n",
    "                pypka_resname, PDBresname = pdb_df.iloc[j]['Res Name'], residue.get_resname() #pypka error\n",
    "\n",
    "                if pypka_resname=='NTR':\n",
    "                    resname, pypka_resname, NTRresname=0, \"N\", PDBresname\n",
    "\n",
    "                elif pypka_resname=='CTR':\n",
    "                    resname,pypka_resname, CTRresname =1,\"X\", PDBresname #carboxyl\n",
    "\n",
    "                elif pypka_resname==PDBresname: \n",
    "                    resname=pypka_resname[0] #A,T,G...\n",
    "\n",
    "                else: \n",
    "                    continue #if pypka_resname DNE PDB resname (pypka error #1)\n",
    "                \n",
    "                #---CUTOUT + FNAME GENERATION----#\n",
    "                cutouts_1_datapoint=generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter, resname) ##############can be multiple #returns empty if disordered\n",
    "                residues.append(residue)\n",
    "                cutouts_apdb.append(*cutouts_1_datapoint) \n",
    "                id = f\"{pdbname}{chain}{res_id}\"\n",
    "                site_dict.update({id: residue})\n",
    "                print(id)\n",
    "\n",
    "                if resname==\"H\": \n",
    "                    fnames.append(f\"{id}_{resname}{counter + .1}\") \n",
    "                    fnames.append(f\"{id}_{resname}{counter + .2}\") \n",
    "                 \n",
    "                elif CTRresname:\n",
    "                    fnames.append(f\"{id}_{pypka_resname}{counter}-{CTRresname}\")\n",
    "                elif NTRresname:\n",
    "                    fnames.append(f\"{id}_{pypka_resname}{counter}-{NTRresname}\") \n",
    "\n",
    "                else: #normal\n",
    "                    fnames.append(f\"{id}_{resname}{counter}\") \n",
    "\n",
    "                counter+=1\n",
    "\n",
    "            except Exception as e: #TODO: remove this when done debugging\n",
    "                print(f\"Exception caught: {e}\")\n",
    "                raise  \n",
    "  \n",
    "        #os.remove(f\"{local_folder}/PDB/pdb{pdbname}.ent\")  #TODO\n",
    "            \n",
    "        #--PROTEIN WISE. MERGE OR NOT\n",
    "        merged_and_solos, greaterN_pair_i = merge_or_not_cutouts(cutouts_apdb, distance_cutoff) #############\n",
    "        for cut, fname in zip(merged_and_solos, fnames): #(list(set(cut1 + cut2)),resnames[i] + resnames[closest_cutout_i], (centers[i], centers[closest_cutout_i]))\n",
    "            \n",
    "            if cut:\n",
    "                \n",
    "                #resi_atom, L = site_dict[fname.split(\"_\")[0]]['CA'], len(cut) #cntrl\n",
    "                L=len(cut)\n",
    "\n",
    "                if L==3: \n",
    "                    third = cut[2]\n",
    "                    if type(third) != tuple: ##solo ter, done\n",
    "                        for a in third.get_atoms(): #AMIGHT Delete\n",
    "                            Fname=f\"{fname}-{str(round(a.get_coord()[0],3))}\"\n",
    "                            break\n",
    "                        #centers_apdb.append(cut[1])#\n",
    "                        newfnames.append(Fname)\n",
    "                        \n",
    "                    #info = ((f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)) #coords of CA ##?\n",
    "                        save_amber_chainify_recut_deprotonate((Fname, site_dict[f[0]]['CA'].get_coord(), None), None)) #SOLO TER\n",
    "                    \n",
    "                    #maybe here i can feed the info which identifies, but i need to label all else so that they are not recognized. then would just need\n",
    "                                                      #to change the name in resdict.\n",
    "                                            \n",
    "                    else: #merged normal  #done\n",
    "                        f1, f2, key = fname.split(\"_\"), friend_f.split(\"_\"), cut[1].strip(\",\") #199lA162_L39_199lA159_A36_LA\n",
    "                        #centers_apdb.append(third)\n",
    "                        #friend_f = fnames[greaterN_pair_i[0]]\n",
    "                        Fname=\"\".join([fname,'_',fnames[greaterN_pair_i[0]],\"_\",key])\n",
    "                        del greaterN_pair_i[0]\n",
    "                        #(fname(site_dict[fname.split(\"_\")[0]]['CA']\n",
    "                        atoms_to_structure(key, Fname) #save as pdb) #cut #TODO!!!!!!!!! need to change resnames of\n",
    "                        newfnames.append(Fname)\n",
    "                        #info = ((Fname, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)) #coords of CA\n",
    "                        save_amber_chainify_recut_deprotonate((Fname, (site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)), key, flag=1)\n",
    "\n",
    "\n",
    "                elif L==4: #merged, ter #TODO\n",
    "                    key=cut[1]\n",
    "                    for a in cut[3].get_atoms(): \n",
    "                        friend_f = fnames[greaterN_pair_i[0]]\n",
    "                        Fname=\"\".join([fname,'_',friend_f,\"_\",cut[1].strip(\",\"),\"-\",a.get_name(), str(round(a.get_coord()[0],3))])\n",
    "                        newfnames.append(Fname)\n",
    "                        break\n",
    "                    del greaterN_pair_i[0]\n",
    "                    #centers_apdb.append(cut[2])\n",
    "                    atoms_to_structure(key, Fname)\n",
    "                    #info = ((f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)) #coords of CA ##?\n",
    "                    save_amber_chainify_recut_deprotonate(((f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]]) for f in (f1, f2)), key, flag=0)\n",
    "            \n",
    "\n",
    "                else:  #solo, noemal, done\n",
    "                    #centers_apdb.append(cut[1])\n",
    "                    newfnames.append(fname)\n",
    "                    atoms_to_structure(key, fname) \n",
    "                    #info = ((f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]])) #coords of CA \n",
    "                    save_amber_chainify_recut_deprotonate(((f, site_dict[f[0]]['CA'].get_coord(), protonatable_sites2[f[1][0]])), cut[0], flag=None)\n",
    "\n",
    "        #amber(f)\n",
    "        #add_chains(f)\n",
    "        #deprotonate/recut(f, site_dict[fname])\n",
    "    return newfnames, centers_apdb, residues\n",
    "\n",
    "def _ns_fXYZx2(info):\n",
    "    \"\"\"per residue. \"\"\"\n",
    "    f=info[0]\n",
    "    pdbatoms = list(pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{f}').get_atoms())\n",
    "    ns = PDB.NeighborSearch(list(pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{f}').get_atoms())) #set up ns , entire protein\n",
    "    #cut = ns.search(centerA[0], distance_cutoff, \"A\"), ns.search(centerB[1], distance_cutoff, \"A\")\n",
    "    return f, info[1], info[2], ns, ns.search(centerA[0], distance_cutoff, \"A\"), ns.search(centerB[1], distance_cutoff, \"A\")\n",
    "    \n",
    "def amber(fname):\n",
    "    skript = f\"\"\"source leaprc.protein.ff14SB\n",
    "    source leaprc.water.tip3p\n",
    "    loadOff \"/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\"\n",
    "    mol = loadpdb \"/Users/jessihoernschemeyer/pKaSchNet/cuts/{fname}.pdb\"\n",
    "    savepdb mol \"/Users/jessihoernschemeyer/pKaSchNet/prot/{fname}\"\n",
    "\n",
    "    quit\"\"\"\n",
    "    with open(\"ascript.py\",\"w\") as file: \n",
    "        file.writelines(skript)\n",
    "    \n",
    "def add_chains(file):\n",
    "    chain=\"A\"\n",
    "    counter=0\n",
    "    with open(local_folder + f'/prot/{file}', 'r') as f, open(local_folder + f'/prot/chained/{file}', 'w') as out:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ATOM\"):\n",
    "                # Extract the fields based on PDB format fixed columns\n",
    "                serial = line[6:11].strip()\n",
    "                atom_name = line[12:16].strip()\n",
    "                residue_name = line[17:20].strip()\n",
    "                res_seq = line[22:26].strip()\n",
    "                x = line[30:38].strip()\n",
    "                y = line[38:46].strip()\n",
    "                z = line[46:54].strip()\n",
    "                out.write(f\"ATOM  {int(serial):5d}  {atom_name:<4}{residue_name:>3} {chain:1}{int(res_seq):4d}    {float(x):8.3f}{float(y):8.3f}{float(z):8.3f}  1.00  0.00\\n\")\n",
    "\n",
    "            elif line.startswith(\"TER\"):\n",
    "                counter += 1\n",
    "                chain = char_list[counter]\n",
    "\n",
    "def deprot_save_solo_reg(info, key): #done\n",
    "    \"not his!\"\n",
    "    f, coord, center, cut =  _ns_fXYZx2(info)\n",
    "    #cut=ns.search(center, distance_cutoff, \"A\")\n",
    "    #save(cut, f + \"P\")\n",
    "\n",
    "    for i in range(len(cut)):\n",
    "        a=cut[i]\n",
    "        if a.get_name() == protonatable_sites[key]:\n",
    "            papa = a.get_parent()\n",
    "            if coord == papa['CA'].get_coord():#ctrl\n",
    "                break\n",
    "\n",
    "    del cut[i]\n",
    "    save(cut, f + \"d\")\n",
    "\n",
    "def deprot_save_solo_ter(info):   #TODO!!     \n",
    "            cut=ns.search(center, distance_cutoff, \"A\")\n",
    "            save(cut, f + \"P\")\n",
    "        \n",
    "            res=f.split(\"_\")[1].split(\"-\")\n",
    "            atom = protonatable_sites[res[0][0]] #X,N\n",
    "\n",
    "            if type(atom) == str: #NTR\n",
    "                for i in range(len(cut)):\n",
    "                    if a.get_name() == atom:\n",
    "                        papa = a.get_parent()\n",
    "                        if info_resdict[papa.get_resname()] == papa['CA'].get_coord():#ctrl\n",
    "                            break\n",
    "            \n",
    "            \n",
    "            else: #tuple, C-ter\n",
    "                for i in range(len(cut)):\n",
    "                    a=cut[i]\n",
    "                    if a.get_name() in atom:\n",
    "                        papa = a.get_parent()\n",
    "                        if info_resdict[papa.get_resname()] == papa['CA'].get_coord():#ctrl\n",
    "                            break\n",
    "\n",
    "                del cut[i]\n",
    "                save(cut, f + \"d\")\n",
    "                \n",
    "            for i in range(len(cut)):\n",
    "                a=merged[i]\n",
    "                if a.get_name() == protonatable_sites[key]:\n",
    "                    papa = a.get_parent()\n",
    "                    if info_resdict[papa.get_resname()] == papa['CA'].get_coord():#ctrl\n",
    "                        break\n",
    "\n",
    "                del cut[i]\n",
    "                save(cut, f + \"d\")\n",
    "\n",
    "def deprot_save_merged_ter(info, key): #mostly done\n",
    "    \"cant do AA! or his\"\n",
    "    atoms_i=[]\n",
    "\n",
    "    res1,res2=info[0],info[1] #tuple, tuple ((f, coord, resname,\n",
    "    f, coordA, centerA,cut1 = _ns_fXYZx2(info[0])\n",
    "    f, coordB, centerB,cut2 = _ns_fXYZx2(info[1])\n",
    "    info_resdict={res1[2] : res1[1], res2[2] : res2[1]}\n",
    "\n",
    "    f_split=f.split(\"_\")\n",
    "    resA, resB = f_split[1].split(\"-\"), f_split[3].split(\"-\") #N0-MET, G1 --> [N0, MET], [G1]\n",
    "\n",
    "    \n",
    "    counter=0\n",
    "\n",
    "    #recut\n",
    "    merged = set(cut1 + cut2) \n",
    "    save(merged, f + \"P\")\n",
    "\n",
    "    if len(resA) > 1: #res A is TER [N0, MET]\n",
    "        ter_res = resA[1] #MET\n",
    "        reg_res_key = resB[0]\n",
    "        reg_res = protonatable_sites2[reg_res_key] #GLU #G=resB[0]\n",
    "\n",
    "    if len(resB) > 1: #res B is TER\n",
    "        ter_res = resB[1]\n",
    "        reg_res_key = resA[0]\n",
    "        reg_res =protonatable_sites2[reg_res_key]\n",
    " \n",
    "   \n",
    "    for i in range(len(merged)):\n",
    "        a=merged[i]\n",
    "        papa = a.get_parent()\n",
    "        resname = papa.get_resname()\n",
    "        if resname == ter_res: \n",
    "            if info_resdict[resname] == papa['CA'].get_coord():\n",
    "                if papa.has_id('OXT'):\n",
    "                    atom = papa[\"OXT\"]\n",
    "                    atoms_i.append({merged.index(atom):ter_res})\n",
    "                    #atoms_to_delete.append({papa: \"OXT\"})\n",
    "                    counter+=1\n",
    "                    if counter == 2:\n",
    "                            break      \n",
    "\n",
    "                else:\n",
    "                    atom = papa[\"C\"]\n",
    "                    atoms_i.append({merged.index(atom):ter_res})\n",
    "                    #atoms_to_delete.append({papa: \"C\"})\n",
    "                    counter+=1\n",
    "                    if counter == 2:\n",
    "                            break      \n",
    "\n",
    "        elif resname == reg_res:\n",
    "            if info_resdict[resname] == papa['CA'].get_coord():\n",
    "                atom = papa[protonatable_sites[reg_res_key]]\n",
    "                atoms_i.append({merged.index(atom):reg_res})\n",
    "                #atoms_to_delete.append({papa: protonatable_sites[reg_res_key]})\n",
    "                counter+=1\n",
    "                if counter == 2:\n",
    "                        break      \n",
    "\n",
    "    Bd, A, B = merged.copy(), atoms_i[0], atoms_i[1]\n",
    "    #ApBp\n",
    "    save(merged, f + \"P\")\n",
    "\n",
    "    #deprotonate A\n",
    "    del merged[A] #delete first atom from ApBp\n",
    "    save(merged, f + A.value()) #ApBp\n",
    "\n",
    "    #deprotonate B          \n",
    "    del Bd[B]\n",
    "    save(Bd, f + B.value())\n",
    "\n",
    "    #AdBd\n",
    "    save(list({merged} ^ + {Bd}), f + \"D\") #symmetrical difference = AdBd\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def deprotonate_save_merged(info, key): #done\n",
    "    \"((info1), {info2)). f is the same for both! cant do AA! or his\"\n",
    "    atoms_i=[]\n",
    "    res1,res2=info[0],info[1] #tuple, tuple\n",
    "    f, coordA, centerA,cut1 = _ns_fXYZx2(info[0])\n",
    "    f, coordB, centerB,cut2 = _ns_fXYZx2(info[1])\n",
    "\n",
    "    info_resdict={res1[2] : res1[1], res2[2] : res2[1]} #name of res, coord of res {ASP:C1, ASP:C2}\n",
    "    counter=0\n",
    "    #cut1, cut2 = ns.search(centerA[0], distance_cutoff, \"A\"), ns.search(centerB[1], distance_cutoff, \"A\")\n",
    "\n",
    "    #recut\n",
    "    merged = set(cut1 + cut2) \n",
    "\n",
    "    #DEPROTONATE\n",
    "\n",
    "    #acquire atoms to delete\n",
    "    atoms = (protonatable_sites[k] for k in key) #Hs names\n",
    "    for i in range(len(merged)): #iterate thru atoms\n",
    "        a=merged[i]#atom in merged\n",
    "        if a.get_name() in atoms: #if atomname == hydrogen atom of res name\n",
    "            papa = a.get_parent()\n",
    "            resname=papa.get_resname()\n",
    "            if info_resdict[resname] == papa['CA'].get_coord():#CA coord of Tres of OG cut == Tres's alphacarbon position, which would be in the cut. #TODO: if one were to use reallu small distances this may not work :)\n",
    "                atoms_i.append({i:resname[0]}) #{3 : 'A', 12 : 'A'}\n",
    "                counter+=1\n",
    "                if counter == 2: #if it found 2 site,leave #his wouldnt work here\n",
    "                    break\n",
    "    Bd, A, B = merged.copy(), atoms_i[0], atoms_i[1]\n",
    "    \n",
    "    #ApBp\n",
    "    save(merged, f + \"P\")\n",
    "\n",
    "    #deprotonate A\n",
    "    #A=atoms_i[0] #first atom's index\n",
    "    del merged[A] #delete first atom from ApBp\n",
    "    save(merged, f + A.value()) #ApBp\n",
    "\n",
    "    #deprotonate B          \n",
    "    #B=atoms_i[1]\n",
    "    del Bd[B]\n",
    "    save(Bd, f + B.value())\n",
    "\n",
    "    #AdBd\n",
    "    save(list({merged} ^ + {Bd}), f + \"D\") #symmetrical difference = AdBd\n",
    "\n",
    "    return\n",
    "\n",
    "def save_amber_chainify_recut_deprotonate(info, key, flag):\n",
    "        \"\"\"info (tuple or tuple of tuples): ((f, alpha carbon of the titratable residue, resname, cut))\n",
    "        #TODO: fix error in SAVE!\n",
    "        \"\"\"\n",
    "        #atoms_i=[]\n",
    "        #f, coord, center =info[0], info[1], info[2]\n",
    "        #pdbatoms = list(pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{f}').get_atoms())\n",
    "        #ns = PDB.NeighborSearch(pdbatoms) #set up ns , entire protein\n",
    "        f=info[0][0] #is the same for both\n",
    "        #protonate\n",
    "        amber(f)\n",
    "\n",
    "        #add chains to protonated pdb\n",
    "        add_chains(f)\n",
    "\n",
    "        #info_resdict={res1[2] : res1[1], res2[2] : res2[1]} #name of res, coord of res\n",
    "        #MERGED\n",
    "        if flag==1: \n",
    "            deprotonate_save_merged(info, key)\n",
    "\n",
    "\n",
    "        #ter merged\n",
    "        elif flag==0:\n",
    "            cut1=ns.search(center[0], distance_cutoff, \"A\")\n",
    "            cut2=ns.search(center[1], distance_cutoff, \"A\")\n",
    "            f_split=f.split()\n",
    "            resA, resB = f_split[1].split(\"-\"), f_split[3].split(\"-\")\n",
    "\n",
    "            if len(resA) > 1:\n",
    "                res1 = resA[1]\n",
    "                res2 = protonatable_sites[resB[0]]\n",
    "\n",
    "            if len(resB) > 1:\n",
    "                res2 = resB[1]\n",
    "                res1=protonatable_sites[resA[0]]\n",
    "            \n",
    "            merged = set(cut1 + cut2)\n",
    "            save(merged, f + \"P\")\n",
    "            \n",
    "            for i in range(len(merged)):\n",
    "                a=merged[i]\n",
    "                if a.get_name() in atoms_to_delete:\n",
    "                    papa = a.get_parent()\n",
    "                    if papa.get_resname() in (res1, res2):\n",
    "                        if rs['CA'].get_coord() == papa['CA'].get_coord():\n",
    "                            atoms_i.append(i)\n",
    "                            counter+=1\n",
    "                            if counter == 2:\n",
    "                                break\n",
    "                                \n",
    "            Bd = merged.copy()\n",
    "\n",
    "            del merged[atoms_del[0]]\n",
    "            save(cut, f + \"Ad\")\n",
    "\n",
    "            del Bd[atoms_del[1]]\n",
    "            save(Bd, f + \"Bd\")\n",
    "\n",
    "            save(set(merged + Bd), f + \"D\")\n",
    "\n",
    "\n",
    "        #solo\n",
    "        else: #none flag\n",
    "\n",
    "            if key != None: #solo, noemal\n",
    "                deprot_save_solo_reg(info, key) \n",
    "\n",
    "            else: #solo, ter\n",
    "                deprot_save_solo_ter(info)  #TODO\n",
    "\n",
    "            \n",
    "#dask_df = read_database(pkPDB_CSV)\n",
    "#pdb_parser, pdbs = PDB.PDBParser(), list(OrderedSet(list(dask_df[\"PDB ID\"])))\n",
    "fs, cs, rs = get_cutout(dask_df, 5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider putting cA in fname"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fix REDUNDANT MERGED IS!!! (still?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIS, change names of "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "                \n",
    "\n",
    "\"\"\"for f in fs:\n",
    "    amber(f)\n",
    "    #!tleap -s -f /Users/jessihoernschemeyer/pKaSchNet/ascript.py\n",
    "    add_chains(f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def deprotonate_singles(res, cut): #turn one acidic into all its others? #NOT HIS!!!\n",
    "    \"\"\"Binary Situation\n",
    "    this function takes a cutout that is not merged / a single cutout, and the file name of that cutout. It gets the residue string name, and from that a string of the atom name of the hydrogen ion\n",
    "    that should be deleted. \n",
    "    cut: Set(<atom1>, <atom2>)\n",
    "    ONE CCUT AT A TIME!\n",
    "    Then, found atoms is a list of all the atoms with that name e.g. \"OXT\" and the desired parent res (in the file name).\n",
    "    If the atom has the name and parent res name matching the file name information, then the atom is detached and then saved.\n",
    "    \n",
    "    This returns: ApBd or AdBp.\"\"\"\n",
    "#NORMAL CASE\n",
    "    atom_to_delete=None\n",
    "\n",
    "    atom_to_delete = protonatable_sites.get(res)\n",
    "    if atom_to_delete:\n",
    "        Res = protonatable_sites2[res] #careful here w same name\n",
    "\n",
    "        for atom in cut:\n",
    "            residue=atom.get_parent()\n",
    "            if residue.get_resname() == Res:\n",
    "                residue.detach_child(atom_to_delete)\n",
    "                return cut\n",
    "            \n",
    "    if not atom_to_delete: #his (atom), or TER\n",
    "        if res[0]==\"+\": #ter\n",
    "            for atom in cut:\n",
    "                residue=atom.get_parent()\n",
    "                if residue.get_resname() == \"HIP\":\n",
    "                    residue.detach_child(res) #res IS atom to delete for HIS!\n",
    "                    return cut\n",
    "        else: #his\n",
    "            for atom in cut:\n",
    "                residue=atom.get_parent()\n",
    "                if residue.get_resname() == \"HIP\":\n",
    "                    residue.detach_child(res) #res IS atom to delete for HIS\n",
    "\n",
    "            deprotonate_terminus_single(res, cut)\n",
    "\n",
    "def deprotonate_terminus_single(res, cut):\n",
    "    \"\"\"Input: XPHE, NARG..\n",
    "    returns a deprotonated NTR or CTR\"\"\"\n",
    "    ter, resi = res[0], res[1:]\n",
    "    for atom in cut:\n",
    "        residue=atom.get_parent()\n",
    "        if residue.get_resname() == resi: \n",
    "            if res==\"X\": #CTR\n",
    "                atoms = residue.get_atoms()\n",
    "                try: \n",
    "                    residue.detach_child(\"OXT\")\n",
    "                    return cut \n",
    "                except:\n",
    "                    residue.detach_child(\"C\")\n",
    "                    return cut\n",
    "            else: #NTR \n",
    "                residue.detach_child(\"N\")\n",
    "                return cut\n",
    "\n",
    "def dp_GleichRes2Mal(res, cut): #doesnt take HHH or ters\n",
    "    \"returns two cuts, deprotonated of them both.\"\n",
    "    \n",
    "    found_atoms, dp_cuts =[],[]\n",
    "    atom_to_delete = protonatable_sites[res]\n",
    "\n",
    "    if type(atom_to_delete) == tuple: #histidine\n",
    "        for atom in cut:\n",
    "            residue=atom.get_parent()\n",
    "            if residue.get_resname() == \"HIP\":\n",
    "                for atom in residue.get_atoms():   \n",
    "                    atomname = atom.get_name()        \n",
    "                    if atomname in atom_to_delete:\n",
    "                        found_atoms.append((atomname, residue))\n",
    "\n",
    "        \n",
    "        found_atoms.sort() #will sort by letter and number \n",
    "        resA_del, resB_del, resA_eps, resB_eps = found_atoms[0], found_atoms[1], found_atoms[2], found_atoms[3]\n",
    "        \n",
    "        hipAhipB = cut.copy() \n",
    "        dp_cuts.append(hipAhipB, \"HIPHIP\")\n",
    "        #modify resA\n",
    "        resA_del[1].detach_child(resA_del[0]) #makes HIE res A, res B HIP\n",
    "        hieAhipB = cut.copy()\n",
    "        dp_cuts.append(hieAhipB, \"HIEHIP\") #HIE+HIp\n",
    "\n",
    "        resA_eps[1].detach_child(resA_eps[0]) #makes HIS res A, res B HIP\n",
    "        hisAhipB = cut.copy()\n",
    "        dp_cuts.append(hisAhipB, \"HISHIP\") #HIS+HIp\n",
    "\n",
    "        hidAhipB = hisAhipB.union(hipAhipB-hieAhipB)\n",
    "        dp_cuts.append(hidAhipB, \"HIDHIP\")\n",
    "\n",
    "        #modify residue b \n",
    "        resB_del[1].detach_child(resB_del[0]) #makes HIE res A, res B HIP\n",
    "        hisAhieB = cut.copy()\n",
    "        dp_cuts.append(hisAhieB, \"HISHIE\")\n",
    "\n",
    "        resB_eps[1].detach_child(resB_eps[0])\n",
    "        hisAhisB = cut.copy()\n",
    "        dp_cuts.append(hisAhisB, \"HISHIE\")\n",
    "\n",
    "        hisAhidB = hisAhisB.union(hisAhipB-hisAhieB)\n",
    "        dp_cuts.append(hisAhisB, \"HISHID\")\n",
    "        \n",
    "        #now make the rest \n",
    "        hipA_atoms = hipAhipB - hisAhipB \n",
    "        HIPHIE = hisAhieB.union(hipA_atoms) #arg is the atoms which make hip seperate from his\n",
    "        dp_cuts.append(HIPHIE, \"HIPHIE\")\n",
    "        HIPHID = hisAhidB.union(hipA_atoms)\n",
    "        dp_cuts.append(HIPHID, \"HIPHID\")\n",
    "        HIPHIS = hisAhisB.union(hipA_atoms)\n",
    "        dp_cuts.append(HIPHIS, \"HIPHIS\")\n",
    "\n",
    "        dp_cuts.append(HIPHIE | hieAhipB, \"HIEHIE\")\n",
    "        dp_cuts.append(HIPHID | hieAhipB, \"HIEHID\")\n",
    "        dp_cuts.apprnf(HIPHIS | hieAhipB,  \"HIEHIS\")\n",
    "\n",
    "        dp_cuts.append(HIPHIE | hidAhipB, \"HIDHIE\") \n",
    "        dp_cuts.append(HIPHID | hidAhipB, \"HIDHID\")\n",
    "        dp_cuts.append(HIPHIS | hidAhipB, \"HIDHIS\")\n",
    "\n",
    "    elif len(atom_to_delete) == 2: #nor his\n",
    "        Res = protonatable_sites2[res]\n",
    "        for residue in cut.get_residues():\n",
    "            if residue.get_name() == Res:\n",
    "                for atom in residue.get_atoms():           \n",
    "                    if atom.get_name() == atom_to_delete:\n",
    "                        found_atoms.append((residue, atom_to_delete))\n",
    "\n",
    "        #for two found atoms\n",
    "        resA, resB = found_atoms[0], found_atoms[1]\n",
    "        resA[0].detach_child(resA[1])\n",
    "        Adp = cut.copy()\n",
    "        #deprotonate cut fully by removing the other second residue\n",
    "        resB[0].detach_child(resB[1])\n",
    "        Bdp = cut.copy()\n",
    "\n",
    "        return Adp, resB\n",
    "\n",
    "def recut_and_deprotonate(fnames_apdb, centers_apdb, distance_cutoff): #the centers come in #fnames after protonation\n",
    "    \"\"\"\n",
    "    fnames_apdb [list]: [fname_cut1, fname_cut2, fname_cut3] --> resA &/OR resB\n",
    "                    Ex: ['199lA11_GLU3', '199lA10_ASP2_199lA161_TYR37_AT', '199lA70_ASP22_199lA31_HIS11.2_AH'] \n",
    "\n",
    "    This function takes in all the file names for a single pdb, as well as the centers of their titratable site (OXT, N, NE2, NH...). Using the fname, it\n",
    "    makes a cutout again using that center which was found before. \n",
    "    \n",
    "    If the cutout is merged, then there will be a multiple centers. Then, the cutout becomes the set of both cutoute (a sphere of distance_cutoff from the \n",
    "    protonatable site.)\"\"\"\n",
    "    for fname, center in zip(fnames_apdb, centers_apdb):\n",
    "        struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{fname}')\n",
    "        pdbatoms = list(struct.get_atoms())\n",
    "        ns = PDB.NeighborSearch(pdbatoms) #set up ns , entire protein\n",
    "        print(\"all atoms\", len(list(struct.get_atoms())))\n",
    "        #############MERGEDD#####\n",
    "        if type(center)==tuple: \n",
    "            f=fname.split(\"_\")\n",
    "            print(f)\n",
    "            singles_res, key=f[1],f[4] #22X-PHE, AT, XASP\n",
    "            resA, resB = key[0],key[1] #A,T\n",
    "\n",
    "            #NTR/CTR (cannot combine NTR and CTR.) MERGED\n",
    "            if resA or resB in ('X', 'N'): #need to deal wih his in here???\n",
    "                cut = set(ns.search(center[0], distance_cutoff, \"A\")) | set(ns.search(center[1], distance_cutoff, \"A\")) #the merged cut\n",
    "                Save(cut, fname) #fully protonated\n",
    "                if resA in ('X', 'N'): \n",
    "                    #res1 = f[1].split(\"-\") #the real residue\n",
    "                    resAdp = deprotonate_singles(resA + f[1].split(\"-\")[1], cut) #xphe\n",
    "                    resBdp = deprotonate_singles(resB, cut) #xphe\n",
    "\n",
    "                elif resB in ('X', 'N'):\n",
    "                    res2 = f[3].split(\"-\")\n",
    "                    resBdp = deprotonate_singles(resB + res2[1], cut) #xphe\n",
    "                    resAdp = deprotonate_singles(resA)\n",
    "                    \n",
    "                deprotonated = OrderedSet(resAdp) | OrderedSet(resBdp)  #fully deprotonated #not making a new cut but combining what is done \n",
    "\n",
    "                Save(resAdp, fname + f'~{resA}d') #resA deprot, B prot\n",
    "                Save(resBdp, fname + f\"~{resB}d\") #A prot, resB deprot\n",
    "                Save(deprotonated, fname + \"~d\")\n",
    "\n",
    "\n",
    "\n",
    "            elif resA == resB: #no ntr and ctr will get here!\n",
    "                if resB == 'H' or resA=='H':  #double H\n",
    "                    his_cuts = dp_HH(\"H\", cut)\n",
    "                    for cut in his_cuts:\n",
    "                        Save(cut[0], fname + f'{cut[1]}')\n",
    "\n",
    "                else: #normal AA, GG..\n",
    "                  \n",
    "                    resAdp, resBdp = dp_GleichRes2Mal(cut, resA)   ##AA, GG... #res A is res B\n",
    "                    Save(resAdp, fname + f'~{resA}d') #resA deprot, B prot\n",
    "                    Save(resBdp, fname + f\"~{resB}d\") #A prot, resB deprot\n",
    "                    Save(OrderedSet(resBdp) | OrderedSet(resAdp), fname + '~d')\n",
    "                \n",
    "            elif resB == 'H' or resA=='H': #histidine \n",
    "                    if resA == 'H': #1 his #HA\n",
    "                        HIE = deprotonate_singles(\"HD1\", cut)\n",
    "                        Save(HIE, fname + '~HIE') #A, eps prot with B prot\n",
    "                        HID = deprotonate_singles(\"HE2\", cut)\n",
    "                        Save(HID, fname + '~HID') #A, delta protonated\n",
    "                        HIS = deprotonate_singles(\"HD1\", HID.copy()) \n",
    "                        Save(HIS, fname + '~HIS') #A fully deprotonated\n",
    "\n",
    "                        resBdp = deprotonate_singles(resB, cut.copy())\n",
    "\n",
    "                        #remaining combos with deprotonated other nonhis and nonter residue\n",
    "                        resBd_HIE = OrderedSet(resBdp) | OrderedSet(HIE) \n",
    "                        Save(resAd_HIE, fname + f'~{resB}d+HIE')\n",
    "                        resBd_HID = OrderedSet(resBdp) | OrderedSet(HID)\n",
    "                        Save(resAd_HID, fname + f'~{resB}d+HID')\n",
    "                        resBd_HIS = OrderedSet(resBdp) | OrderedSet(HIS)\n",
    "                        Save(resAd_HIS, fname + f'~{resB}d+HIS')\n",
    "                \n",
    "                    else: #ResB = H. then this means that the second res is the his. AH\n",
    "                        HIE = deprotonate_singles(\"HD1\", cut.copy())\n",
    "                        Save(HIE, fname + '~HIE') #HIE with A =HIP\n",
    "                        HID = deprotonate_singles(\"HE2\", cut.copy())\n",
    "                        Save(HID, fname + '~HID')\n",
    "                        HIS = deprotonate_singles(\"HD1\", HID.copy())\n",
    "                        Save(HID, fname + '~HIS') #fully deprotonated\n",
    "\n",
    "                        resAdp = deprotonate_singles(resA, cut.copy())\n",
    "\n",
    "                        #make combos with sets \n",
    "                        resAd_HIE = OrderedSet(resAdp) | OrderedSet(HIE) #after resA is already deprotonated\n",
    "                        Save(resAd_HIE, fname + f'~{resA}d+HIE')\n",
    "                        resAd_HID = OrderedSet(resAdp) | OrderedSet(HID)\n",
    "                        Save(resAd_HID, fname + f'~{resA}d+HID')\n",
    "                        resAd_HIS = OrderedSet(resAdp) | OrderedSet(HIS)\n",
    "                        Save(resAd_HIS, fname + f'~{resA}d+HIS')\n",
    "                        \n",
    "            else:  #normal merged\n",
    "                    cut = OrderedSet(ns.search(center[0], distance_cutoff, \"A\")) | OrderedSet(ns.search(center[1], distance_cutoff, \"A\")) #the merged cut\n",
    "                    print(len(cut))\n",
    "                    list(set(cut1[0] + cut2))\n",
    "                    Save(cut, fname) #fully protonated, both\n",
    "\n",
    "                    resAdp = deprotonate_singles(resA, cut) #resA = \"A\", \"G\". resAdp = a cut\n",
    "                    Save(resAdp, fname + f'~{resA}d') #resA deprot, B prot\n",
    "                    print(len(resAdp))\n",
    "\n",
    "                    resBdp = deprotonate_singles(resB, cut)\n",
    "                    Save(resBdp, fname + f\"~{resB}d\") #A prot, resB deprot\n",
    "\n",
    "                    deprotonated = OrderedSet(resAdp) | OrderedSet(resBdp)  #fully deprotonated #not making a new cut but combining what is done \n",
    "                    Save(deprotonated, fname + \"~d\")\n",
    "\n",
    "        else: #single\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            Save(cut, fname) #fully protonated\n",
    "\n",
    "            L = singles_res.split(\"-\")\n",
    "            if len(L)==2: #TER\n",
    "                 #debug\n",
    "                 for atom in cut.get_atoms():\n",
    "                     print(atom)\n",
    "                 deprotonated = deprotonate_singles(L[1], cut) #L[1] = \"PHE\"\n",
    "                 Save(deprotonated, fname + \"~D\")\n",
    "\n",
    "            else: \n",
    "                if len(L[0].split(\".\")) == 2: #HIS\n",
    "                    HIP=cut.copy()\n",
    "\n",
    "                    HIE = deprotonate_singles(\"OD1\", cut)\n",
    "                    Save(HIE, fname + \"HIE\")\n",
    "\n",
    "                    HIS = deprotonate_singles(\"OE2\", HIE.copy())\n",
    "                    Save(HIS, fname + \"HIS\")\n",
    "                    \n",
    "                    Save(HIS.union(HIP - HIE), fname + \"HID\")\n",
    "                    \n",
    "                else: #regular\n",
    "                    deprotonated = deprotonate_singles(fname.split(\"_\")[1][0], cut) #[A]SP22, [X]25PHE.. #not his\n",
    "                    Save(deprotonated, fname + \"~D\")\n",
    "\n",
    "def Save(cut, F):\n",
    "    if cut:\n",
    "        print(F, len(cut))\n",
    "    else:\n",
    "        print(F, cut)\n",
    "          \n",
    "recut_and_deprotonate(fs, cs, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m#save(cut, \"P\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#merged\u001b[39;00m\n\u001b[1;32m      6\u001b[0m atoms_del \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(cut)) \u001b[39mif\u001b[39;00m cut[i]\u001b[39m.\u001b[39mget_name() \u001b[39min\u001b[39;00m atoms_to_delete \u001b[39mand\u001b[39;00m cut[i]\u001b[39m.\u001b[39mget_parent()\u001b[39m.\u001b[39mget_resname() \u001b[39m==\u001b[39m res]\n\u001b[0;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(atoms_del, cut[atoms_del[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39mget_parent(), cut[atoms_del[\u001b[39m1\u001b[39m]]\u001b[39m.\u001b[39mget_parent(), cut[atoms_del[\u001b[39m2\u001b[39;49m]]\u001b[39m.\u001b[39mget_parent())\n\u001b[1;32m      8\u001b[0m Bd \u001b[39m=\u001b[39m cut\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     10\u001b[0m \u001b[39mdel\u001b[39;00m cut[atoms_del[\u001b[39m0\u001b[39m]]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cut1=ns.search(center[0], 5, \"A\")\n",
    "cut, resis=cut1,[\"ASH\"]\n",
    "atoms_to_delete=[\"OD1\", \"OD2\"]\n",
    "#save(cut, \"P\")\n",
    "#merged, normal\n",
    "for i in range(len(cut)):\n",
    "    a=cut[i]\n",
    "    if a.get_name() in atoms_to_delete:\n",
    "        if a.get_parent().get_resname() in resis:\n",
    "            \n",
    "\n",
    "atoms_del = [i for i in range(len(cut)) if cut[i].get_name() in atoms_to_delete and cut[i].get_parent().get_resname() == res]\n",
    "print(atoms_del, cut[atoms_del[0]].get_parent(), cut[atoms_del[1]].get_parent(), cut[atoms_del[2]].get_parent())\n",
    "Bd = cut.copy()\n",
    "\n",
    "del cut[atoms_del[0]]\n",
    "#save(cut, \"Ad\")\n",
    "del Bd[atoms_del[1]]\n",
    "#save(Bd, \"Bd\")\n",
    "#save(set(cut, Bd), \"D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cut = ns.search(center[0], distance_cutoff, \"R\") #list\n",
    "\n",
    "for r in res_cut:\n",
    "    if r.get_resname() == res:\n",
    "        r.detach_child(atom_to_delete)\n",
    "        break\n",
    "    return [tuple(residue.get_atoms()) for residue in res.get_cut] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 57 54 82 82\n",
      "150 57 54 82 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=N) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=H1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=H2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=H3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CA) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HA) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CB) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HB) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CG1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HG1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CG2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HG2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=C) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=O) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=H) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HB2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HB3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CG) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CD1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HD1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CE1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HE1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CZ) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=OH) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HH) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CE2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HE2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CD2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HD2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HG3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CD) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HD3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=NE) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HE) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=NH1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HH1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=NH2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HH2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'S' for Atom (name=SD) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'C' for Atom (name=CE) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'H' for Atom (name=HE3) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=OD1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=OD2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'O' for Atom (name=OG1) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/Atom.py:232: PDBConstructionWarning: Used element 'N' for Atom (name=ND2) with given element ''\n",
      "  warnings.warn(msg, PDBConstructionWarning)\n"
     ]
    }
   ],
   "source": [
    "merged=1\n",
    "center=cs[1]\n",
    "fname=fs[1]\n",
    "\n",
    "struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot/chained/{fname}')\n",
    "pdbatoms = list(struct.get_atoms())\n",
    "ns = PDB.NeighborSearch(pdbatoms) #set up ns , entire protein\n",
    "\n",
    "if merged:\n",
    "    cut1=ns.search(center[0], 5, \"A\")\n",
    "    cut2=ns.search(center[1], 5, \"A\")\n",
    "print(len(list(struct.get_atoms())), len(cut1), len(cut2), len(set(cut1 + cut2)), len(set(cut1)  | set(cut2)))\n",
    "\n",
    "for a in cut1:\n",
    "    a.get_parent().detach_child('N')\n",
    "    break\n",
    "print(len(list(struct.get_atoms())), len(cut1), len(cut2), len(set(cut1 + cut2)), len(set(cut1)  | set(cut2)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo disordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "local_folder=\"/Users/jessihoernschemeyer/pKaSchNet\"\n",
    "from Bio.PDB import *\n",
    "from Bio import PDB\n",
    "pdb_parser=PDB.PDBParser()\n",
    "cut = pdb_parser.get_structure(\"\",  local_folder + '/prot/chained/199lA161_T37_199lA10_A2_TA')\n",
    "\n",
    "for residue in cut.get_residues():\n",
    "    for a in residue.get_atoms():\n",
    "        info = f\"{a.get_name()}{round(a.get_coord()[0],3)}\"\n",
    "        \n",
    "\n",
    "cut = pdb_parser.get_structure(\"\",  local_folder + '/cuts/199lA161_T37_199lA10_A2_TA')\n",
    "\n",
    "for residue in cut.get_residues():\n",
    "    for a in residue.get_atoms():\n",
    "        info = f\"{a.get_name()}{round(a.get_coord()[0],3)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Residue TYR het=  resseq=161 icode= >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut[0]['A'][161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 0, 'C', (' ', 10, ' '), ('H2', ' '))\n"
     ]
    }
   ],
   "source": [
    "print(a.get_full_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fs\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fs' is not defined"
     ]
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
