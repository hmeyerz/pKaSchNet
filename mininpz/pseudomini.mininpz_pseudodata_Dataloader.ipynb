{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed size: 21 bytes\n",
      "data loader:\n",
      "zs: [tensor([[6, 7]], dtype=torch.int32), tensor([[8]], dtype=torch.int32)]\n",
      "xs: [tensor([[[0.0000, 1.0000, 2.0000],\n",
      "         [3.0000, 4.0000, 5.0000]]]), tensor([[[6.0000, 7.0000, 8.0000]]])]\n",
      "ys: [tensor([0.5000]), tensor([1.2000])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import zlib\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1) Compression pipeline (once, offline)\n",
    "# ---------------------------------------\n",
    "coords_list = [\n",
    "    np.array([[0.0, 1.0, 2.0],\n",
    "              [3.0, 4.0, 5.0]], dtype=np.float32),\n",
    "    np.array([[6.0, 7.0, 8.0]],        dtype=np.float32)\n",
    "]\n",
    "elm_lists = [\n",
    "    np.array([6, 7], dtype=np.uint8),\n",
    "    np.array([8],    dtype=np.uint8)\n",
    "]\n",
    "segment_ids        = np.array(['33A3','67B0'], dtype='S4')\n",
    "segment_lengths    = np.array([2,1],         dtype=np.uint16)\n",
    "per_segment_scalars= np.array([0.5,1.2],    dtype=np.float32)\n",
    "\n",
    "# Flatten\n",
    "coords_flat = np.vstack(coords_list)    # (3,3)\n",
    "elms_flat   = np.concatenate(elm_lists)# (3,)\n",
    "\n",
    "# Quantize & delta\n",
    "precision = 0.001\n",
    "quantized = np.round(coords_flat/precision).astype(np.int32)\n",
    "deltas    = quantized.copy()\n",
    "deltas[1:] -= quantized[:-1]\n",
    "\n",
    "# int16 + serialize\n",
    "deltas16   = deltas.astype(np.int16)\n",
    "coord_bytes= deltas16.tobytes()\n",
    "elm_bytes  = elms_flat.tobytes()\n",
    "\n",
    "# Compress\n",
    "blob       = coord_bytes + elm_bytes\n",
    "compressed = zlib.compress(blob, level=9)\n",
    "with open('pseudomini.coords_elms.zlib','wb') as f:\n",
    "    f.write(compressed)\n",
    "\n",
    "# Sidecars\n",
    "np.save('pseudomini.segment_ids.npy',         segment_ids)\n",
    "np.save('pseudomini.segment_lengths.npy',     segment_lengths)\n",
    "np.save('pseudomini.per_segment_scalars.npy', per_segment_scalars)\n",
    "\n",
    "print(\"Compressed size:\", len(compressed), \"bytes\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2) Dataset & DataLoader definitions\n",
    "# ---------------------------------------\n",
    "class CompressedCoordsDataset(Dataset):\n",
    "    def __init__(self, base_dir, precision=0.001, pin_memory=False):\n",
    "        self.base      = base_dir.rstrip(\"/\") + \"/\"\n",
    "        self.precision = precision\n",
    "        self.pin_memory= pin_memory\n",
    "\n",
    "    def __len__(self):\n",
    "        # In this example, only one sample\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # --- Load metadata ---\n",
    "        #seg_ids  = np.load(self.base + 'segment_ids.npy',         allow_pickle=True).astype(str)\n",
    "        seg_lens = np.load(self.base + 'segment_lengths.npy')     # (M,)\n",
    "        scalars  = np.load(self.base + 'per_segment_scalars.npy') # (M,)\n",
    "\n",
    "        # --- Decompress blob ---\n",
    "        with open(self.base + 'coords_elms.zlib','rb') as f:\n",
    "            comp = f.read()\n",
    "        blob = zlib.decompress(comp)\n",
    "\n",
    "        # --- Split streams ---\n",
    "        N = int(seg_lens.sum())\n",
    "        coord_len = N*3*np.dtype(np.int16).itemsize\n",
    "        elm_len   = N*np.dtype(np.uint8).itemsize\n",
    "\n",
    "        coord_bytes = blob[:coord_len]\n",
    "        elm_bytes   = blob[coord_len:coord_len+elm_len]\n",
    "\n",
    "        # --- Reconstruct coords ---\n",
    "        deltas_rec  = np.frombuffer(coord_bytes, dtype=np.int16).reshape(N,3).astype(np.int32)\n",
    "        quant_rec   = np.cumsum(deltas_rec, axis=0)\n",
    "        coords_flat = quant_rec.astype(np.float32) * self.precision  # (N,3)\n",
    "\n",
    "        # --- Reconstruct elements ---\n",
    "        elms_flat   = np.frombuffer(elm_bytes, dtype=np.uint8)       # (N,)\n",
    "\n",
    "        # --- Split by segment_lengths ---\n",
    "        offsets     = np.concatenate([[0], np.cumsum(seg_lens)]).astype(int)\n",
    "        coords_list = [coords_flat[offsets[i]:offsets[i+1]] for i in range(len(seg_lens))]\n",
    "        elms_list   = [elms_flat[  offsets[i]:offsets[i+1]] for i in range(len(seg_lens))]\n",
    "\n",
    "        # --- To torch tensors ---\n",
    "        zs = [torch.tensor(e, dtype=torch.int32).pin_memory() if self.pin_memory \n",
    "              else torch.tensor(e, dtype=torch.int32) for e in elms_list]\n",
    "        xs = [torch.tensor(x, dtype=torch.float32).pin_memory() if self.pin_memory \n",
    "              else torch.tensor(x, dtype=torch.float32) for x in coords_list]\n",
    "        ys = [torch.tensor(s, dtype=torch.float32).pin_memory() if self.pin_memory \n",
    "              else torch.tensor(s, dtype=torch.float32) for s in scalars]\n",
    "\n",
    "        return zs, xs, ys\n",
    "\n",
    "# Helper to get a DataLoader\n",
    "def get_loader(base_dir, batch_size=1, pin_memory=False):\n",
    "    ds = CompressedCoordsDataset(base_dir, pin_memory=pin_memory)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3) Example usage\n",
    "# ---------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    loader = get_loader(\".\", batch_size=1, pin_memory=False)\n",
    "    for zs, xs, ys in loader:\n",
    "        print(\"data loader:\")\n",
    "        print(\"zs:\", zs)\n",
    "        print(\"xs:\", xs)\n",
    "        print(\"ys:\", ys)\n",
    "        break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.2s to execute on shitty 2015 macbook pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
