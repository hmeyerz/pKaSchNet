{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "from Bio import PDB\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from ase import Atoms, Atom\n",
    "import dask.dataframe as dd\n",
    "from ordered_set import OrderedSet\n",
    "import os\n",
    "\n",
    "\n",
    "local_folder=\"/Users/jessihoernschemeyer/pKaSchNet\"\n",
    "pkPDB_CSV = f\"{local_folder}/pkas.csv\"\n",
    "def read_database(path):\n",
    "    \"\"\"csv --> dask df\"\"\"\n",
    "    #make the dask data frame from the PYPKA csv\n",
    "    dk=dd.read_csv(pkPDB_CSV, delimiter=';', na_filter=False, dtype={'idcode':'category', \n",
    "                                                                    'residue_number':'uint8',\n",
    "                                                                    'pk': 'float32',\n",
    "                                                                    'residue_name':'category',\n",
    "                                                                    'chain': 'category',\n",
    "                                                                    'residue_name': 'category'\n",
    "                                                                    })\n",
    "                                                            \n",
    "    dk=dk.rename(columns={'idcode': 'PDB ID', 'residue_number': 'Res ID', 'residue_name': 'Res Name', 'residue_number': 'Res ID', 'pk': 'pKa', 'chain' : 'Chain'}) #rename columns to match df from pkad \n",
    "    dk=dk.sort_values(['PDB ID', 'Res ID'], ascending=[True, True]) \n",
    "    dk=dk.compute() \n",
    "    dff = dk.reset_index() \n",
    "\n",
    "    return dff\n",
    "\n",
    "def check_atoms_protein(structure, struc_atoms): \n",
    "    \"\"\"internal function. checks every atom in the entire protein for metals, undesirables\"\"\"\n",
    "    pdb_residues=[]\n",
    "    for atom in struc_atoms: \n",
    "        resname, atomid=atom.get_parent().get_resname(), atom.get_full_id()[2:]\n",
    "        element=atomid[2][0]\n",
    "\n",
    "        if element in [\"MG\", \"MN\", \"FE\", \"CO\", \"NI\", \"CU\", \"ZN\"]:\n",
    "            return 0,0#print(f\"{element} present, pdb skipped\")\n",
    "        \n",
    "        else:\n",
    "            #atomid=atom.get_full_id() #('', 0, 'B', (' ', 177, ' '), ('OH', ' '))\n",
    "            if atomid[1][0] not in [' ']:\n",
    "                if element == 'S': #check 4 hetero sulfur, exclude.\n",
    "                    print(f\"{atomid}, hetero sulfur. pdb skipped \")\n",
    "                    return 0,0\n",
    "                \n",
    "                if element in ['CA', 'CL', 'K', 'NA']: #other salt\n",
    "                    for res in structure.get_residues():\n",
    "                        if resname in [\"GLU\", \"HIS\", \"ASP\", \"ARG\", \"TYR\", \"CYS\", \"LYS\"]: #if the other salt is part of the residue (<3Ã¥ from geometric center), delete atom from residue\n",
    "                            if np.linalg.norm(res.center_of_mass(geometric=True) - atom.get_coord()) < 3:\n",
    "                                atom.get_parent().detach_child(atom.get_id()) #print(f\"salt {atom} deleted, {d} from {res}\")\n",
    "\n",
    "        pdb_residues.append(atomid[0] + str(atomid[1][1]))\n",
    "    \n",
    "    return structure, set(pdb_residues) #('', 0, 'B', ('W', 371, ' '), ('O', ' '))\n",
    "\n",
    "def atoms_to_structure(cutout, filename): \n",
    "    \"\"\"Internal function (or not), cutout --> save to harddrive\n",
    "    input: cutout: list of biopython atom objects (NOT ASE)\"\"\"\n",
    "    chain_dict = {}\n",
    "\n",
    "    structure = Structure.Structure(filename)\n",
    "    model = Model.Model(0)\n",
    "    structure.add(model)\n",
    "\n",
    "    for atom in cutout:\n",
    "        res = atom.get_parent()\n",
    "        res_id, resname, chain_id = res.get_id(), res.get_resname(), res.get_full_id()[2]\n",
    "\n",
    "        #make acidic GLH and ASH straight here. so change their name before saving \n",
    "        if resname == \"GLU\":\n",
    "            resname=\"GLH\"\n",
    "            \n",
    "        if resname==\"ASP\":\n",
    "            resname=\"ASH\"\n",
    "\n",
    "        if resname==\"HIS\":\n",
    "            resname=\"HIP\"\n",
    "            \n",
    "        \n",
    "        if chain_id not in chain_dict:\n",
    "            chain = Chain.Chain(chain_id) #make new chain\n",
    "            chain_dict[chain_id] = chain\n",
    "            model.add(chain) #add it\n",
    "\n",
    "        else:\n",
    "            chain = chain_dict[chain_id]\n",
    "\n",
    "        if res_id in [res.get_id() for res in chain.get_residues()]:\n",
    "            residue = [res for res in chain.get_residues() if res.get_id() == res_id][0] \n",
    "        else:\n",
    "            residue = Residue.Residue(res_id, resname, '') #make new res\n",
    "            chain.add(residue)\n",
    "\n",
    "        residue.add(atom)\n",
    "    # save the pdb\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(f\"{filename}.pdb\")\n",
    "\n",
    "#dask_df = read_database(local_folder + pkPDB_CSV)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: #TODO: THIS EXCLUDES NTR AND CTR! (navigating pypka error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dont forget removed disordered at site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdb_parser, pdbs = PDB.PDBParser(), list(OrderedSet(list(dask_df[\"PDB ID\"])))\n",
    "def generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter, fname):\n",
    "    \"\"\"Residue wise resolurion. ns is neighbor search set up for the entire protein, residue is the single data point / 1 of several residues in a pdb & in pypka.\n",
    "    input is one residue. output is the cutout around its titratable site, both of which can be plural e.g. his, mb asp and glu.\n",
    "    residue (biopython Residue object): a single protonable residue \"\"\"\n",
    "    protonatable_sites = [\"OE2\", \"SG\", \"NZ\", \"OD2\", \"NE2\", \"ND1\", \"OH\"]\n",
    "    cuts = []\n",
    "    for atom in residue.get_atoms():\n",
    "        if atom.is_disordered(): \n",
    "            atomN = str(atom)[16:-1]\n",
    "            if atomN in protonatable_sites:\n",
    "                return #dont make cutout of titratable site is disordered\n",
    "        atomN = str(atom)[6:-1]#, residue.get_resname()[0]\n",
    "        \n",
    "        if atomN == protonatable_sites[0]: #glu\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, residue.get_resname()[0], cut)) #counter is id!\n",
    "            \n",
    "            continue\n",
    "        if atomN  == protonatable_sites[1]: #CYS\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, residue.get_resname()[0], cut))\n",
    "            return cuts\n",
    "        if atomN == protonatable_sites[2]: #LYS\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, residue.get_resname()[0], cut))\n",
    "            return cuts\n",
    "        if atomN ==protonatable_sites[3]: #ASP\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, residue.get_resname()[0], cut))\n",
    "            continue\n",
    "########HIS \n",
    "        if atomN == protonatable_sites[4]: #his eps #TODO: maybe one always comes first in biopython?\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((str(counter) + 'E', center, residue.get_resname()[0], cut))\n",
    "            continue\n",
    "        if atomN == protonatable_sites[5]: #HIS #TODO\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((str(counter) + 'D', center, residue.get_resname()[0], cut))\n",
    "            continue\n",
    "\n",
    "        if atomN == protonatable_sites[6]: #TYR\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, 6, \"A\")\n",
    "            cuts.append((counter, center, residue.get_resname()[0], cut))\n",
    "            return cuts\n",
    "\n",
    "    return cuts #plural because of sites with multiple sites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure exists: 'PDB/pdb194l.ent' \n",
      "except\n",
      "except\n",
      "[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "if none yet frozenset({2, 4})\n",
      "making frozenset({2, 4})\n",
      "null frozenset({2, 4})\n",
      "making frozenset({5, 14})\n",
      "making frozenset({17, 6})\n",
      "making frozenset({8, 10})\n",
      "null frozenset({8, 10})\n",
      "making frozenset({11, 12})\n",
      "null frozenset({11, 12})\n",
      "null frozenset({5, 14})\n",
      "null frozenset({17, 6})\n",
      "[2, 8, 10, 12, 15]\n",
      "LA\n",
      "TL\n",
      "TL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jl/8mbcps0x1jv9616svy8_9vy80000gn/T/ipykernel_4659/1373970189.py:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  closest_cutout_i = int(np.where((distances[:,counter])==np.min(a_residues_distance_array))[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA\n",
      "TA\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[199], line 143\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m fnames,[c[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m cutouts_apdb]\n\u001b[1;32m    141\u001b[0m \u001b[39m#os.remove(f\"{local_folder}/PDB/pdb{pdbname}.ent\")\"\"\"\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m fs, cs \u001b[39m=\u001b[39m get_cutout(dask_df, \u001b[39m8\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[199], line 126\u001b[0m, in \u001b[0;36mget_cutout\u001b[0;34m(dask_df, distance_cutoff)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mprint\u001b[39m(pairid)\n\u001b[1;32m    124\u001b[0m \u001b[39m#fnames.index()\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m#Fname=\"\".join([fname,'~',str(pairid[0]),\"_\",str(pairid[1])])\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m Fname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([fname,\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m,fnames[greaterN_pair_i[counter]],\u001b[39m\"\u001b[39m\u001b[39m~\u001b[39m\u001b[39m\"\u001b[39m,pairid])\n\u001b[1;32m    127\u001b[0m \u001b[39m#del greaterN_pair_i[0]\u001b[39;00m\n\u001b[1;32m    128\u001b[0m fnames[fnames\u001b[39m.\u001b[39mindex(fname)] \u001b[39m=\u001b[39m Fname\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "def merge_or_not_cutouts(cutouts_apdb, distance_cutoff): #TODO: reduce dtypes #PDB WISE!\n",
    "    \"\"\"\n",
    "    in: all of the cutouts from the pdb. returns the merged or solo cutout for each input residue of cutouts_apdb. len in = len out\"\"\"\n",
    "    #protein wise ..\n",
    "    dp_ids,centers,cuts, Ds_lite, counter, cutouts, cuts_dict,resnames,redunant_merged_is =[],[],[],[], 0, [], {},[],[]\n",
    "    for site in cutouts_apdb:\n",
    "        dp_ids.append(site[0]) #1,2,3,4,5,6,7,8,9E,9D,... #is counter from generate_around_prot_site\n",
    "        centers.append(site[1]) \n",
    "        resnames.append(site[2])\n",
    "        cuts.append(site[3])\n",
    "        \n",
    "\n",
    "    num_residues=len(centers)\n",
    "    distances = np.zeros((num_residues, num_residues))\n",
    "    print(dp_ids)\n",
    "    for i in range(num_residues): #residue wise..\n",
    "        for j in range(i + 1, num_residues):\n",
    "            distance = np.linalg.norm(centers[i] - centers[j]).astype(np.float32)\n",
    "            if distance < distance_cutoff:\n",
    "                distances[i, j] = distance\n",
    "                distances[j, i] = distance\n",
    "\n",
    "    for i in range(len(distances)):\n",
    "        Ds_lite.append(np.array([distances[:,i][j] for j in range(num_residues) if distances[:,i][j] != 0])) #goes column wise and just gets the nonzeros\n",
    "    \n",
    "#residuewise.... \n",
    "    for a_residues_distance_array in Ds_lite: #ds lite is nontrivial distances\n",
    "        if a_residues_distance_array.size != 0: #if not empty\n",
    "            closest_cutout_i = int(np.where((distances[:,counter])==np.min(a_residues_distance_array))[0])\n",
    "            pair_i = frozenset((dp_ids[counter],dp_ids[closest_cutout_i]))#key #frozen set is immutable thus can be used as a dict key #also order doesnt matter, 2-1=1-2\n",
    "            #print(\"gonna be merged\", pair_i) #LIST(ORDEREDSET) AUTOMATICALLY MAKES THEM ASCENDING!!\n",
    "            if not bool(cuts_dict.keys()): #if there are not any pairs yet generated, make some..\n",
    "                print(\"if none yet\", pair_i)\n",
    "                if pair_i not in cuts_dict.keys(): #if not in merged dict, make it\n",
    "                    closest_cutout = cuts[closest_cutout_i]\n",
    "                    print(\"making\", pair_i)\n",
    "                    cutout = (list(set(cuts[counter] + closest_cutout)),resnames[counter] + resnames[closest_cutout_i])\n",
    "                    cuts_dict[pair_i] = cutout[0]\n",
    "                else: #null\n",
    "                    #print(pair_i)\n",
    "                    print(\"null, pair_i\")\n",
    "                    cutout = 0 #\"cutout = dict entry\n",
    "                    redunant_merged_is.append(counter)\n",
    "            else:\n",
    "                if pair_i not in cuts_dict.keys(): #if not in merged dict, make it\n",
    "                    closest_cutout = cuts[closest_cutout_i]\n",
    "                    print(\"making\", pair_i)\n",
    "         \n",
    "                    cutout = (list(set(cuts[counter] + closest_cutout)),resnames[counter] + resnames[closest_cutout_i])\n",
    "                    cuts_dict[pair_i] = cutout[0]\n",
    "                else: #null\n",
    "                    print(\"null\", pair_i)\n",
    "                    cutout = 0\n",
    "                    redunant_merged_is.append(counter)\n",
    "            counter += 1 #the counter goes up each time a \n",
    "\n",
    "        else: #solo cutout\n",
    "            cutout = cuts[counter]\n",
    "            counter += 1\n",
    "        cutouts.append(cutout)\n",
    "    #print(list(cuts_dict.keys()))\n",
    "    if len(cutouts) != len(dp_ids):\n",
    "        return #this will make an exception if something went wrong\n",
    "\n",
    "    return cutouts,redunant_merged_is #merged or solo\n",
    "\n",
    "def get_cutout(dask_df, distance_cutoff): #\"PARENT\" FUNCTION\n",
    "    \"\"\"for each protein in dask_df (the entire PYPKA database), it iterates residue wise through the 121,294 proteins in PYPKA database and downloads\n",
    "    the structure from RCSB with biopython. Then, it checks and skips the structure if metals & hetero sulfurs are present, and deletes non-sulfur\n",
    "    salts from titratable residues.\n",
    "    Then, for each structure residue represented in PYPKA, generates a cutout for each residue, appends the structure to cutouts_apdb\"\"\"\n",
    "    pdbname=\"11as\"  #for now\n",
    "    cutouts_apdb, all_tit_res =[],[]\n",
    "    for i in range(18,19): #will equal len of set of pdbs in pypka, == 121294 \n",
    "        cutouts_apdb, fnames, cutouts_1_datapoint, counter, pdbname =[],[], [],0, pdbs[i]\n",
    "        Structure = pdb_parser.get_structure(\"\",  PDBList().retrieve_pdb_file(str.lower(pdbname),obsolete=False, pdir='PDB',file_format = 'pdb'))\n",
    "        structure, pdb_residues = check_atoms_protein(Structure, Structure.get_atoms())\n",
    "        if structure==0: #skip entire pdb and all its entries in pypka db if there are undesirables in pdb\n",
    "            continue\n",
    "\n",
    "        ns = PDB.NeighborSearch(list(structure.get_atoms())) #set up ns , entire protein\n",
    "        pdb_df = dask_df[dask_df.iloc[:, 1] == pdbname].drop(columns = [\"PDB ID\", \"pKa\"]) #make a subdf containing only residue entries which are in PYPKA (dask_df) \n",
    "        dp_ids=[]\n",
    "        for j in range(len(pdb_df)):  #go through each residue in a pdb #each j is a datapoint!\n",
    "            chain, res_id =pdb_df.iloc[j]['Chain'], int(pdb_df.iloc[j]['Res ID'])\n",
    "            \n",
    "            try: \n",
    "                residue=structure[0][chain][res_id] #a datapoint #TODO: make ID?\n",
    "                pypka_resname, PDBresname = pdb_df.iloc[j]['Res Name'], residue.get_resname() #pypka error\n",
    "\n",
    "                if pypka_resname not in [PDBresname]: #ACHTUNG! this navigates the pyka error. #TODO: mail him #TODO: THIS EXCLUDES NTR AND CTR!\n",
    "                    continue\n",
    "\n",
    "                #generate the cutout solo cutouts\n",
    "                cutouts_1_datapoint=generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter,  f\"{pdbname}_{chain}_{res_id}_{PDBresname}\") #can be multiple\n",
    "                #returns empty if disordered\n",
    "\n",
    "                cutouts_apdb.append(*cutouts_1_datapoint) #append each residue/data point cutouts here #it will error here if disordered\n",
    "                fnames.append(f\"{pdbname}_{PDBresname[0].lower()}_{chain}_{res_id}-{cutouts_1_datapoint[0][0]}\") #{cutouts_1_datapoint[0][0] is the\n",
    "\n",
    "                all_tit_res.append(chain + str(res_id))\n",
    "                #print(f\"{pdbname}_{res_id}_{chain}_{PDBresname[0]}-{cutouts_1_datapoint[0][0]}\")\n",
    "                counter+=1 #counter doesnt reach here if it fails\n",
    "\n",
    "            except: \n",
    "                counter += 1\n",
    "\n",
    "                #print(f\"{pdbname}_{res_id}_{chain}_{PDBresname}\")\n",
    "                print(\"except\") #delete\n",
    "                pass #means pypka res not found in PDB\n",
    "\n",
    "        #os.remove(f\"{local_folder}/PDB/pdb{pdbname}.ent\")  \n",
    "        if cutouts_apdb:\n",
    "            merged_and_solos, greaterN_pair_i =merge_or_not_cutouts(cutouts_apdb, distance_cutoff)#make a merged cutout or not based off radius criteria\n",
    "            #print(merged_and_solos) #!IIS will be generated in ascending order and will always be the the higher cutout# .\n",
    "            counter=0\n",
    "            print(greaterN_pair_i)\n",
    "            for cut, fname in zip(merged_and_solos, fnames[:]):\n",
    "\n",
    "                if type(cut)==tuple: #means it is a merged cutout. second argument is the pairid #it is still 1-to-1 here but ima destroy it\n",
    "                    pairid=cut[1]\n",
    "                    print(pairid)\n",
    "                    #fnames.index()\n",
    "                    #Fname=\"\".join([fname,'~',str(pairid[0]),\"_\",str(pairid[1])])\n",
    "                    print(counter)\n",
    "                    Fname=\"\".join([fname,'+',fnames[greaterN_pair_i[counter]],\"~\",pairid])\n",
    "                    #del greaterN_pair_i[0]\n",
    "                    fnames[fnames.index(fname)] = Fname\n",
    "                    atoms_to_structure(cut[0], Fname) #save as pdb)\n",
    "                    counter += 1\n",
    "                elif cut==0:\n",
    "                    del fnames[fnames.index(fname)]\n",
    "                    continue\n",
    "                else:\n",
    "                    atoms_to_structure(cut, fname) \n",
    "            #lines = str(all_tit_res)[1:-1].strip()\n",
    "            #with open(f\"{pdbname}\", 'w') as file: #save all the residue names \n",
    "                #file.write(lines)\n",
    "\n",
    "    return fnames,[c[1] for c in cutouts_apdb]\n",
    "#os.remove(f\"{local_folder}/PDB/pdb{pdbname}.ent\")\"\"\"\n",
    "\n",
    "fs, cs = get_cutout(dask_df, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['194l_G_A_7-1',\n",
       " '194l_L_A_13-2',\n",
       " '194l_A_A_18-4',\n",
       " '194l_T_A_20-5',\n",
       " '194l_T_A_23-6',\n",
       " '194l_L_A_33-7',\n",
       " '194l_G_A_35-8',\n",
       " '194l_A_A_48-9',\n",
       " '194l_A_A_52-10',\n",
       " '194l_T_A_53-11~194l_A_A_66-12',\n",
       " '194l_A_A_87-13',\n",
       " '194l_L_A_96-14',\n",
       " '194l_L_A_97-15',\n",
       " '194l_A_A_101-16',\n",
       " '194l_L_A_116-17',\n",
       " '194l_A_A_119-18']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['194l_A_7_GLU-1',\n",
       " '194l_A_13_LYS-2',\n",
       " '194l_A_18_ASP-4',\n",
       " '194l_A_20_TYR-5',\n",
       " '194l_A_23_TYR-6',\n",
       " '194l_A_33_LYS-7',\n",
       " '194l_A_35_GLU-8',\n",
       " '194l_A_48_ASP-9',\n",
       " '194l_A_52_ASP-10',\n",
       " '194l_A_53_TYR-11~194l_A_66_ASP-12',\n",
       " '194l_A_66_ASP-12~194l_A_66_ASP-12',\n",
       " '194l_A_87_ASP-13',\n",
       " '194l_A_96_LYS-14',\n",
       " '194l_A_97_LYS-15',\n",
       " '194l_A_101_ASP-16',\n",
       " '194l_A_116_LYS-17',\n",
       " '194l_A_119_ASP-18']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'194l_A_66_ASP-12~11_12'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['194l_A_7_GLU-1',\n",
       " '194l_A_13_LYS-2',\n",
       " '194l_A_18_ASP-4',\n",
       " '194l_A_20_TYR-5',\n",
       " '194l_A_23_TYR-6',\n",
       " '194l_A_33_LYS-7',\n",
       " '194l_A_35_GLU-8',\n",
       " '194l_A_48_ASP-9',\n",
       " '194l_A_52_ASP-10',\n",
       " '194l_A_53_TYR-11~11_12',\n",
       " '194l_A_66_ASP-12~11_12',\n",
       " '194l_A_87_ASP-13',\n",
       " '194l_A_96_LYS-14',\n",
       " '194l_A_97_LYS-15',\n",
       " '194l_A_101_ASP-16',\n",
       " '194l_A_116_LYS-17',\n",
       " '194l_A_119_ASP-18']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATOM      1  NE  ARG A  68      15.618  12.907  25.348  1.00 21.04           N  \n",
      "ATOM      2  NH1 ARG A  68      17.096  12.044  23.798  1.00 21.06           N  \n",
      "ATOM      3  NH2 ARG A  68      15.677  13.774  23.202  1.00 18.29           N  \n",
      "ATOM      4  CD  ARG A  68      16.058  12.007  26.404  1.00 19.61           C  \n",
      "ATOM      5  CG  ARG A  68      15.052  11.889  27.516  1.00 18.53           C  \n",
      "ATOM      6  N   ARG A  68      13.708  10.820  30.066  1.00 16.80           N  \n",
      "ATOM      7  C   ARG A  68      14.893  13.023  30.298  1.00 18.53           C  \n",
      "ATOM      8  CZ  ARG A  68      16.125  12.908  24.114  1.00 21.25           C  \n",
      "ATOM      9  CE2 TYR A  53       9.642  12.506  22.253  1.00 11.57           C  \n",
      "ATOM     10  CE1 TYR A  53       9.296  14.165  23.955  1.00 11.47           C  \n",
      "ATOM     11  CG  TYR A  53       7.722  13.983  22.122  1.00 11.04           C  \n",
      "ATOM     12  OH  TYR A  53      11.165  12.736  24.066  1.00 12.47           O  \n",
      "ATOM     13  CD2 TYR A  53       8.485  12.935  21.608  1.00 10.96           C  \n",
      "ATOM     14  CZ  TYR A  53      10.034  13.129  23.421  1.00 11.20           C  \n",
      "ATOM     15  CD1 TYR A  53       8.144  14.587  23.306  1.00 12.03           C  \n",
      "ATOM     16  CB  TYR A  53       6.500  14.471  21.398  1.00 11.71           C  \n",
      "ATOM     17  OG1 THR A  69      12.434  15.158  29.323  1.00 14.68           O  \n",
      "ATOM     18  CB  THR A  69      12.422  15.444  30.724  1.00 15.92           C  \n",
      "ATOM     19  N   THR A  69      13.858  13.438  31.017  1.00 18.79           N  \n",
      "ATOM     20  CB  THR A  51      12.238  16.014  23.693  1.00 11.16           C  \n",
      "ATOM     21  O   THR A  51       9.516  17.404  24.623  1.00 10.41           O  \n",
      "ATOM     22  CG2 THR A  51      12.045  15.770  22.203  1.00 12.54           C  \n",
      "ATOM     23  N   THR A  51      12.015  17.662  25.520  1.00 11.04           N  \n",
      "ATOM     24  CA  THR A  51      11.838  17.459  24.090  1.00 10.50           C  \n",
      "ATOM     25  C   THR A  51      10.372  17.667  23.769  1.00 10.57           C  \n",
      "ATOM     26  OG1 THR A  51      13.619  15.786  24.028  1.00 12.45           O  \n",
      "ATOM     27  CA  CYS A  80       5.804  10.905  24.805  1.00 11.93           C  \n",
      "ATOM     28  SG  CYS A  80       7.186  12.682  26.471  1.00 11.87           S  \n",
      "ATOM     29  CB  CYS A  80       7.077  11.722  24.932  1.00 11.64           C  \n",
      "ATOM     30  CG  ASH A  66      11.344  12.476  27.410  1.00 11.34           C  \n",
      "ATOM     31  N   ASH A  66       9.170  10.823  28.820  1.00 13.58           N  \n",
      "ATOM     32  C   ASH A  66      11.268   9.581  28.499  1.00 15.00           C  \n",
      "ATOM     33  CA  ASH A  66      10.086  10.278  27.823  1.00 13.99           C  \n",
      "ATOM     34  OD1 ASH A  66      11.640  12.488  28.625  1.00 12.29           O  \n",
      "ATOM     35  OD2 ASH A  66      11.672  13.406  26.643  1.00 12.11           O  \n",
      "ATOM     36  O   ASH A  66      12.175   9.085  27.839  1.00 15.97           O  \n",
      "ATOM     37  CB  ASH A  66      10.545  11.332  26.805  1.00 13.57           C  \n",
      "ATOM     38  OG  SER A  60      10.499  16.257  27.646  1.00 11.82           O  \n",
      "ATOM     39  CA  SER A  60       8.109  16.435  28.070  1.00 13.08           C  \n",
      "ATOM     40  CB  SER A  60       9.273  15.539  27.642  1.00 12.04           C  \n",
      "ATOM     41  N   ASH A  52      10.102  18.220  22.587  1.00 10.25           N  \n",
      "ATOM     42  O   ASH A  52       9.236  16.917  20.318  1.00 11.42           O  \n",
      "HETATM   43  O   HOH A 132      13.921  14.937  26.553  1.00 12.84           O  \n",
      "HETATM   44  O   HOH A 135       9.655  12.959  30.734  1.00 15.67           O  \n",
      "ATOM     45  CG2 THR A  43      10.285  13.470  18.296  1.00 12.71           C  \n",
      "TER      46      THR A  43                                                       \n",
      "END   \n"
     ]
    }
   ],
   "source": [
    "!cat 194l_A_66_ASP-12~9_10.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['194l_A_7_GLU-0',\n",
       " '194l_A_13_LYS-1',\n",
       " '194l_A_18_ASP-2',\n",
       " '194l_A_20_TYR-3',\n",
       " '194l_A_23_TYR-4',\n",
       " '194l_A_33_LYS-5',\n",
       " '194l_A_35_GLU-6',\n",
       " '194l_A_48_ASP-7',\n",
       " '194l_A_52_ASP-8',\n",
       " '194l_A_53_TYR-9~9_10',\n",
       " '194l_A_66_ASP-10~9_10',\n",
       " '194l_A_87_ASP-11',\n",
       " '194l_A_96_LYS-12',\n",
       " '194l_A_97_LYS-13',\n",
       " '194l_A_101_ASP-14',\n",
       " '194l_A_116_LYS-15',\n",
       " '194l_A_119_ASP-16']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the original file\n",
    "source=local_folder + \"/194l_A_53_TYR-9~9_10.pdb\"\n",
    "\n",
    "# Path to the duplicate file\n",
    "destination=local_folder + \"/194l_A_66_ASP-10~9_10.pdb\"\n",
    "\n",
    "# Copy the file\n",
    "!cp \"{source}\" \"{destination}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "join > +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['194l_A_7_GLU-0',\n",
       " '194l_A_13_LYS-1',\n",
       " '194l_A_18_ASP-2',\n",
       " '194l_A_20_TYR-3',\n",
       " '194l_A_23_TYR-4',\n",
       " '194l_A_33_LYS-5',\n",
       " '194l_A_35_GLU-6',\n",
       " '194l_A_48_ASP-7',\n",
       " '194l_A_52_ASP-8',\n",
       " '194l_A_53_TYR-9910',\n",
       " '194l_A_66_ASP-10910',\n",
       " '194l_A_87_ASP-11',\n",
       " '194l_A_96_LYS-12',\n",
       " '194l_A_97_LYS-13',\n",
       " '194l_A_101_ASP-14',\n",
       " '194l_A_116_LYS-15',\n",
       " '194l_A_119_ASP-16']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure that TIP3p and ff14sb in same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat 194l_A_7_GLU-0.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/prep to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd to search path.\n",
      "-s: Ignoring all leaprc startup files.\n",
      "-f: Source /Users/jessihoernschemeyer/pKaSchNet/ascript.py.\n",
      "\n",
      "Welcome to LEaP!\n",
      "Sourcing: /Users/jessihoernschemeyer/pKaSchNet/ascript.py\n",
      "----- Source: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.protein.ff14SB\n",
      "----- Source of /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.protein.ff14SB done\n",
      "Log file: ./leap.log\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/parm10.dat\n",
      "Reading title:\n",
      "PARM99 + frcmod.ff99SB + frcmod.parmbsc0 + OL3 for RNA\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ff14SB\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "ff14SB protein backbone and sidechain parameters\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino12.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/aminoct12.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/aminont12.lib\n",
      "----- Source: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.water.tip3p\n",
      "----- Source of /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.water.tip3p done\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/atomic_ions.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/solvents.lib\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "This is the additional/replacement parameter set for TIP3P water\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ions1lm_126_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Li/Merz ion parameters of monovalent ions for TIP3P water model (12-6 normal usage set)\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ionsjc_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Monovalent ion parameters for Ewald and TIP3P water from Joung & Cheatham JPCB (2008)\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ions234lm_126_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Li/Merz ion parameters of divalent to tetravalent ions for TIP3P water model (12-6 normal usage set)\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\n",
      "Loading PDB file: /Users/jessihoernschemeyer/pKaSchNet/194l_A_7_GLU-0.pdb\n",
      "-- residue 160: duplicate [ CE] atoms (total 2)\n",
      "-- residue 160: duplicate [ NZ] atoms (total 2)\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      "Atom names in each residue should be unique.\n",
      "     (Same-name atoms are handled by using the first\n",
      "      occurrence and by ignoring the rest.\n",
      "      Many instances of duplicate atom names usually come\n",
      "      from alternate conformations in the PDB file.)\n",
      "\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      "One sided connection. Residue (default_name) missing connect1 atom.\n",
      "  Added missing heavy atom: .R<GLH 157>.A<N 1>\n",
      "  Added missing heavy atom: .R<GLH 157>.A<C 15>\n",
      "  Added missing heavy atom: .R<GLH 157>.A<O 16>\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      "One sided connection. Residue (TP3) missing connect0 atom.\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      "One sided connection. Residue (default_name) missing connect1 atom.\n",
      "  Added missing heavy atom: .R<LYS 160>.A<CG 8>\n",
      "  Added missing heavy atom: .R<LYS 160>.A<CB 5>\n",
      "  Added missing heavy atom: .R<LYS 160>.A<CA 3>\n",
      "  Added missing heavy atom: .R<LYS 160>.A<N 1>\n",
      "  Added missing heavy atom: .R<LYS 160>.A<C 21>\n",
      "  Added missing heavy atom: .R<LYS 160>.A<O 22>\n",
      "  Added missing heavy atom: .R<PHE 161>.A<N 1>\n",
      "  Added missing heavy atom: .R<PHE 161>.A<CA 3>\n",
      "  Added missing heavy atom: .R<PHE 161>.A<CB 5>\n",
      "  Added missing heavy atom: .R<PHE 161>.A<C 19>\n",
      "  Added missing heavy atom: .R<PHE 161>.A<CG 8>\n",
      "  Added missing heavy atom: .R<PHE 161>.A<O 20>\n",
      "  Added missing heavy atom: .R<PHE 161>.A<CD1 9>\n",
      "  Added missing heavy atom: .R<PHE 161>.A<CE1 11>\n",
      "  Added missing heavy atom: .R<PHE 161>.A<CZ 13>\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      "One sided connection. Residue (TP3) missing connect0 atom.\n",
      "  total atoms in file: 18\n",
      "  Leap added 57 missing atoms according to residue templates:\n",
      "       18 Heavy\n",
      "       39 H / lone pairs\n",
      "Writing pdb file: /Users/jessihoernschemeyer/pKaSchNet/prot_194l_A_7_GLU-0.pdb\n",
      "\tQuit\n",
      "\n",
      "Exiting LEaP: Errors = 0; Warnings = 5; Notes = 0.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/prep to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd to search path.\n",
      "-s: Ignoring all leaprc startup files.\n",
      "-f: Source /Users/jessihoernschemeyer/pKaSchNet/ascript.py.\n",
      "\n",
      "Welcome to LEaP!\n",
      "Sourcing: /Users/jessihoernschemeyer/pKaSchNet/ascript.py\n",
      "----- Source: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.protein.ff14SB\n",
      "----- Source of /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.protein.ff14SB done\n",
      "Log file: ./leap.log\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/parm10.dat\n",
      "Reading title:\n",
      "PARM99 + frcmod.ff99SB + frcmod.parmbsc0 + OL3 for RNA\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ff14SB\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "ff14SB protein backbone and sidechain parameters\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino12.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/aminoct12.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/aminont12.lib\n",
      "----- Source: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.water.tip3p\n",
      "----- Source of /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.water.tip3p done\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/atomic_ions.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/solvents.lib\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "This is the additional/replacement parameter set for TIP3P water\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ions1lm_126_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Li/Merz ion parameters of monovalent ions for TIP3P water model (12-6 normal usage set)\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ionsjc_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Monovalent ion parameters for Ewald and TIP3P water from Joung & Cheatham JPCB (2008)\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ions234lm_126_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Li/Merz ion parameters of divalent to tetravalent ions for TIP3P water model (12-6 normal usage set)\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\n",
      "Loading PDB file: /Users/jessihoernschemeyer/pKaSchNet/194l_A_13_LYS-1.pdb\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      "One sided connection. Residue (default_name) missing connect1 atom.\n",
      "Created a new atom named: OXT within residue: .R<LEU 188>\n",
      "  Added missing heavy atom: .R<LEU 188>.A<CA 3>\n",
      "  Added missing heavy atom: .R<LEU 188>.A<N 1>\n",
      "  Added missing heavy atom: .R<LEU 188>.A<CB 5>\n",
      "  Added missing heavy atom: .R<LEU 188>.A<CG 8>\n",
      "  Added missing heavy atom: .R<LEU 188>.A<CD1 10>\n",
      "  Added missing heavy atom: .R<LEU 188>.A<CD2 14>\n",
      "  Added missing heavy atom: .R<CLYS 189>.A<CA 3>\n",
      "  Added missing heavy atom: .R<CLYS 189>.A<N 1>\n",
      "  Added missing heavy atom: .R<CLYS 189>.A<C 21>\n",
      "  Added missing heavy atom: .R<CLYS 189>.A<O 22>\n",
      "  Added missing heavy atom: .R<CLYS 189>.A<OXT 23>\n",
      "  total atoms in file: 9\n",
      "  Leap added 37 missing atoms according to residue templates:\n",
      "       11 Heavy\n",
      "       26 H / lone pairs\n",
      "  The file contained 1 atoms not in residue templates\n",
      "Writing pdb file: /Users/jessihoernschemeyer/pKaSchNet/prot_194l_A_13_LYS-1.pdb\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      " Converting C-terminal residue name to PDB format: CLYS -> LYS\n",
      "\tQuit\n",
      "\n",
      "Exiting LEaP: Errors = 0; Warnings = 2; Notes = 0.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/prep to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm to search path.\n",
      "-I: Adding /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd to search path.\n",
      "-s: Ignoring all leaprc startup files.\n",
      "-f: Source /Users/jessihoernschemeyer/pKaSchNet/ascript.py.\n",
      "\n",
      "Welcome to LEaP!\n",
      "Sourcing: /Users/jessihoernschemeyer/pKaSchNet/ascript.py\n",
      "----- Source: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.protein.ff14SB\n",
      "----- Source of /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.protein.ff14SB done\n",
      "Log file: ./leap.log\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/parm10.dat\n",
      "Reading title:\n",
      "PARM99 + frcmod.ff99SB + frcmod.parmbsc0 + OL3 for RNA\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ff14SB\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "ff14SB protein backbone and sidechain parameters\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino12.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/aminoct12.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/aminont12.lib\n",
      "----- Source: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.water.tip3p\n",
      "----- Source of /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/cmd/leaprc.water.tip3p done\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/atomic_ions.lib\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/solvents.lib\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "This is the additional/replacement parameter set for TIP3P water\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ions1lm_126_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Li/Merz ion parameters of monovalent ions for TIP3P water model (12-6 normal usage set)\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ionsjc_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Monovalent ion parameters for Ewald and TIP3P water from Joung & Cheatham JPCB (2008)\n",
      "Loading parameters: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/parm/frcmod.ions234lm_126_tip3p\n",
      "Reading force field modification type file (frcmod)\n",
      "Reading title:\n",
      "Li/Merz ion parameters of divalent to tetravalent ions for TIP3P water model (12-6 normal usage set)\n",
      "Loading library: /Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\n",
      "Loading PDB file: /Users/jessihoernschemeyer/pKaSchNet/194l_A_18_ASP-2.pdb\n",
      "  Added missing heavy atom: .R<NLYS 13>.A<CB 7>\n",
      "  Added missing heavy atom: .R<NLYS 13>.A<CA 5>\n",
      "  Added missing heavy atom: .R<NLYS 13>.A<N 1>\n",
      "  Added missing heavy atom: .R<NLYS 13>.A<C 23>\n",
      "  Added missing heavy atom: .R<NLYS 13>.A<O 24>\n",
      "  Added missing heavy atom: .R<NLYS 13>.A<NZ 19>\n",
      "  Added missing heavy atom: .R<LEU 14>.A<CA 3>\n",
      "  Added missing heavy atom: .R<LEU 14>.A<CG 8>\n",
      "  Added missing heavy atom: .R<LEU 14>.A<N 1>\n",
      "  Added missing heavy atom: .R<LEU 14>.A<C 18>\n",
      "  Added missing heavy atom: .R<LEU 14>.A<CD1 10>\n",
      "  Added missing heavy atom: .R<LEU 14>.A<O 19>\n",
      "  Added missing heavy atom: .R<CASN 16>.A<CA 3>\n",
      "  Added missing heavy atom: .R<CASN 16>.A<CB 5>\n",
      "  Added missing heavy atom: .R<CASN 16>.A<C 13>\n",
      "  Added missing heavy atom: .R<CASN 16>.A<O 14>\n",
      "  Added missing heavy atom: .R<CASN 16>.A<OXT 15>\n",
      "  Added missing heavy atom: .R<CASN 16>.A<OD1 9>\n",
      "  total atoms in file: 16\n",
      "  Leap added 55 missing atoms according to residue templates:\n",
      "       18 Heavy\n",
      "       37 H / lone pairs\n",
      "Writing pdb file: /Users/jessihoernschemeyer/pKaSchNet/prot_194l_A_18_ASP-2.pdb\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      " Converting N-terminal residue name to PDB format: NLYS -> LYS\n",
      "\n",
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/bin/teLeap: Warning!\n",
      " Converting C-terminal residue name to PDB format: CASN -> ASN\n",
      "\tQuit\n",
      "\n",
      "Exiting LEaP: Errors = 0; Warnings = 2; Notes = 0.\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "import time\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import chain, product\n",
    "#protonate(\"194l\", )\n",
    "def amber(input_pdb):\n",
    "    skript = f\"\"\"source leaprc.protein.ff14SB\n",
    "    source leaprc.water.tip3p\n",
    "    loadOff \"/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\"\n",
    "    mol = loadpdb \"/Users/jessihoernschemeyer/pKaSchNet/{input_pdb}.pdb\"\n",
    "    savepdb mol \"/Users/jessihoernschemeyer/pKaSchNet/prot_{input_pdb}.pdb\"\n",
    "\n",
    "    quit\"\"\"\n",
    "    with open(\"ascript.py\",\"w\") as file: \n",
    "        file.writelines(skript)\n",
    "    return\n",
    "\n",
    "\n",
    "for f in fs[:3]:\n",
    "    amber(f)\n",
    "    !tleap -s -f /Users/jessihoernschemeyer/pKaSchNet/ascript.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat 194l_A_18_ASP-2.pdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat 194l_A_13_LYS-1.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "amber(\"194l_A_7_GLU-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to put not the same cutout through schnet!! maybe have to add a pair id.\n",
    "will just replace the pdb in the end instead of prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prot_194l_A_18_ASP-2AT'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname='prot_194l_A_18_ASP-2' + 'AT'\n",
    "fname\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acidic\n",
    "protonatable_sites = [\"HE2\", \"HG\", \"HZ1\", \"OD2\", \"HE2\", \"HD1\", \"HH\"] # glu cys lys asp hie hid tyr\n",
    "protonatable_sites = [\"G\":\"HE2\", \"HG\", \"HZ1\", \"OD2\", \"HE2\", \"HD1\", \"HH\"] \n",
    "in=\"194l_A_7_GLU-0_0.pdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat 194l_A_7_GLU-0.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed '/HH/d' /Users/jessihoernschemeyer/pKaSchNet/194l_A_53_TYR-9.pdb #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!sed '/delete_this/d' file > newfile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if a solo cutout we can use sed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "from Bio import PDB\n",
    "from ase import Atoms, Atom\n",
    "import torch\n",
    "from matscipy.neighbours import neighbour_list as msp_neighbor_list\n",
    "pdb_parser = PDB.PDBParser()\n",
    "def PDB_to_schnet_input_and_names_map(cut,r):\n",
    "\n",
    "    pos, names, B, a = [],[], [], []\n",
    "    z_symbol = {'H' : 1,\n",
    "        'C' : 6,\n",
    "        'N' : 7,\n",
    "        'O' : 8,\n",
    "        'S': 16}\n",
    "    #struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/{file}')\n",
    "\n",
    "    for atom in cut:\n",
    "        id=atom.get_full_id()\n",
    "        res, name = id[3][1], id[4][0]\n",
    "        names.append(name)\n",
    "        pos.append(atom.get_coord())\n",
    "        a.append(atom)\n",
    "\n",
    "\n",
    "    z=[z_symbol.get(name[0]) for name in names]\n",
    "    #Z IS MADE FROM THE NAMES\n",
    "    atoms = Atoms([z_symbol.get(name[0]) for name in names], pos)\n",
    "    atoms.set_cell([[1,0,0], [0,1,0], [0,0,1]])\n",
    "\n",
    "    d, i, j = msp_neighbor_list('dij',  atoms, [r for i in range(len(atoms))])\n",
    "    inputs = {'Z':torch.tensor(z).long(), 'R':torch.tensor(d).float(), 'idx_i':torch.tensor(i).long(), 'idx_j': torch.tensor(j).long()}\n",
    "\n",
    "  \n",
    "    return inputs, [names, a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATOM      1  CE  LYS A  13     -16.811  20.282  11.682  1.00 34.74           C  \n",
      "ATOM      2  CD  LYS A  13     -15.333  19.969  11.652  1.00 30.15           C  \n",
      "ATOM      3  CG  LYS A  13     -14.897  19.284  12.931  1.00 25.07           C  \n",
      "ATOM      4  CD2 LEU A  25     -11.936  22.147  11.830  1.00 15.53           C  \n",
      "ATOM      5  CB  LEU A  25     -11.288  24.145  13.113  1.00 14.78           C  \n",
      "ATOM      6  N   ASH A  18     -12.669  21.775  17.303  1.00 20.30           N  \n",
      "ATOM      7  OD2 ASH A  18     -15.738  23.817  14.132  1.00 29.04           O  \n",
      "ATOM      8  CG  ASH A  18     -14.738  23.940  14.877  1.00 26.01           C  \n",
      "ATOM      9  CB  ASH A  18     -14.230  22.676  15.588  1.00 22.91           C  \n",
      "ATOM     10  OD1 ASH A  18     -14.154  25.049  15.039  1.00 26.14           O  \n",
      "ATOM     11  O   ASH A  18     -14.928  23.245  18.476  1.00 20.09           O  \n",
      "ATOM     12  C   ASH A  18     -13.993  23.754  17.846  1.00 21.32           C  \n",
      "ATOM     13  CA  ASH A  18     -13.274  22.987  16.745  1.00 21.37           C  \n",
      "ATOM     14  N   ASN A  19     -13.494  24.955  18.110  1.00 20.60           N  \n",
      "ATOM     15  ND2 ASN A  19     -16.201  26.319  16.593  1.00 36.78           N  \n",
      "ATOM     16  CG  ASN A  19     -15.701  26.949  17.652  1.00 32.66           C  \n",
      "TER      17      ASN A  19                                                       \n",
      "END   \n"
     ]
    }
   ],
   "source": [
    "!cat 194l_A_18_ASP-2.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATOM      1  N   LEU     1     -16.599  20.501   9.740  1.00  0.00\n",
      "ATOM      2  H   LEU     1     -16.579  19.602  10.200  1.00  0.00\n",
      "ATOM      3  CA  LEU     1     -16.662  20.530   8.292  1.00  0.00\n",
      "ATOM      4  HA  LEU     1     -17.566  21.052   7.978  1.00  0.00\n",
      "ATOM      5  CB  LEU     1     -15.454  21.253   7.705  1.00  0.00\n",
      "ATOM      6  HB2 LEU     1     -15.429  22.278   8.073  1.00  0.00\n",
      "ATOM      7  HB3 LEU     1     -14.541  20.737   8.003  1.00  0.00\n",
      "ATOM      8  CG  LEU     1     -15.558  21.262   6.183  1.00  0.00\n",
      "ATOM      9  HG  LEU     1     -15.583  20.237   5.814  1.00  0.00\n",
      "ATOM     10  CD1 LEU     1     -16.835  21.984   5.766  1.00  0.00\n",
      "ATOM     11 HD11 LEU     1     -16.811  23.010   6.134  1.00  0.00\n",
      "ATOM     12 HD12 LEU     1     -16.910  21.991   4.678  1.00  0.00\n",
      "ATOM     13 HD13 LEU     1     -17.699  21.468   6.185  1.00  0.00\n",
      "ATOM     14  CD2 LEU     1     -14.351  21.985   5.596  1.00  0.00\n",
      "ATOM     15 HD21 LEU     1     -13.438  21.469   5.894  1.00  0.00\n",
      "ATOM     16 HD22 LEU     1     -14.424  21.992   4.508  1.00  0.00\n",
      "ATOM     17 HD23 LEU     1     -14.325  23.010   5.965  1.00  0.00\n",
      "ATOM     18  C   LEU     1     -16.687  19.122   7.716  1.00  0.00\n",
      "ATOM     19  O   LEU     1     -16.654  18.126   8.472  1.00  0.00\n",
      "ATOM     20  OXT LEU     1     -17.736  19.750   7.435  1.00  0.00\n",
      "ATOM     21  N   LYS     2     -11.671  17.686  14.022  1.00  0.00\n",
      "ATOM     22  H   LYS     2     -11.487  16.698  14.130  1.00  0.00\n",
      "ATOM     23  CA  LYS     2     -13.045  18.141  14.102  1.00  0.00\n",
      "ATOM     24  HA  LYS     2     -13.146  18.850  14.923  1.00  0.00\n",
      "ATOM     25  CB  LYS     2     -13.471  18.828  12.809  1.00  0.00\n",
      "ATOM     26  HB2 LYS     2     -12.829  19.689  12.626  1.00  0.00\n",
      "ATOM     27  HB3 LYS     2     -13.384  18.127  11.979  1.00  0.00\n",
      "ATOM     28  CG  LYS     2     -14.897  19.284  12.931  1.00  0.00\n",
      "ATOM     29  HG2 LYS     2     -15.536  18.420  13.116  1.00  0.00\n",
      "ATOM     30  HG3 LYS     2     -14.981  19.982  13.764  1.00  0.00\n",
      "ATOM     31  CD  LYS     2     -15.333  19.969  11.652  1.00  0.00\n",
      "ATOM     32  HD2 LYS     2     -14.768  20.894  11.541  1.00  0.00\n",
      "ATOM     33  HD3 LYS     2     -15.119  19.309  10.811  1.00  0.00\n",
      "ATOM     34  CE  LYS     2     -16.811  20.282  11.682  1.00  0.00\n",
      "ATOM     35  HE2 LYS     2     -17.054  20.866  12.570  1.00  0.00\n",
      "ATOM     36  HE3 LYS     2     -17.096  20.841  10.791  1.00  0.00\n",
      "ATOM     37  NZ  LYS     2     -17.552  18.998  11.717  1.00  0.00\n",
      "ATOM     38  HZ1 LYS     2     -17.289  18.480  12.543  1.00  0.00\n",
      "ATOM     39  HZ2 LYS     2     -18.545  19.183  11.738  1.00  0.00\n",
      "ATOM     40  HZ3 LYS     2     -17.327  18.457  10.894  1.00  0.00\n",
      "ATOM     41  C   LYS     2     -13.994  16.976  14.345  1.00  0.00\n",
      "ATOM     42  O   LYS     2     -13.563  15.830  14.447  1.00  0.00\n",
      "ATOM     43  OXT LYS     2     -15.205  17.168  14.441  1.00  0.00\n",
      "TER   \n",
      "ATOM     44  O   WAT     3     -14.999  15.436  10.929  1.00  0.00\n",
      "ATOM     45  H1  WAT     3     -14.042  15.436  10.929  1.00  0.00\n",
      "ATOM     46  H2  WAT     3     -15.239  16.363  10.929  1.00  0.00\n",
      "TER   \n",
      "END   \n"
     ]
    }
   ],
   "source": [
    "!cat prot_194l_A_13_LYS-1.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-17.552,  18.998,  11.717], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!cat 194l_A_18_ASP-2.pdb\n",
    "!cat 194l_A_13_LYS-1.pdb\n",
    "struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot_194l_A_18_ASP-2.pdb')\n",
    "\n",
    "\n",
    "ns = PDB.NeighborSearch(list(struct.get_atoms())) #set up ns , entire protein\n",
    "cut1 = ns.search(cs[2], 5, \"A\")\n",
    "input1, extras1 = PDB_to_schnet_input_and_names_map(cut1,6)\n",
    "\n",
    "struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot_194l_A_13_LYS-1.pdb')\n",
    "\n",
    "len([atom for atom in struct.get_atoms()])\n",
    "\n",
    "ns = PDB.NeighborSearch(list(struct.get_atoms())) #set up ns , entire protein\n",
    "cut2 = ns.search(cs[1], 5, \"A\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue WAT het=  resseq=3 icode= >\n",
      "<Residue WAT het=  resseq=3 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n"
     ]
    }
   ],
   "source": [
    "for atom in cut1:\n",
    "    print(atom.get_parent())\n",
    "print(\"\")\n",
    "for atom in cut2:\n",
    "    print(atom.get_parent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input1.get('Z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schnetpack.representation.schnet import SchNet\n",
    "from torch.nn import Sequential\n",
    "from schnetpack.model import NeuralNetworkPotential\n",
    "from torch import nn\n",
    "from schnetpack.nn import Dense\n",
    "from schnetpack.nn.radial import GaussianRBF\n",
    "from schnetpack.nn.cutoff import CosineCutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39mset_printoptions(profile\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtensor_dict.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m r\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "weights = torch.load('tensor_dict.pth')\n",
    "r=10\n",
    "output_weight = torch.load('output_tensor.pth')\n",
    "\n",
    "Model = SchNet(n_atom_basis=128, n_interactions=6, radial_basis=GaussianRBF(50, r), cutoff_fn=CosineCutoff(r))\n",
    "for keys, weight in weights.items():\n",
    "    left = f\"Model.{keys}\" \n",
    "    right = f\"torch.nn.Parameter(torch.{weight})\"\n",
    "    execu = f\"{left} = {right}\"\n",
    "    st = execu.replace(\"\\n       \",\"\")\n",
    "    st2 = st.replace(\"representation.\",\"\")\n",
    "    try:\n",
    "        exec(st2)\n",
    "    finally:\n",
    "        right2 = f\"torch.nn.Parameter({weight})\"\n",
    "        E=f\"{left} = {right2}\"\n",
    "        s = execu.replace(\"\\n       \",\"\")\n",
    "        s2 = s.replace(\"representation.\",\"\")\n",
    "        exec(s2)\n",
    "\n",
    "modelll=nn.Sequential(Dense(128,64), Dense(64,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelll[0].weight = nn.Parameter(output_weight.get('dense1_weight'))\n",
    "    modelll[0].bias = nn.Parameter(output_weight.get('dense1_bias'))\n",
    "    modelll[1].weight = nn.Parameter(output_weight.get('dense2_weight'))\n",
    "    modelll[1].bias = nn.Parameter(output_weight.get('dense2_bias'))\n",
    "\n",
    "#input1, extras1 = PDB_to_schnet_input_and_names_map(cut1)\n",
    "#outputs1 = Model(input1)\n",
    "#E1 = modelll(outputs1.get('scalar_representation'))\n",
    "#Eatoms1 = [[atom for atom in extras1[1]], [e for e in E1]]\n",
    "#Eatoms1_dict = dict(zip([atom for atom in extras1[1]], [e for e in E1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "outputs1 = Model(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=10\n",
    "input1, extras1 = PDB_to_schnet_input_and_names_map(cut1)\n",
    "len(input1.get('Z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mschnetpack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mradial\u001b[39;00m \u001b[39mimport\u001b[39;00m GaussianRBF\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mschnetpack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcutoff\u001b[39;00m \u001b[39mimport\u001b[39;00m CosineCutoff\n\u001b[0;32m----> 8\u001b[0m torch\u001b[39m.\u001b[39mset_printoptions(profile\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtensor_dict.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m r\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from schnetpack.representation.schnet import SchNet\n",
    "from torch.nn import Sequential\n",
    "from schnetpack.model import NeuralNetworkPotential\n",
    "from torch import nn\n",
    "from schnetpack.nn import Dense\n",
    "from schnetpack.nn.radial import GaussianRBF\n",
    "from schnetpack.nn.cutoff import CosineCutoff\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "weights = torch.load('tensor_dict.pth')\n",
    "r=10\n",
    "output_weight = torch.load('output_tensor.pth')\n",
    "\n",
    "Model = SchNet(n_atom_basis=128, n_interactions=6, radial_basis=GaussianRBF(50, r), cutoff_fn=CosineCutoff(r))\n",
    "for keys, weight in weights.items():\n",
    "    left = f\"Model.{keys}\" \n",
    "    right = f\"torch.nn.Parameter(torch.{weight})\"\n",
    "    execu = f\"{left} = {right}\"\n",
    "    st = execu.replace(\"\\n       \",\"\")\n",
    "    st2 = st.replace(\"representation.\",\"\")\n",
    "    try:\n",
    "        exec(st2)\n",
    "    finally:\n",
    "        right2 = f\"torch.nn.Parameter({weight})\"\n",
    "        E=f\"{left} = {right2}\"\n",
    "        s = execu.replace(\"\\n       \",\"\")\n",
    "        s2 = s.replace(\"representation.\",\"\")\n",
    "        exec(s2)\n",
    "\n",
    "modelll=nn.Sequential(Dense(128,64), Dense(64,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelll[0].weight = nn.Parameter(output_weight.get('dense1_weight'))\n",
    "    modelll[0].bias = nn.Parameter(output_weight.get('dense1_bias'))\n",
    "    modelll[1].weight = nn.Parameter(output_weight.get('dense2_weight'))\n",
    "    modelll[1].bias = nn.Parameter(output_weight.get('dense2_bias'))\n",
    "\n",
    "input1, extras1 = PDB_to_schnet_input_and_names_map(cut1)\n",
    "outputs1 = Model(input1)\n",
    "E1 = modelll(outputs1.get('scalar_representation'))\n",
    "Eatoms1 = [[atom for atom in extras1[1]], [e for e in E1]]\n",
    "Eatoms1_dict = dict(zip([atom for atom in extras1[1]], [e for e in E1]))\n",
    "\n",
    "Model = SchNet(n_atom_basis=128, n_interactions=6, radial_basis=GaussianRBF(50, r), cutoff_fn=CosineCutoff(r))\n",
    "for keys, weight in weights.items():\n",
    "    left = f\"Model.{keys}\" \n",
    "    right = f\"torch.nn.Parameter(torch.{weight})\"\n",
    "    execu = f\"{left} = {right}\"\n",
    "    st = execu.replace(\"\\n       \",\"\")\n",
    "    st2 = st.replace(\"representation.\",\"\")\n",
    "    try:\n",
    "        exec(st2)\n",
    "    finally:\n",
    "        right2 = f\"torch.nn.Parameter({weight})\"\n",
    "        E=f\"{left} = {right2}\"\n",
    "        s = execu.replace(\"\\n       \",\"\")\n",
    "        s2 = s.replace(\"representation.\",\"\")\n",
    "        exec(s2)\n",
    "\n",
    "modelll=nn.Sequential(Dense(128,64), Dense(64,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelll[0].weight = nn.Parameter(output_weight.get('dense1_weight'))\n",
    "    modelll[0].bias = nn.Parameter(output_weight.get('dense1_bias'))\n",
    "    modelll[1].weight = nn.Parameter(output_weight.get('dense2_weight'))\n",
    "    modelll[1].bias = nn.Parameter(output_weight.get('dense2_bias'))\n",
    "\n",
    "input2, _ = PDB_to_schnet_input_and_names_map(cut2)\n",
    "outputs2 = Model(input2)\n",
    "E2 = modelll(outputs2.get('scalar_representation'))\n",
    "\n",
    "Eatoms2 = [[atom for atom in _[1]], [e for e in E2]]\n",
    "Eatoms2_dict = dict(zip([atom for atom in _[1]], [e for e in E2]))\n",
    "\n",
    "common_entries = set(Eatoms1[0]).intersection(set(Eatoms2[0]))\n",
    "for x in list(common_entries):\n",
    "    print(Eatoms2_dict.get(x), Eatoms1_dict.get(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(modelll\u001b[39m.\u001b[39mstate_dict()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelll' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(modelll.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_entries = set(Eatoms1[0]).intersection(set(Eatoms2[0]))\n",
    "for x in list(common_entries):\n",
    "    print(Eatoms2_dict.get(x), Eatoms1_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cut[0].get_full_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
