{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "from Bio import PDB\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from ase import Atoms, Atom\n",
    "import dask.dataframe as dd\n",
    "from ordered_set import OrderedSet\n",
    "import os\n",
    "\n",
    "\n",
    "local_folder=\"/Users/jessihoernschemeyer/pKaSchNet\"\n",
    "pkPDB_CSV = f\"{local_folder}/pkas.csv\"\n",
    "def read_database(path):\n",
    "    \"\"\"csv --> dask df\"\"\"\n",
    "    #make the dask data frame from the PYPKA csv\n",
    "    dk=dd.read_csv(pkPDB_CSV, delimiter=';', na_filter=False, dtype={'idcode':'category', \n",
    "                                                                    'residue_number':'uint8',\n",
    "                                                                    'pk': 'float32',\n",
    "                                                                    'residue_name':'category',\n",
    "                                                                    'chain': 'category',\n",
    "                                                                    'residue_name': 'category'\n",
    "                                                                    })\n",
    "                                                            \n",
    "    dk=dk.rename(columns={'idcode': 'PDB ID', 'residue_number': 'Res ID', 'residue_name': 'Res Name', 'residue_number': 'Res ID', 'pk': 'pKa', 'chain' : 'Chain'}) #rename columns to match df from pkad \n",
    "    dk=dk.sort_values(['PDB ID', 'Res ID'], ascending=[True, True]) \n",
    "    dk=dk.compute() \n",
    "    dff = dk.reset_index() \n",
    "\n",
    "    return dff\n",
    "\n",
    "def check_atoms_protein(structure, struc_atoms): \n",
    "    \"\"\"internal function. checks every atom in the entire protein for metals, undesirables\"\"\"\n",
    "    pdb_residues=[]\n",
    "    for atom in struc_atoms: \n",
    "        resname, atomid=atom.get_parent().get_resname(), atom.get_full_id()[2:]\n",
    "        element=atomid[2][0]\n",
    "\n",
    "        if element in [\"MG\", \"MN\", \"FE\", \"CO\", \"NI\", \"CU\", \"ZN\"]:\n",
    "            return 0#,0#print(f\"{element} present, pdb skipped\")\n",
    "        \n",
    "        else:\n",
    "            #atomid=atom.get_full_id() #('', 0, 'B', (' ', 177, ' '), ('OH', ' '))\n",
    "            if atomid[1][0] not in [' ']:\n",
    "                if element == 'S': #check 4 hetero sulfur, exclude.\n",
    "                    print(f\"{atomid}, hetero sulfur. pdb skipped \")\n",
    "                    return 0#,0\n",
    "                \n",
    "                if element in ['CA', 'CL', 'K', 'NA']: #other salt\n",
    "                    for res in structure.get_residues():\n",
    "                        if resname in [\"GLU\", \"HIS\", \"ASP\", \"ARG\", \"TYR\", \"CYS\", \"LYS\"]: #if the other salt is part of the residue (<3Ã¥ from geometric center), delete atom from residue\n",
    "                            if np.linalg.norm(res.center_of_mass(geometric=True) - atom.get_coord()) < 3:\n",
    "                                atom.get_parent().detach_child(atom.get_id()) #print(f\"salt {atom} deleted, {d} from {res}\")\n",
    "    \n",
    "    return structure#, set(pdb_residues) #('', 0, 'B', ('W', 371, ' '), ('O', ' '))\n",
    "\n",
    "def atoms_to_structure(cutout, filename): \n",
    "    \"\"\"Internal function (or not), cutout --> save to harddrive\n",
    "    input: cutout: list of biopython atom objects (NOT ASE)\"\"\"\n",
    "    chain_dict = {}\n",
    "\n",
    "    structure = Structure.Structure(filename)\n",
    "    model = Model.Model(0)\n",
    "    structure.add(model)\n",
    "\n",
    "    for atom in cutout:\n",
    "        res = atom.get_parent()\n",
    "        res_id, resname, chain_id = res.get_id(), res.get_resname(), res.get_full_id()[2]\n",
    "\n",
    "        #make acidic GLH and ASH straight here. so change their name before saving \n",
    "        if resname == \"GLU\":\n",
    "            resname=\"GLH\"\n",
    "            \n",
    "        if resname==\"ASP\":\n",
    "            resname=\"ASH\"\n",
    "\n",
    "        if resname==\"HIS\":\n",
    "            resname=\"HIP\"\n",
    "            \n",
    "        \n",
    "        if chain_id not in chain_dict:\n",
    "            chain = Chain.Chain(chain_id) #make new chain\n",
    "            chain_dict[chain_id] = chain\n",
    "            model.add(chain) #add it\n",
    "\n",
    "        else:\n",
    "            chain = chain_dict[chain_id]\n",
    "\n",
    "        if res_id in [res.get_id() for res in chain.get_residues()]:\n",
    "            residue = [res for res in chain.get_residues() if res.get_id() == res_id][0] \n",
    "        else:\n",
    "            residue = Residue.Residue(res_id, resname, '') #make new res\n",
    "            chain.add(residue)\n",
    "\n",
    "        residue.add(atom)\n",
    "    # save the pdb\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(f\"cuts/{filename}.pdb\")\n",
    "\n",
    "dask_df = read_database(local_folder + pkPDB_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_parser, pdbs = PDB.PDBParser(), list(OrderedSet(list(dask_df[\"PDB ID\"])))\n",
    "def generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter, resname):\n",
    "    \"\"\"Residue wise resolurion. ns is neighbor search set up for the entire protein, residue is the single data point / 1 of several residues in a pdb & in pypka.\n",
    "    input is one residue. output is the cutout around its titratable site, both of which can be plural e.g. his, mb asp and glu.\n",
    "    residue (biopython Residue object): a single protonable residue \"\"\"\n",
    "    protonatable_sites = [\"OE2\", \"SG\", \"NZ\", \"OD2\", \"NE2\", \"ND1\", \"OH\"]\n",
    "    cuts = []\n",
    "    if resname==0:\n",
    "        #first atom is N and NTR\n",
    "        #atoms=residue.\n",
    "        print(\"ntr section\")\n",
    "        Natom = residue.get_atom('N')\n",
    "        print(Natom)\n",
    "        center = Natom.get_coord()\n",
    "        cut = ns.search(center, distance_cutoff, \"A\")\n",
    "        print('ntr', cut)\n",
    "        cuts.append((counter, center, 'NTR', cut)) #counter is id!\n",
    "        return cuts\n",
    "    \n",
    "    elif resname==1:\n",
    "        print(\"ctr section\")\n",
    "        try:\n",
    "            Catom = residue['OXT']\n",
    "        except:\n",
    "            Catom = residue['C']\n",
    "        print(Catom)\n",
    "        center = Catom.get_coord()\n",
    "        cut = ns.search(center, distance_cutoff, \"A\")\n",
    "        print('ctr',cut)\n",
    "        cuts.append((counter, center, 'CTR', cut)) #counter is id!\n",
    "        return cuts\n",
    "        #residue.get_atoms()\n",
    "        \n",
    "     #for atom in residue.get_atoms():\n",
    "       # if atom.is_disordered(): \n",
    "            #atomN = str(atom)[16:-1]\n",
    "            #if atomN in [\"N\", \"OXT\"]: #can remove this after schnet\n",
    "                #return #dont make cutout of titratable site is disordered\n",
    "\n",
    "\n",
    "    else:\n",
    "        if resname==\"G\": \n",
    "            atom=residue[protonatable_sites[0]]\n",
    "            if atom.is_disordered(): \n",
    "                return\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, residue.get_resname()[0], cut)) #counter is id!\n",
    "            return cuts\n",
    "            \n",
    "        if resname==\"C\": \n",
    "            atom=residue[protonatable_sites[1]]\n",
    "            if atom.is_disordered(): \n",
    "                return\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, resname, cut)) #counter is id!\n",
    "            return cuts\n",
    "        if resname==\"L\": \n",
    "            atom=residue[protonatable_sites[2]]\n",
    "            if atom.is_disordered(): \n",
    "                return\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, resname, cut)) #counter is id!\n",
    "            return cuts\n",
    "        if resname==\"A\": \n",
    "            atom=residue[protonatable_sites[3]]\n",
    "            if atom.is_disordered(): \n",
    "                return\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, resname, cut)) #counter is id!\n",
    "            return cuts\n",
    "        if resname==\"H\":\n",
    "            atom1=residue[protonatable_sites[4]], atom2=residue[protonatable_sites[5]]\n",
    "            if atom1.is_disordered(): \n",
    "                return\n",
    "            if atom2.is_disordered():\n",
    "                return\n",
    "            \n",
    "            center1,center2=atom1.get_coord(), atom2.get_coord()\n",
    "            cut1=ns.search(center1, distance_cutoff, \"A\")\n",
    "            cut2=ns.search(center2, distance_cutoff, \"A\")\n",
    "            cuts.append((counter+.1, center1, resname, cut1), (counter+.2, center2, resname, cut2))\n",
    "        if resname==\"T\":\n",
    "            atom=residue[protonatable_sites[6]]\n",
    "            if atom.is_disordered(): \n",
    "                return\n",
    "            center = atom.get_coord()\n",
    "            cut = ns.search(center, distance_cutoff, \"A\")\n",
    "            cuts.append((counter, center, resname, cut)) #counter is id!\n",
    "            return cuts\n",
    "\n",
    "    return cuts #plural because of sites with multiple sites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "def merge_or_not_cutouts(cutouts_apdb, distance_cutoff): #TODO: reduce dtypes #PDB WISE!\n",
    "    \"\"\"\n",
    "    in: all of the cutouts from the pdb. returns the merged or solo cutout for each input residue of cutouts_apdb. len in = len out\"\"\"\n",
    "    #protein wise ..\n",
    "    dp_ids,centers,cuts, Ds_lite, cutouts, resnames,redunant_merged_is, done_pairs =[],[],[],[], [],[],[],[]\n",
    "\n",
    "    for site in cutouts_apdb:\n",
    "        dp_ids.append(site[0]) #1,2,3,4,5,6,7,8,9.1, 9.2....\n",
    "        centers.append(site[1]) \n",
    "        resnames.append(site[2])\n",
    "        cuts.append(site[3])\n",
    "\n",
    "    num_residues=len(centers)\n",
    "    distances = np.zeros((num_residues, num_residues))\n",
    "    \n",
    "    for i in range(num_residues):\n",
    "        for j in range(i + 1, num_residues):\n",
    "            distance = np.linalg.norm(centers[i] - centers[j]).astype(np.float32)\n",
    "            if distance < distance_cutoff:\n",
    "                distances[i, j] = distance\n",
    "                distances[j, i] = distance\n",
    "\n",
    "    Ds_lite = [distances[i][distances[i] != 0] for i in range(num_residues)] #nonzero entries for easier searching\n",
    "#residuewise...\n",
    "    for i in range(len(Ds_lite)): #=len IDs \n",
    "        a_residues_distance_array=Ds_lite[i]\n",
    "        if a_residues_distance_array.any(): #if not empty\n",
    "            index=dp_ids[i]\n",
    "            closest_cutout_i = int(np.where((distances[:,int(index)])==np.min(a_residues_distance_array))[0])\n",
    "            pair_i = frozenset((index,dp_ids[closest_cutout_i]))#key #frozen set is immutable thus can be used as a dict key #also order doesnt matter, 2-1=1-2\n",
    "\n",
    "            if not done_pairs: #if there are any yet merged\n",
    "                cutout = (list(set(cuts[i] + cuts[closest_cutout_i])),resnames[i] + resnames[closest_cutout_i])\n",
    "                done_pairs.append(pair_i)\n",
    "                redunant_merged_is.append(closest_cutout_i)\n",
    "                \n",
    "            else: #if there are already some generated\n",
    "                if pair_i not in done_pairs: #if that mergedcut hasnt yet been made\n",
    "                    cutout = (list(set(cuts[i] + cuts[closest_cutout_i])),resnames[i] + resnames[closest_cutout_i])\n",
    "                    done_pairs.append(pair_i)\n",
    "                    redunant_merged_is.append(closest_cutout_i)\n",
    "\n",
    "                else: #null\n",
    "                    cutout = None\n",
    "\n",
    "        else: #solo cutout\n",
    "            cutout = cuts[i]\n",
    "\n",
    "        cutouts.append(cutout)\n",
    "\n",
    "    if len(cutouts) != len(dp_ids): #delete?\n",
    "        return #this will make an exception if something went wrong\n",
    "    \n",
    "    return cutouts,redunant_merged_is #merged or solo\n",
    "\n",
    "def get_cutout(dask_df, distance_cutoff): #\"PARENT\" FUNCTION\n",
    "    \"\"\"for each protein in dask_df (the entire PYPKA database), it iterates residue wise through the 121,294 proteins in PYPKA database and downloads\n",
    "    the structure from RCSB with biopython. Then, it checks and skips the structure if metals & hetero sulfurs are present, and deletes non-sulfur\n",
    "    salts from titratable residues.\n",
    "    Then, for each structure residue represented in PYPKA, generates a cutout for each residue, appends the structure to cutouts_apdb\"\"\"\n",
    "    #pdbname=\"11as\"  #for now #delete\n",
    "    cutouts_apdb, all_tit_res =[],[]\n",
    "    for i in range(24,25): #will equal len of set of pdbs in pypka, == 121294 \n",
    "        cutouts_apdb, fnames, cutouts_1_datapoint, counter, pdbname, newfnames =[],[], [],0, pdbs[i],[]\n",
    "        Structure = pdb_parser.get_structure(\"\",  PDBList().retrieve_pdb_file(str.lower(pdbname),obsolete=False, pdir='PDB',file_format = 'pdb'))\n",
    "        structure= check_atoms_protein(Structure, Structure.get_atoms())\n",
    "        if not structure: #skip entire pdb and all its entries in pypka db if there are undesirables in pdb\n",
    "            continue\n",
    "            \n",
    "        ns = PDB.NeighborSearch(list(structure.get_atoms())) #set up ns , entire protein\n",
    "        pdb_df = dask_df[dask_df.iloc[:, 1] == pdbname].drop(columns = [\"PDB ID\", \"pKa\"]) #make a subdf containing only residue entries which are in PYPKA (dask_df) \n",
    "        for j in range(len(pdb_df)):  #go through each residue in a pdb #each j is a datapoint!\n",
    "            chain, res_id =pdb_df.iloc[j]['Chain'], int(pdb_df.iloc[j]['Res ID'])\n",
    "            try: \n",
    "                residue=structure[0][chain][res_id] #a datapoint #TODO: make ID?\n",
    "                pypka_resname, PDBresname = pdb_df.iloc[j]['Res Name'], residue.get_resname() #pypka error\n",
    "                if pypka_resname=='NTR':\n",
    "                    resname=0\n",
    "                elif pypka_resname=='CTR':\n",
    "                    resname=1\n",
    "                elif pypka_resname==PDBresname:\n",
    "                    resname=pypka_resname[0]\n",
    "                    print(resname)\n",
    "                #pypka error: if not in ntr or == pdbresname, it will error and pass.\n",
    "                    #elif pypka_resname == PDBresname: #ACHTUNG! this navigates the pyka error. #TODO: mail him #TODO: THIS EXCLUDES NTR AND CTR!\n",
    "\n",
    "                cutouts_1_datapoint=generate_cutout_around_protonatable_site(residue, distance_cutoff, ns, counter, resname) #can be multiple #returns empty if disordered\n",
    "                if cutouts_1_datapoint: #cutouts_1_datapoint DNE if titratable site is disordered\n",
    "                    cutouts_apdb.append(*cutouts_1_datapoint) #append each residue/data point cutouts here #it will error here if disordered\n",
    "                    fnames.append(f\"{pdbname}{chain}{res_id}_{pypka_resname}{counter}\") \n",
    "                    counter+=1\n",
    "                else:\n",
    "                    continue #pypka error\n",
    "\n",
    "            except: \n",
    "                print(\"hi\")\n",
    "                pass #means pypka res not found in PDB\n",
    "        \n",
    "        #os.remove(f\"{local_folder}/PDB/pdb{pdbname}.ent\")  \n",
    "        if cutouts_apdb:\n",
    "            merged_and_solos, greaterN_pair_i =merge_or_not_cutouts(cutouts_apdb, distance_cutoff)#make a merged cutout or not based off radius criteria\n",
    "            for cut, fname in zip(merged_and_solos, fnames):\n",
    "                if type(cut)==tuple: #means it is a merged cutout. second argument is the pairid #it is still 1-to-1 here but ima destroy it\n",
    "                    Fname=\"\".join([fname,'_',fnames[greaterN_pair_i[0]],\"_\",cut[1]]) #cut1 is pairid AT, HH,...\n",
    "                    newfnames.append(Fname)\n",
    "                    del greaterN_pair_i[0]\n",
    "                    atoms_to_structure(cut[0], Fname) #save as pdb)\n",
    "                elif not cut:\n",
    "                    continue\n",
    "                else:\n",
    "                    newfnames.append(fname)\n",
    "                    atoms_to_structure(cut, fname) \n",
    "\n",
    "    return newfnames,[c[1] for c in cutouts_apdb] #centers\n",
    "\n",
    "\n",
    "fs,centers = get_cutout(dask_df, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure that TIP3p and ff14sb in same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "\n",
    "import time\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import chain, product\n",
    "#protonate(\"194l\", )\n",
    "def amber(input_pdb):\n",
    "    skript = f\"\"\"source leaprc.protein.ff14SB\n",
    "    source leaprc.water.tip3p\n",
    "    loadOff \"/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/dat/leap/lib/amino19.lib\"\n",
    "    mol = loadpdb \"/Users/jessihoernschemeyer/pKaSchNet/cuts/{input_pdb}.pdb\"\n",
    "    savepdb mol \"/Users/jessihoernschemeyer/pKaSchNet/prot/{input_pdb}.pdb\"\n",
    "\n",
    "    quit\"\"\"\n",
    "    with open(\"ascript.py\",\"w\") as file: \n",
    "        file.writelines(skript)\n",
    "    return\n",
    "\n",
    "\n",
    "for f in fs:\n",
    "    amber(f)\n",
    "    !tleap -s -f /Users/jessihoernschemeyer/pKaSchNet/ascript.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do move everything to same directory\n",
    "\n",
    "can delete from cutouts as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acidic\n",
    "protonatable_sites = [\"HE2\", \"HG\", \"HZ1\", \"OD2\", \"HE2\", \"HD1\", \"HH\"] # glu cys lys asp hie hid tyr\n",
    "protonatable_sites = {\"G\":\"HE2\", \"C\":\"HG\", \"L\":\"HZ1\", \"A\":\"HD2\",\"H1\": \"HD1\", \"H2\":\"HE2\", \"T\": \"HH\"}\n",
    "in=\"194l_A_7_GLU-0_0.pdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed '/HH/d' /Users/jessihoernschemeyer/pKaSchNet/194l_A_53_TYR-9.pdb #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Structure id=protein>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessihoernschemeyer/miniconda3/envs/cfcnn/lib/python3.9/site-packages/Bio/PDB/PDBParser.py:388: PDBConstructionWarning: Ignoring unrecognized record '\\outl0' at line 10\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# Create a PDB parser object\n",
    "parser = PDBParser()\n",
    "\n",
    "# Load the PDB file with a non-standard extension\n",
    "structure = parser.get_structure('protein', '/Users/jessihoernschemeyer/pKaSchNet/cuts/og.rtf.HIE')\n",
    "\n",
    "# Now you can work with the 'structure' object as usual\n",
    "print(structure)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!sed '/delete_this/d' file > newfile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if a solo cutout we can use sed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "from Bio import PDB\n",
    "from ase import Atoms, Atom\n",
    "import torch\n",
    "from matscipy.neighbours import neighbour_list as msp_neighbor_list\n",
    "pdb_parser = PDB.PDBParser()\n",
    "def PDB_to_schnet_input_and_names_map(cut,r):\n",
    "\n",
    "    pos, names, B, a = [],[], [], []\n",
    "    z_symbol = {'H' : 1,\n",
    "        'C' : 6,\n",
    "        'N' : 7,\n",
    "        'O' : 8,\n",
    "        'S': 16}\n",
    "    #struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/{file}')\n",
    "\n",
    "    for atom in cut:\n",
    "        id=atom.get_full_id()\n",
    "        res, name = id[3][1], id[4][0]\n",
    "        names.append(name)\n",
    "        pos.append(atom.get_coord())\n",
    "        a.append(atom)\n",
    "\n",
    "\n",
    "    z=[z_symbol.get(name[0]) for name in names]\n",
    "    #Z IS MADE FROM THE NAMES\n",
    "    atoms = Atoms([z_symbol.get(name[0]) for name in names], pos)\n",
    "    atoms.set_cell([[1,0,0], [0,1,0], [0,0,1]])\n",
    "\n",
    "    d, i, j = msp_neighbor_list('dij',  atoms, [r for i in range(len(atoms))])\n",
    "    inputs = {'Z':torch.tensor(z).long(), 'R':torch.tensor(d).float(), 'idx_i':torch.tensor(i).long(), 'idx_j': torch.tensor(j).long()}\n",
    "\n",
    "  \n",
    "    return inputs, [names, a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATOM      1  CE  LYS A  13     -16.811  20.282  11.682  1.00 34.74           C  \n",
      "ATOM      2  CD  LYS A  13     -15.333  19.969  11.652  1.00 30.15           C  \n",
      "ATOM      3  CG  LYS A  13     -14.897  19.284  12.931  1.00 25.07           C  \n",
      "ATOM      4  CD2 LEU A  25     -11.936  22.147  11.830  1.00 15.53           C  \n",
      "ATOM      5  CB  LEU A  25     -11.288  24.145  13.113  1.00 14.78           C  \n",
      "ATOM      6  N   ASH A  18     -12.669  21.775  17.303  1.00 20.30           N  \n",
      "ATOM      7  OD2 ASH A  18     -15.738  23.817  14.132  1.00 29.04           O  \n",
      "ATOM      8  CG  ASH A  18     -14.738  23.940  14.877  1.00 26.01           C  \n",
      "ATOM      9  CB  ASH A  18     -14.230  22.676  15.588  1.00 22.91           C  \n",
      "ATOM     10  OD1 ASH A  18     -14.154  25.049  15.039  1.00 26.14           O  \n",
      "ATOM     11  O   ASH A  18     -14.928  23.245  18.476  1.00 20.09           O  \n",
      "ATOM     12  C   ASH A  18     -13.993  23.754  17.846  1.00 21.32           C  \n",
      "ATOM     13  CA  ASH A  18     -13.274  22.987  16.745  1.00 21.37           C  \n",
      "ATOM     14  N   ASN A  19     -13.494  24.955  18.110  1.00 20.60           N  \n",
      "ATOM     15  ND2 ASN A  19     -16.201  26.319  16.593  1.00 36.78           N  \n",
      "ATOM     16  CG  ASN A  19     -15.701  26.949  17.652  1.00 32.66           C  \n",
      "TER      17      ASN A  19                                                       \n",
      "END   \n"
     ]
    }
   ],
   "source": [
    "!cat 194l_A_18_ASP-2.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATOM      1  N   LEU     1     -16.599  20.501   9.740  1.00  0.00\n",
      "ATOM      2  H   LEU     1     -16.579  19.602  10.200  1.00  0.00\n",
      "ATOM      3  CA  LEU     1     -16.662  20.530   8.292  1.00  0.00\n",
      "ATOM      4  HA  LEU     1     -17.566  21.052   7.978  1.00  0.00\n",
      "ATOM      5  CB  LEU     1     -15.454  21.253   7.705  1.00  0.00\n",
      "ATOM      6  HB2 LEU     1     -15.429  22.278   8.073  1.00  0.00\n",
      "ATOM      7  HB3 LEU     1     -14.541  20.737   8.003  1.00  0.00\n",
      "ATOM      8  CG  LEU     1     -15.558  21.262   6.183  1.00  0.00\n",
      "ATOM      9  HG  LEU     1     -15.583  20.237   5.814  1.00  0.00\n",
      "ATOM     10  CD1 LEU     1     -16.835  21.984   5.766  1.00  0.00\n",
      "ATOM     11 HD11 LEU     1     -16.811  23.010   6.134  1.00  0.00\n",
      "ATOM     12 HD12 LEU     1     -16.910  21.991   4.678  1.00  0.00\n",
      "ATOM     13 HD13 LEU     1     -17.699  21.468   6.185  1.00  0.00\n",
      "ATOM     14  CD2 LEU     1     -14.351  21.985   5.596  1.00  0.00\n",
      "ATOM     15 HD21 LEU     1     -13.438  21.469   5.894  1.00  0.00\n",
      "ATOM     16 HD22 LEU     1     -14.424  21.992   4.508  1.00  0.00\n",
      "ATOM     17 HD23 LEU     1     -14.325  23.010   5.965  1.00  0.00\n",
      "ATOM     18  C   LEU     1     -16.687  19.122   7.716  1.00  0.00\n",
      "ATOM     19  O   LEU     1     -16.654  18.126   8.472  1.00  0.00\n",
      "ATOM     20  OXT LEU     1     -17.736  19.750   7.435  1.00  0.00\n",
      "ATOM     21  N   LYS     2     -11.671  17.686  14.022  1.00  0.00\n",
      "ATOM     22  H   LYS     2     -11.487  16.698  14.130  1.00  0.00\n",
      "ATOM     23  CA  LYS     2     -13.045  18.141  14.102  1.00  0.00\n",
      "ATOM     24  HA  LYS     2     -13.146  18.850  14.923  1.00  0.00\n",
      "ATOM     25  CB  LYS     2     -13.471  18.828  12.809  1.00  0.00\n",
      "ATOM     26  HB2 LYS     2     -12.829  19.689  12.626  1.00  0.00\n",
      "ATOM     27  HB3 LYS     2     -13.384  18.127  11.979  1.00  0.00\n",
      "ATOM     28  CG  LYS     2     -14.897  19.284  12.931  1.00  0.00\n",
      "ATOM     29  HG2 LYS     2     -15.536  18.420  13.116  1.00  0.00\n",
      "ATOM     30  HG3 LYS     2     -14.981  19.982  13.764  1.00  0.00\n",
      "ATOM     31  CD  LYS     2     -15.333  19.969  11.652  1.00  0.00\n",
      "ATOM     32  HD2 LYS     2     -14.768  20.894  11.541  1.00  0.00\n",
      "ATOM     33  HD3 LYS     2     -15.119  19.309  10.811  1.00  0.00\n",
      "ATOM     34  CE  LYS     2     -16.811  20.282  11.682  1.00  0.00\n",
      "ATOM     35  HE2 LYS     2     -17.054  20.866  12.570  1.00  0.00\n",
      "ATOM     36  HE3 LYS     2     -17.096  20.841  10.791  1.00  0.00\n",
      "ATOM     37  NZ  LYS     2     -17.552  18.998  11.717  1.00  0.00\n",
      "ATOM     38  HZ1 LYS     2     -17.289  18.480  12.543  1.00  0.00\n",
      "ATOM     39  HZ2 LYS     2     -18.545  19.183  11.738  1.00  0.00\n",
      "ATOM     40  HZ3 LYS     2     -17.327  18.457  10.894  1.00  0.00\n",
      "ATOM     41  C   LYS     2     -13.994  16.976  14.345  1.00  0.00\n",
      "ATOM     42  O   LYS     2     -13.563  15.830  14.447  1.00  0.00\n",
      "ATOM     43  OXT LYS     2     -15.205  17.168  14.441  1.00  0.00\n",
      "TER   \n",
      "ATOM     44  O   WAT     3     -14.999  15.436  10.929  1.00  0.00\n",
      "ATOM     45  H1  WAT     3     -14.042  15.436  10.929  1.00  0.00\n",
      "ATOM     46  H2  WAT     3     -15.239  16.363  10.929  1.00  0.00\n",
      "TER   \n",
      "END   \n"
     ]
    }
   ],
   "source": [
    "!cat prot_194l_A_13_LYS-1.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-17.552,  18.998,  11.717], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m struct \u001b[39m=\u001b[39m pdb_parser\u001b[39m.\u001b[39mget_structure(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Users/jessihoernschemeyer/pKaSchNet/prot_194l_A_18_ASP-2.pdb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m ns \u001b[39m=\u001b[39m PDB\u001b[39m.\u001b[39mNeighborSearch(\u001b[39mlist\u001b[39m(struct\u001b[39m.\u001b[39mget_atoms())) \u001b[39m#set up ns , entire protein\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m cut1 \u001b[39m=\u001b[39m ns\u001b[39m.\u001b[39msearch(cs[\u001b[39m2\u001b[39m], \u001b[39m5\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m input1, extras1 \u001b[39m=\u001b[39m PDB_to_schnet_input_and_names_map(cut1,\u001b[39m6\u001b[39m)\n\u001b[1;32m     10\u001b[0m struct \u001b[39m=\u001b[39m pdb_parser\u001b[39m.\u001b[39mget_structure(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Users/jessihoernschemeyer/pKaSchNet/prot_194l_A_13_LYS-1.pdb\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cs' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!cat 194l_A_18_ASP-2.pdb\n",
    "!cat 194l_A_13_LYS-1.pdb\n",
    "struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot_194l_A_18_ASP-2.pdb')\n",
    "\n",
    "\n",
    "ns = PDB.NeighborSearch(list(struct.get_atoms())) #set up ns , entire protein\n",
    "cut1 = ns.search(cs[2], 5, \"A\")\n",
    "input1, extras1 = PDB_to_schnet_input_and_names_map(cut1,6)\n",
    "\n",
    "struct = pdb_parser.get_structure(\"\",  f'/Users/jessihoernschemeyer/pKaSchNet/prot_194l_A_13_LYS-1.pdb')\n",
    "\n",
    "len([atom for atom in struct.get_atoms()])\n",
    "\n",
    "ns = PDB.NeighborSearch(list(struct.get_atoms())) #set up ns , entire protein\n",
    "cut2 = ns.search(cs[1], 5, \"A\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Atom N>\n",
      "<Atom N>\n",
      "<Atom N>\n",
      "<Atom N>\n"
     ]
    }
   ],
   "source": [
    "a=struct.get_residues()\n",
    "for b in a:\n",
    "    print(b['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=1 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=2 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASH het=  resseq=3 icode= >\n",
      "<Residue ASN het=  resseq=4 icode= >\n",
      "\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LEU het=  resseq=1 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue WAT het=  resseq=3 icode= >\n",
      "<Residue WAT het=  resseq=3 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n",
      "<Residue LYS het=  resseq=2 icode= >\n"
     ]
    }
   ],
   "source": [
    "for atom in cut1:\n",
    "    print(atom.get_parent())\n",
    "print(\"\")\n",
    "for atom in cut2:\n",
    "    print(atom.get_parent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input1.get('Z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schnetpack.representation.schnet import SchNet\n",
    "from torch.nn import Sequential\n",
    "from schnetpack.model import NeuralNetworkPotential\n",
    "from torch import nn\n",
    "from schnetpack.nn import Dense\n",
    "from schnetpack.nn.radial import GaussianRBF\n",
    "from schnetpack.nn.cutoff import CosineCutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39mset_printoptions(profile\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtensor_dict.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m r\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "weights = torch.load('tensor_dict.pth')\n",
    "r=10\n",
    "output_weight = torch.load('output_tensor.pth')\n",
    "\n",
    "Model = SchNet(n_atom_basis=128, n_interactions=6, radial_basis=GaussianRBF(50, r), cutoff_fn=CosineCutoff(r))\n",
    "for keys, weight in weights.items():\n",
    "    left = f\"Model.{keys}\" \n",
    "    right = f\"torch.nn.Parameter(torch.{weight})\"\n",
    "    execu = f\"{left} = {right}\"\n",
    "    st = execu.replace(\"\\n       \",\"\")\n",
    "    st2 = st.replace(\"representation.\",\"\")\n",
    "    try:\n",
    "        exec(st2)\n",
    "    finally:\n",
    "        right2 = f\"torch.nn.Parameter({weight})\"\n",
    "        E=f\"{left} = {right2}\"\n",
    "        s = execu.replace(\"\\n       \",\"\")\n",
    "        s2 = s.replace(\"representation.\",\"\")\n",
    "        exec(s2)\n",
    "\n",
    "modelll=nn.Sequential(Dense(128,64), Dense(64,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelll[0].weight = nn.Parameter(output_weight.get('dense1_weight'))\n",
    "    modelll[0].bias = nn.Parameter(output_weight.get('dense1_bias'))\n",
    "    modelll[1].weight = nn.Parameter(output_weight.get('dense2_weight'))\n",
    "    modelll[1].bias = nn.Parameter(output_weight.get('dense2_bias'))\n",
    "\n",
    "#input1, extras1 = PDB_to_schnet_input_and_names_map(cut1)\n",
    "#outputs1 = Model(input1)\n",
    "#E1 = modelll(outputs1.get('scalar_representation'))\n",
    "#Eatoms1 = [[atom for atom in extras1[1]], [e for e in E1]]\n",
    "#Eatoms1_dict = dict(zip([atom for atom in extras1[1]], [e for e in E1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "outputs1 = Model(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=10\n",
    "input1, extras1 = PDB_to_schnet_input_and_names_map(cut1)\n",
    "len(input1.get('Z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mschnetpack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mradial\u001b[39;00m \u001b[39mimport\u001b[39;00m GaussianRBF\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mschnetpack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcutoff\u001b[39;00m \u001b[39mimport\u001b[39;00m CosineCutoff\n\u001b[0;32m----> 8\u001b[0m torch\u001b[39m.\u001b[39mset_printoptions(profile\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtensor_dict.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m r\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from schnetpack.representation.schnet import SchNet\n",
    "from torch.nn import Sequential\n",
    "from schnetpack.model import NeuralNetworkPotential\n",
    "from torch import nn\n",
    "from schnetpack.nn import Dense\n",
    "from schnetpack.nn.radial import GaussianRBF\n",
    "from schnetpack.nn.cutoff import CosineCutoff\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "weights = torch.load('tensor_dict.pth')\n",
    "r=10\n",
    "output_weight = torch.load('output_tensor.pth')\n",
    "\n",
    "Model = SchNet(n_atom_basis=128, n_interactions=6, radial_basis=GaussianRBF(50, r), cutoff_fn=CosineCutoff(r))\n",
    "for keys, weight in weights.items():\n",
    "    left = f\"Model.{keys}\" \n",
    "    right = f\"torch.nn.Parameter(torch.{weight})\"\n",
    "    execu = f\"{left} = {right}\"\n",
    "    st = execu.replace(\"\\n       \",\"\")\n",
    "    st2 = st.replace(\"representation.\",\"\")\n",
    "    try:\n",
    "        exec(st2)\n",
    "    finally:\n",
    "        right2 = f\"torch.nn.Parameter({weight})\"\n",
    "        E=f\"{left} = {right2}\"\n",
    "        s = execu.replace(\"\\n       \",\"\")\n",
    "        s2 = s.replace(\"representation.\",\"\")\n",
    "        exec(s2)\n",
    "\n",
    "modelll=nn.Sequential(Dense(128,64), Dense(64,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelll[0].weight = nn.Parameter(output_weight.get('dense1_weight'))\n",
    "    modelll[0].bias = nn.Parameter(output_weight.get('dense1_bias'))\n",
    "    modelll[1].weight = nn.Parameter(output_weight.get('dense2_weight'))\n",
    "    modelll[1].bias = nn.Parameter(output_weight.get('dense2_bias'))\n",
    "\n",
    "input1, extras1 = PDB_to_schnet_input_and_names_map(cut1)\n",
    "outputs1 = Model(input1)\n",
    "E1 = modelll(outputs1.get('scalar_representation'))\n",
    "Eatoms1 = [[atom for atom in extras1[1]], [e for e in E1]]\n",
    "Eatoms1_dict = dict(zip([atom for atom in extras1[1]], [e for e in E1]))\n",
    "\n",
    "Model = SchNet(n_atom_basis=128, n_interactions=6, radial_basis=GaussianRBF(50, r), cutoff_fn=CosineCutoff(r))\n",
    "for keys, weight in weights.items():\n",
    "    left = f\"Model.{keys}\" \n",
    "    right = f\"torch.nn.Parameter(torch.{weight})\"\n",
    "    execu = f\"{left} = {right}\"\n",
    "    st = execu.replace(\"\\n       \",\"\")\n",
    "    st2 = st.replace(\"representation.\",\"\")\n",
    "    try:\n",
    "        exec(st2)\n",
    "    finally:\n",
    "        right2 = f\"torch.nn.Parameter({weight})\"\n",
    "        E=f\"{left} = {right2}\"\n",
    "        s = execu.replace(\"\\n       \",\"\")\n",
    "        s2 = s.replace(\"representation.\",\"\")\n",
    "        exec(s2)\n",
    "\n",
    "modelll=nn.Sequential(Dense(128,64), Dense(64,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelll[0].weight = nn.Parameter(output_weight.get('dense1_weight'))\n",
    "    modelll[0].bias = nn.Parameter(output_weight.get('dense1_bias'))\n",
    "    modelll[1].weight = nn.Parameter(output_weight.get('dense2_weight'))\n",
    "    modelll[1].bias = nn.Parameter(output_weight.get('dense2_bias'))\n",
    "\n",
    "input2, _ = PDB_to_schnet_input_and_names_map(cut2)\n",
    "outputs2 = Model(input2)\n",
    "E2 = modelll(outputs2.get('scalar_representation'))\n",
    "\n",
    "Eatoms2 = [[atom for atom in _[1]], [e for e in E2]]\n",
    "Eatoms2_dict = dict(zip([atom for atom in _[1]], [e for e in E2]))\n",
    "\n",
    "common_entries = set(Eatoms1[0]).intersection(set(Eatoms2[0]))\n",
    "for x in list(common_entries):\n",
    "    print(Eatoms2_dict.get(x), Eatoms1_dict.get(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(modelll\u001b[39m.\u001b[39mstate_dict()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelll' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(modelll.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_entries = set(Eatoms1[0]).intersection(set(Eatoms2[0]))\n",
    "for x in list(common_entries):\n",
    "    print(Eatoms2_dict.get(x), Eatoms1_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cut[0].get_full_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
